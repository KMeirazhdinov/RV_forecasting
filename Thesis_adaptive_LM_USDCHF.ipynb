{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_12396\\644169225.py:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import pywt, math\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from tensorflow.keras.models import save_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow.keras import regularizers\n",
    "from pandas.plotting import lag_plot\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.regularizers import l1, l2\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from datetime import timedelta\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from IPython.display import Image\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.io\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"USD_CHF_RV_89_93.csv.zip\"\n",
    "df = pd.read_csv(f'{path}', compression = 'zip') \n",
    "rv = df.rvfx.values\n",
    "r = np.flip(rv - np.mean(rv)) # Flip the data for convenience\n",
    "test_size = 520\n",
    "r_test = np.flip(r[:test_size]) # This corresponds to the last 520 observation (The most recent ones)\n",
    "r = np.append(r, 0)\n",
    "ts = np.arange(0, len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f606499fd0>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.flip(r))\n",
    "plt.plot(np.concatenate((np.zeros((len(r)-test_size),),r_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_test_set(original_series,horizon):\n",
    "\n",
    "    original_series = original_series[:-1]\n",
    "    compare = np.zeros((len(original_series) - horizon + 1,))\n",
    "\n",
    "    for i in range(len(compare)):\n",
    "\n",
    "        compare[i] = np.mean(original_series[i:i+horizon])\n",
    "\n",
    "    return np.flip(compare)[-test_size+horizon:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1/2\n",
    "dec_lo, dec_hi, rec_lo, rec_hi = [c, c], [-c, c], [1, 1], [1, -1]\n",
    "filter_bank = [dec_lo, dec_hi, rec_lo, rec_hi]\n",
    "BandiWavelet = pywt.Wavelet(name=\"Bandi\", filter_bank=filter_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A1, D1) = pywt.dwt(r, BandiWavelet)\n",
    "(A2, D2) = pywt.dwt(A1, BandiWavelet)\n",
    "\n",
    "# Creating the timestamps to making indexing more convenient\n",
    "ts1 = np.arange(0, len(r), 2**1)\n",
    "ts2 = np.arange(0, len(r), 2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bring_to_original_size(arr, j):\n",
    "\n",
    "  # This function accepts the wavelet coefficients and depending on the scale\n",
    "  # will return the wavelet coefficients that are of the same size as the\n",
    "  # original realized volatility time series (3600), by filling zeros in between.\n",
    "\n",
    "  output = np.array([])\n",
    "\n",
    "  zeros_array = np.zeros(2**j-1)\n",
    "\n",
    "  for i in range(len(arr)):\n",
    "\n",
    "    output = np.append(output, arr[i])\n",
    "\n",
    "    output = np.concatenate((output, zeros_array))\n",
    "\n",
    "  return output\n",
    "\n",
    "def adjust_size(A,D):\n",
    "\n",
    "  # Since we model the scales using the other scales, for the j=3 coefficients\n",
    "  # last 7 observations are 0s, for j=2 its 3 and for j=1 its 1. Hence the output\n",
    "  # is the matrix of wavelet coefficients being all of the size of the coefficients\n",
    "  # for j=3. Check the output.\n",
    "\n",
    "  lengths = []\n",
    "\n",
    "  for i in range(A.shape[1]):\n",
    "\n",
    "      lengths.append(np.where(A[:,i] == A[:,i][A[:,i] != 0][-1])[0][0]+1)\n",
    "\n",
    "  cutoff = np.min(lengths)\n",
    "\n",
    "  A_output = A[:cutoff,:]\n",
    "  D_output = D[:cutoff,:]\n",
    "\n",
    "  return A_output, D_output\n",
    "\n",
    "fA1 = bring_to_original_size(A1, 1)\n",
    "fA2 = bring_to_original_size(A2, 2)\n",
    "fD1 = bring_to_original_size(D1, 1)\n",
    "fD2 = bring_to_original_size(D2, 2)\n",
    "\n",
    "fA = np.column_stack((fA1,fA2))\n",
    "fD = np.column_stack((fD1,fD2))\n",
    "fA, fD = adjust_size(fA,fD)\n",
    "\n",
    "# Creating the timestamps to making indexing more convenient\n",
    "ts1 = np.arange(0, len(fA), 2**1)\n",
    "ts2 = np.arange(0, len(fA), 2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling function\n",
    "def assemble(position, yA2, yD2, yD1):\n",
    "\n",
    "    a2 = yA2\n",
    "\n",
    "    if position == 3:\n",
    "\n",
    "        d2 = -yD2\n",
    "        d1 = -yD1\n",
    "\n",
    "    elif position == 2:\n",
    "        d2 = -yD2\n",
    "        d1 = yD1\n",
    "\n",
    "    elif position == 1:\n",
    "        d2 = yD2\n",
    "        d1 = -yD1\n",
    "\n",
    "    elif position == 0:\n",
    "        d2 = yD2\n",
    "        d1 = yD1\n",
    "\n",
    "    output = a2 + d2 + d1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_1(ind_mat):\n",
    "    checker = 0\n",
    "    for i in range(len(ind_mat)):\n",
    "        if np.sum(ind_mat[i,0] < ind_mat[i,1:]) != len(ind_mat[i,1:]):\n",
    "            print(f\"Check observation {i}\")\n",
    "            print(f\"Row is {ind_mat[i,:]}\")\n",
    "            print('                          ')\n",
    "        else:\n",
    "            checker += 1\n",
    "    return checker == len(ind_mat)\n",
    "\n",
    "def check_2(ind_mat):\n",
    "    checker = 0\n",
    "    for i in range(len(ind_mat)):\n",
    "        row = ind_mat[i,:]\n",
    "        y = row[0]\n",
    "        x = row[1:]\n",
    "        check = 0\n",
    "        for j in range(len(x)):\n",
    "            if x[j] > y:\n",
    "                check += 1\n",
    "        if check == len(x):\n",
    "            checker += 1\n",
    "        else:\n",
    "            print(f'Something is wrong with the order, check row {i}')\n",
    "            print(f'{row}')\n",
    "            print(f'           ')\n",
    "    return checker == len(ind_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj(M, j, struct, num_lags):\n",
    "\n",
    "    num_lags = np.array(num_lags).astype(int)\n",
    "\n",
    "    lags = [np.arange(struct[0],struct[0]+num_lags[0]),np.arange(struct[1],struct[1]+num_lags[1])]\n",
    "\n",
    "    Jmax = num_lags[0]+num_lags[1]\n",
    "\n",
    "    max_inds = [-2*(num_lags[0]+struct[0]-1)-1, -4*(num_lags[1]+struct[1]-1)-1]\n",
    "    idxcount = len(M) + np.min(max_inds)\n",
    "\n",
    "    if j == 2:\n",
    "        idx = ts2[ts2 < idxcount][-1]\n",
    "    elif j == 1:\n",
    "        idx = ts1[ts1 < idxcount][-1]\n",
    "\n",
    "    y_idx = np.arange(0,idx+1,2**j)\n",
    "\n",
    "    X = np.zeros((len(y_idx),Jmax))\n",
    "    X_ind = np.zeros((len(y_idx),Jmax))\n",
    "\n",
    "    X_indices = {1:np.arange(0,num_lags[0]),2:np.arange(num_lags[0],num_lags[0]+num_lags[1])}\n",
    "\n",
    "    for k in range(M.shape[1]):\n",
    "\n",
    "        X_idx = np.nonzero(fA[:,k])[0]\n",
    "\n",
    "        indices = np.zeros((len(y_idx),num_lags[k]), dtype=int)\n",
    "\n",
    "        for i in range(len(y_idx)):\n",
    "\n",
    "            current_y_idx = y_idx[i]\n",
    "\n",
    "            try:\n",
    "\n",
    "                x_idx = X_idx[X_idx > current_y_idx][lags[k]]\n",
    "\n",
    "            except:\n",
    "\n",
    "                print('Something is wrong')\n",
    "\n",
    "            indices[i,:] = x_idx\n",
    "\n",
    "        X[:,X_indices[k+1]] = M[indices,k]\n",
    "        X_ind[:,X_indices[k+1]] = indices\n",
    "\n",
    "    y = M[y_idx,j-1]\n",
    "    reg_mat = np.column_stack((y,X))\n",
    "    reg_mat_ind = np.column_stack((y_idx,X_ind))\n",
    "\n",
    "    # Do the checks to see if data is in the right order/format\n",
    "    # print(\"Check. Checking if the index of y is always smaller than the indices of any feature included, status = \",check_1(reg_mat_ind),check_2(reg_mat_ind))\n",
    "#     print(\"                   \")\n",
    "    return reg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_lags_dict, fA = fA, fD = fD):\n",
    "\n",
    "    Reg_data_dict = {}\n",
    "\n",
    "    lags = [0,0,0]\n",
    "    num_lags = num_lags_dict[1]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 1, lags, num_lags), adj(fD, 1, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[1] = reg_mat\n",
    "\n",
    "    lags = [0,0,0]\n",
    "    num_lags = num_lags_dict[2]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 2, lags, num_lags), adj(fD, 2, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[2] = reg_mat\n",
    "\n",
    "    lags = [1,0,0]\n",
    "    num_lags = num_lags_dict[3]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 2, lags, num_lags), adj(fD, 2, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[3] = reg_mat\n",
    "\n",
    "    return Reg_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multistep Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decimation prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmfndlm(adjusting_models, num_lags_dict, batch_size, val_size = len(r_test)):\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    lm_predictions = []\n",
    "\n",
    "    update_counter = 0\n",
    "    iteration = 1\n",
    "\n",
    "    test_size_decrease = np.copy(val_size)\n",
    "\n",
    "    lm_save_path = f'multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(adjusting_models, file)\n",
    "\n",
    "    for k in range(val_size,0,-1):\n",
    "\n",
    "        T = k                              # Current day\n",
    "        t = T-1                            # Next day (The one we make the prediction for)\n",
    "\n",
    "        stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "        stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "        reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "        position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "        if position == 3 or position == 2:\n",
    "\n",
    "            model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "            model2a,model2d = adjusting_models[3]['A'],adjusting_models[3]['D']\n",
    "\n",
    "            idx_2a = [np.arange(0,num_lags_dict[5][3][0]),np.arange(0,num_lags_dict[5][3][1])]\n",
    "            idx_2d = [np.arange(0,num_lags_dict[6][3][0]),np.arange(0,num_lags_dict[6][3][1])]\n",
    "            idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "            idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "        elif position == 1 or position == 0:\n",
    "\n",
    "            model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "            model2a,model2d = adjusting_models[2]['A'],adjusting_models[2]['D']\n",
    "\n",
    "            idx_2a = [np.arange(0,num_lags_dict[3][2][0]),np.arange(0,num_lags_dict[3][2][1])]\n",
    "            idx_2d = [np.arange(0,num_lags_dict[4][2][0]),np.arange(0,num_lags_dict[4][2][1])]\n",
    "            idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "            idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "        start2a = [ts1[ts1 >= T][idx_2a[0]], ts2[ts2 >= T][idx_2a[1]]]\n",
    "        start2d = [ts1[ts1 >= T][idx_2d[0]], ts2[ts2 >= T][idx_2d[1]]]\n",
    "        start1a = [ts1[ts1 >= T][idx_1a[0]], ts2[ts2 >= T][idx_1a[1]]]\n",
    "        start1d = [ts1[ts1 >= T][idx_1d[0]], ts2[ts2 >= T][idx_1d[1]]]\n",
    "\n",
    "        X_2a = np.concatenate((fA[start2a[0],0],fA[start2a[1],1],fD[start2a[0],0],fD[start2a[1],1])).reshape(1, -1)\n",
    "        X_2d = np.concatenate((fA[start2d[0],0],fA[start2d[1],1],fD[start2d[0],0],fD[start2d[1],1])).reshape(1, -1)\n",
    "        X_1a = np.concatenate((fA[start1a[0],0],fA[start1a[1],1],fD[start1a[0],0],fD[start1a[1],1])).reshape(1, -1)\n",
    "        X_1d = np.concatenate((fA[start1d[0],0],fA[start1d[1],1],fD[start1d[0],0],fD[start1d[1],1])).reshape(1, -1)\n",
    "\n",
    "        yA2 = model2a.predict(X_2a)\n",
    "        yD2 = model2d.predict(X_2d)\n",
    "        yD1 = model1d.predict(X_1d)\n",
    "\n",
    "        pred = assemble(position, yA2, yD2, yD1)[0]\n",
    "\n",
    "        lm_predictions.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "            \n",
    "            test_size_decrease = test_size_decrease - batch_size\n",
    "            adjusting_models, num_lags_dict_big = gen_data_for_lm(num_lags_dict, test_size_decrease)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            lm_save_path = f'multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "            os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "            with open(lm_save_path, 'wb') as file:\n",
    "                pickle.dump(adjusting_models, file)\n",
    "\n",
    "    return lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No decimation approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfndlm(adjusting_models, num_lags_dict, batch_size, val_size = len(r_test)):\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    lm_predictions = []\n",
    "\n",
    "    update_counter = 0\n",
    "\n",
    "    test_size_decrease = np.copy(val_size)\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    lm_save_path = f'multistep_lm/batch_size_{batch_size}/no_decimation_adjusting_models_{iteration}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(adjusting_models, file)\n",
    "\n",
    "    for k in range(val_size,0,-1):\n",
    "\n",
    "        T = k                              # Current day\n",
    "        t = T-1                            # Next day (The one we make the prediction for)\n",
    "\n",
    "        stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "        stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "        reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "        position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "        model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "        model2a,model2d = adjusting_models[2]['A'],adjusting_models[2]['D']\n",
    "\n",
    "        idx_2a = [np.arange(0,num_lags_dict[3][2][0]),np.arange(0,num_lags_dict[3][2][1])]\n",
    "        idx_2d = [np.arange(0,num_lags_dict[4][2][0]),np.arange(0,num_lags_dict[4][2][1])]\n",
    "        idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "        idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "        start2a = [ts1[ts1 >= T][idx_2a[0]], ts2[ts2 >= T][idx_2a[1]]]\n",
    "        start2d = [ts1[ts1 >= T][idx_2d[0]], ts2[ts2 >= T][idx_2d[1]]]\n",
    "        start1a = [ts1[ts1 >= T][idx_1a[0]], ts2[ts2 >= T][idx_1a[1]]]\n",
    "        start1d = [ts1[ts1 >= T][idx_1d[0]], ts2[ts2 >= T][idx_1d[1]]]\n",
    "\n",
    "        X_2a = np.concatenate((fA[start2a[0],0],fA[start2a[1],1],fD[start2a[0],0],fD[start2a[1],1])).reshape(1, -1)\n",
    "        X_2d = np.concatenate((fA[start2d[0],0],fA[start2d[1],1],fD[start2d[0],0],fD[start2d[1],1])).reshape(1, -1)\n",
    "        X_1a = np.concatenate((fA[start1a[0],0],fA[start1a[1],1],fD[start1a[0],0],fD[start1a[1],1])).reshape(1, -1)\n",
    "        X_1d = np.concatenate((fA[start1d[0],0],fA[start1d[1],1],fD[start1d[0],0],fD[start1d[1],1])).reshape(1, -1)\n",
    "\n",
    "        yA2 = model2a.predict(X_2a)\n",
    "        yD2 = model2d.predict(X_2d)\n",
    "        yD1 = model1d.predict(X_1d)\n",
    "\n",
    "        pred = assemble(position, yA2, yD2, yD1)[0]\n",
    "\n",
    "        lm_predictions.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "\n",
    "            test_size_decrease = test_size_decrease - batch_size\n",
    "\n",
    "            adjusting_models, num_lags_dict_big = gen_data_for_lm(num_lags_dict, test_size_decrease)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            lm_save_path = f'multistep_lm/batch_size_{batch_size}/no_decimation_adjusting_models_{iteration}.pkl'\n",
    "\n",
    "            os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "            with open(lm_save_path, 'wb') as file:\n",
    "                pickle.dump(adjusting_models, file)\n",
    "\n",
    "    return lm_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge/Lasso tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_tune(X,y):\n",
    "\n",
    "    grid = np.arange(0,2,0.1)\n",
    "\n",
    "    cv_performance = []\n",
    "\n",
    "    test_size = int(0.2*len(y))\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=4, test_size=test_size)\n",
    "\n",
    "    for k in range(len(grid)):\n",
    "\n",
    "        param = grid[k]\n",
    "        avg_mse = []\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "            X_train, y_train = np.flip(X,0)[train_index,:], np.flip(y)[train_index]\n",
    "            X_val, y_val = np.flip(X,0)[test_index,:], np.flip(y)[test_index]\n",
    "\n",
    "            if param != 0:\n",
    "                model = linear_model.Ridge(alpha=param)\n",
    "                model = model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            avg_mse.append(mean_squared_error(y_val, preds))\n",
    "\n",
    "        cv_performance.append(np.mean(avg_mse))\n",
    "\n",
    "    best_alpha = grid[np.where(cv_performance == np.min(cv_performance))[0][0]]\n",
    "\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_lm_models(i, scale, coef, Reg_data_dict, val_size = len(r_test)):\n",
    "\n",
    "    ya = Reg_data_dict[i]['A'][:,0]\n",
    "    Xa = Reg_data_dict[i]['A'][:,1:]\n",
    "    yd = Reg_data_dict[i]['D'][:,0]\n",
    "    Xd = Reg_data_dict[i]['D'][:,1:]\n",
    "\n",
    "    if scale == 1:\n",
    "        idx = int(len(ya) - (val_size)/(2**1)) \n",
    "    elif scale == 2:\n",
    "        idx = int(len(ya) - (val_size)/(2**2))\n",
    "\n",
    "    ya_train, ya_test = ya[-idx:], ya[:-idx]\n",
    "    yd_train, yd_test = yd[-idx:], yd[:-idx]\n",
    "    Xa_train, Xa_test = Xa[-idx:,:], Xa[:-idx,:]\n",
    "    Xd_train, Xd_test = Xd[-idx:,:], Xd[:-idx,:]\n",
    "\n",
    "    X_train = np.column_stack((Xa_train, Xd_train))\n",
    "    X_test = np.column_stack((Xa_test, Xd_test))\n",
    "\n",
    "    if coef == 'A':\n",
    "        alpha = ridge_tune(X_train, ya_train)\n",
    "\n",
    "        if alpha != 0:\n",
    "            # model = linear_model.Lasso(alpha=alpha)\n",
    "            model = linear_model.Ridge(alpha=alpha)\n",
    "            model = model.fit(X_train, ya_train)\n",
    "        else:\n",
    "            model = LinearRegression().fit(X_train, ya_train)\n",
    "    else:\n",
    "        alpha = ridge_tune(X_train, yd_train)\n",
    "        if alpha != 0:\n",
    "            # model = linear_model.Lasso(alpha=alpha)\n",
    "            model = linear_model.Ridge(alpha=alpha)\n",
    "            model = model.fit(X_train, yd_train)\n",
    "        else:\n",
    "            model = LinearRegression().fit(X_train, yd_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data_for_lm(lags, val_size = len(r_test)):\n",
    "\n",
    "    # Get model1a\n",
    "    Reg_data_dict = generate_data(lags[1])\n",
    "    model1a = prep_lm_models(1, 1, \"A\", Reg_data_dict, val_size)\n",
    "\n",
    "    # Get model1d\n",
    "    Reg_data_dict = generate_data(lags[2])\n",
    "    model1d = prep_lm_models(1, 1, \"D\", Reg_data_dict, val_size)\n",
    "\n",
    "    # Get model2a\n",
    "    Reg_data_dict = generate_data(lags[3])\n",
    "    model2a = prep_lm_models(2, 2, \"A\", Reg_data_dict, val_size)\n",
    "\n",
    "    # Get model2d\n",
    "    Reg_data_dict = generate_data(lags[4])\n",
    "    model2d = prep_lm_models(2, 2, \"D\", Reg_data_dict, val_size)\n",
    "\n",
    "    # Get model3a\n",
    "    Reg_data_dict = generate_data(lags[5])\n",
    "    model3a = prep_lm_models(3, 2, \"A\", Reg_data_dict, val_size)\n",
    "\n",
    "    # Get model3d\n",
    "    Reg_data_dict = generate_data(lags[6])\n",
    "    model3d = prep_lm_models(3, 2, \"D\", Reg_data_dict, val_size)\n",
    "\n",
    "    adjusting_models = {1:{\"A\":model1a,\"D\":model1d},2:{\"A\":model2a,\"D\":model2d},3:{\"A\":model3a,\"D\":model3d}}\n",
    "    num_lags_dict_big = {1:lags[1],2:lags[2],3:lags[3],4:lags[4],5:lags[5],6:lags[6]}\n",
    "\n",
    "    return adjusting_models, num_lags_dict_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "multistep_lags_path = 'multistep_best_lags_lm_USDCHF.pkl'\n",
    "with open(multistep_lags_path, 'rb') as file:\n",
    "    best_lags = pickle.load(file)\n",
    "\n",
    "adjusting_models, num_lags_dict_big = gen_data_for_lm(best_lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  4.8039593987351\n",
      "MAE =  1.3031756132633319\n",
      "R^2 is =  0.676807062635157\n"
     ]
    }
   ],
   "source": [
    "# 1 day ahead forecast\n",
    "batch_size = 22\n",
    "multistep_lm = dmfndlm(adjusting_models, num_lags_dict_big, batch_size)\n",
    "print(\"MSE = \", mean_squared_error(multistep_lm, r_test))\n",
    "print(\"MAE = \", mean_absolute_error(multistep_lm, r_test))\n",
    "print(\"R^2 is = \",r2_score(r_test, multistep_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  4.858782720192742\n",
      "MAE =  1.3251060132529144\n",
      "R^2 is =  0.673118748720044\n"
     ]
    }
   ],
   "source": [
    "# 1 day ahead forecast\n",
    "batch_size = 22\n",
    "multistep_lm = mfndlm(adjusting_models, num_lags_dict_big, batch_size)\n",
    "print(\"MSE = \", mean_squared_error(multistep_lm, r_test))\n",
    "print(\"MAE = \", mean_absolute_error(multistep_lm, r_test))\n",
    "print(\"R^2 is = \",r2_score(r_test, multistep_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faster_dmfndlm(adjusting_models, num_lags_dict, batch_size, val_size = len(r_test)):\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    lm_predictions = []\n",
    "\n",
    "    update_counter = 0\n",
    "    iteration = 1\n",
    "\n",
    "    lm_save_path = f'multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "    with open(lm_save_path, 'rb') as file:\n",
    "        adjusting_models = pickle.load(file)\n",
    "\n",
    "    for k in range(val_size,0,-1):\n",
    "\n",
    "        T = k                              # Current day\n",
    "        t = T-1                            # Next day (The one we make the prediction for)\n",
    "\n",
    "        stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "        stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "        reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "        position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "        if position == 3 or position == 2:\n",
    "\n",
    "            model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "            model2a,model2d = adjusting_models[3]['A'],adjusting_models[3]['D']\n",
    "\n",
    "            idx_2a = [np.arange(0,num_lags_dict[5][3][0]),np.arange(0,num_lags_dict[5][3][1])]\n",
    "            idx_2d = [np.arange(0,num_lags_dict[6][3][0]),np.arange(0,num_lags_dict[6][3][1])]\n",
    "            idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "            idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "        elif position == 1 or position == 0:\n",
    "\n",
    "            model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "            model2a,model2d = adjusting_models[2]['A'],adjusting_models[2]['D']\n",
    "\n",
    "            idx_2a = [np.arange(0,num_lags_dict[3][2][0]),np.arange(0,num_lags_dict[3][2][1])]\n",
    "            idx_2d = [np.arange(0,num_lags_dict[4][2][0]),np.arange(0,num_lags_dict[4][2][1])]\n",
    "            idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "            idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "        start2a = [ts1[ts1 >= T][idx_2a[0]], ts2[ts2 >= T][idx_2a[1]]]\n",
    "        start2d = [ts1[ts1 >= T][idx_2d[0]], ts2[ts2 >= T][idx_2d[1]]]\n",
    "        start1a = [ts1[ts1 >= T][idx_1a[0]], ts2[ts2 >= T][idx_1a[1]]]\n",
    "        start1d = [ts1[ts1 >= T][idx_1d[0]], ts2[ts2 >= T][idx_1d[1]]]\n",
    "\n",
    "        X_2a = np.concatenate((fA[start2a[0],0],fA[start2a[1],1],fD[start2a[0],0],fD[start2a[1],1])).reshape(1, -1)\n",
    "        X_2d = np.concatenate((fA[start2d[0],0],fA[start2d[1],1],fD[start2d[0],0],fD[start2d[1],1])).reshape(1, -1)\n",
    "        X_1a = np.concatenate((fA[start1a[0],0],fA[start1a[1],1],fD[start1a[0],0],fD[start1a[1],1])).reshape(1, -1)\n",
    "        X_1d = np.concatenate((fA[start1d[0],0],fA[start1d[1],1],fD[start1d[0],0],fD[start1d[1],1])).reshape(1, -1)\n",
    "\n",
    "        yA2 = model2a.predict(X_2a)\n",
    "        yD2 = model2d.predict(X_2d)\n",
    "        yD1 = model1d.predict(X_1d)\n",
    "\n",
    "        pred = assemble(position, yA2, yD2, yD1)[0]\n",
    "\n",
    "        lm_predictions.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            lm_save_path = f'multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "            with open(lm_save_path, 'rb') as file:\n",
    "                adjusting_models = pickle.load(file)\n",
    "\n",
    "    return lm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  4.8039593987351\n",
      "MAE =  1.3031756132633319\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'r2score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMSE = \u001b[39m\u001b[39m\"\u001b[39m, mean_squared_error(multistep_lm, r_test))\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMAE = \u001b[39m\u001b[39m\"\u001b[39m, mean_absolute_error(multistep_lm, r_test))\n\u001b[1;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mR^2 is = \u001b[39m\u001b[39m\"\u001b[39m,r2score(r_test, multistep_lm))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r2score' is not defined"
     ]
    }
   ],
   "source": [
    "multistep_lm = faster_dmfndlm(1, num_lags_dict_big, batch_size)\n",
    "print(\"MSE = \", mean_squared_error(multistep_lm, r_test))\n",
    "print(\"MAE = \", mean_absolute_error(multistep_lm, r_test))\n",
    "print(\"R^2 is = \",r2_score(r_test, multistep_lm))\n",
    "\n",
    "# lm_save_path = f'prediction/decimation_multistep_lm_{1}.pkl'\n",
    "# os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "# with open(lm_save_path, 'wb') as file:\n",
    "#     pickle.dump(multistep_lm, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H steps ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dmhflm(t, T, info, adjusting_models, num_lags_dict):\n",
    "\n",
    "    u_fA = info[2]\n",
    "    u_fD = info[3]\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "    stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "    reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "    check = [0,0] # Check variable records whether information is already available from previous forecasts or not, if 1 then the prediction for that scale doesnt have to be performed.\n",
    "\n",
    "    if info[0][0] != None:\n",
    "        if stop1 >= info[0][0]:\n",
    "            check[0] = 1\n",
    "\n",
    "    if info[1][0] != None:\n",
    "        if stop2 >= info[1][0]:\n",
    "            check[1] = 1\n",
    "\n",
    "    position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "    if position == 3 or position == 2:\n",
    "\n",
    "        model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "        model2a,model2d = adjusting_models[3]['A'],adjusting_models[3]['D']\n",
    "\n",
    "        idx_2a = [np.arange(0,num_lags_dict[5][3][0]),np.arange(0,num_lags_dict[5][3][1])]\n",
    "        idx_2d = [np.arange(0,num_lags_dict[6][3][0]),np.arange(0,num_lags_dict[6][3][1])]\n",
    "        idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "        idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "    elif position == 1 or position == 0:\n",
    "\n",
    "        model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "        model2a,model2d = adjusting_models[2]['A'],adjusting_models[2]['D']\n",
    "\n",
    "        idx_2a = [np.arange(0,num_lags_dict[3][2][0]),np.arange(0,num_lags_dict[3][2][1])]\n",
    "        idx_2d = [np.arange(0,num_lags_dict[4][2][0]),np.arange(0,num_lags_dict[4][2][1])]\n",
    "        idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "        idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "    if check[0] == 0: # The prediction has to be made as info is available\n",
    "\n",
    "        start1a = [ts1[ts1 >= T][idx_1a[0]], ts2[ts2 >= T][idx_1a[1]]]\n",
    "        start1d = [ts1[ts1 >= T][idx_1d[0]], ts2[ts2 >= T][idx_1d[1]]]\n",
    "\n",
    "        X_1a = np.concatenate((u_fA[start1a[0],0],u_fA[start1a[1],1],u_fD[start1a[0],0],u_fD[start1a[1],1])).reshape(1, -1)\n",
    "        X_1d = np.concatenate((u_fA[start1d[0],0],u_fA[start1d[1],1],u_fD[start1d[0],0],u_fD[start1d[1],1])).reshape(1, -1)\n",
    "        yA1 = model1a.predict(X_1a)[0]\n",
    "        yD1 = model1d.predict(X_1d)[0]\n",
    "\n",
    "    else:\n",
    "        yA1, yD1 = info[0][1]\n",
    "\n",
    "    if check[1] == 0:\n",
    "\n",
    "        start2a = [ts1[ts1 >= T][idx_2a[0]], ts2[ts2 >= T][idx_2a[1]]]\n",
    "        start2d = [ts1[ts1 >= T][idx_2d[0]], ts2[ts2 >= T][idx_2d[1]]]\n",
    "\n",
    "        X_2a = np.concatenate((u_fA[start2a[0],0],u_fA[start2a[1],1],u_fD[start2a[0],0],u_fD[start2a[1],1])).reshape(1, -1)\n",
    "        X_2d = np.concatenate((u_fA[start2d[0],0],u_fA[start2d[1],1],u_fD[start2d[0],0],u_fD[start2d[1],1])).reshape(1, -1)\n",
    "        yA2 = model2a.predict(X_2a)[0]\n",
    "        yD2 = model2d.predict(X_2d)[0]\n",
    "\n",
    "    else:\n",
    "        yA2, yD2 = info[1][1]\n",
    "\n",
    "    return yA2, yD2, yA1, yD1, reconstruct_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with horizon 5\n",
      "5.285362339643002\n",
      "Done with horizon 20\n",
      "8.635245470498274\n",
      "Done with horizon 60\n",
      "15.803792841172612\n"
     ]
    }
   ],
   "source": [
    "horizons = [5,20,60]\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for horizon in horizons:\n",
    "\n",
    "    forecasts_size = test_size - horizon + 1\n",
    "\n",
    "    horizon_forecasts = []\n",
    "\n",
    "    update_counter = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    lm_save_path = f'multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "    with open(lm_save_path, 'rb') as file:\n",
    "        adjusting_models = pickle.load(file)\n",
    "\n",
    "    for j in range(forecasts_size-1, -1, -1):\n",
    "\n",
    "        pred_obs = j\n",
    "        current_time = pred_obs + horizon # latest available information\n",
    "        to_predict = np.flip(np.arange(pred_obs, current_time))\n",
    "\n",
    "        updated_fA = np.copy(fA)\n",
    "        updated_fD = np.copy(fD)\n",
    "\n",
    "        updated_time = np.copy(current_time)\n",
    "\n",
    "        coef_pick_decision = [[None,None], [None,None], updated_fA, updated_fD]\n",
    "\n",
    "        for i in range(len(to_predict)):\n",
    "\n",
    "            predict = to_predict[i]\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = dmhflm(predict, current_time, [[None,None], [None,None], fA, fD],adjusting_models, num_lags_dict_big)\n",
    "\n",
    "            if i != 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = dmhflm(predict, updated_time, coef_pick_decision, adjusting_models, num_lags_dict_big)\n",
    "\n",
    "            updated_fA[reconstruct_from[0],0], updated_fD[reconstruct_from[0],0] = a1,d1\n",
    "            updated_fA[reconstruct_from[1],1], updated_fD[reconstruct_from[1],1] = a2,d2\n",
    "            coef_pick_decision[2], coef_pick_decision[3] = updated_fA, updated_fD\n",
    "            coef_pick_decision[0][0], coef_pick_decision[1][0] = reconstruct_from[0], reconstruct_from[1]\n",
    "            coef_pick_decision[0][1] = [a1,d1]\n",
    "            coef_pick_decision[1][1] = [a2,d2]\n",
    "            updated_time = updated_time - 1\n",
    "\n",
    "        position = pred_obs - coef_pick_decision[1][0]\n",
    "        pred = assemble(position, coef_pick_decision[1][1][0], coef_pick_decision[1][1][1], coef_pick_decision[0][1][1])\n",
    "        horizon_forecasts.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        # if update_counter % (batch_size*2) == 0:\n",
    "\n",
    "        #     iteration += 1\n",
    "            \n",
    "        #     lm_save_path = f'SPY/multistep_lm/batch_size_{batch_size}/adjusting_models_{iteration}.pkl'\n",
    "\n",
    "        #     with open(lm_save_path, 'rb') as file:\n",
    "        #         adjusting_models = pickle.load(file)\n",
    "\n",
    "    all_predictions.append(horizon_forecasts)\n",
    "\n",
    "    lm_save_path = f'prediction/decimation_multistep_lm_{horizon}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    print(f'Done with horizon {horizon}')\n",
    "    print(mean_squared_error(r_test[horizon-1:],horizon_forecasts))\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(horizon_forecasts, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No decimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhflm(t, T, info, adjusting_models, num_lags_dict):\n",
    "\n",
    "    u_fA = info[2]\n",
    "    u_fD = info[3]\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "    stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "    reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "    check = [0,0] # Check variable records whether information is already available from previous forecasts or not, if 1 then the prediction for that scale doesnt have to be performed.\n",
    "\n",
    "    if info[0][0] != None:\n",
    "        if stop1 >= info[0][0]:\n",
    "            check[0] = 1\n",
    "\n",
    "    if info[1][0] != None:\n",
    "        if stop2 >= info[1][0]:\n",
    "            check[1] = 1\n",
    "\n",
    "    position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "    model1a,model1d = adjusting_models[1]['A'],adjusting_models[1]['D']\n",
    "    model2a,model2d = adjusting_models[2]['A'],adjusting_models[2]['D']\n",
    "\n",
    "    idx_2a = [np.arange(0,num_lags_dict[3][2][0]),np.arange(0,num_lags_dict[3][2][1])]\n",
    "    idx_2d = [np.arange(0,num_lags_dict[4][2][0]),np.arange(0,num_lags_dict[4][2][1])]\n",
    "    idx_1a = [np.arange(0,num_lags_dict[1][1][0]),np.arange(0,num_lags_dict[1][1][1])]\n",
    "    idx_1d = [np.arange(0,num_lags_dict[2][1][0]),np.arange(0,num_lags_dict[2][1][1])]\n",
    "\n",
    "    if check[0] == 0: # The prediction has to be made as info is available\n",
    "\n",
    "        start1a = [ts1[ts1 >= T][idx_1a[0]], ts2[ts2 >= T][idx_1a[1]]]\n",
    "        start1d = [ts1[ts1 >= T][idx_1d[0]], ts2[ts2 >= T][idx_1d[1]]]\n",
    "\n",
    "        X_1a = np.concatenate((u_fA[start1a[0],0],u_fA[start1a[1],1],u_fD[start1a[0],0],u_fD[start1a[1],1])).reshape(1, -1)\n",
    "        X_1d = np.concatenate((u_fA[start1d[0],0],u_fA[start1d[1],1],u_fD[start1d[0],0],u_fD[start1d[1],1])).reshape(1, -1)\n",
    "        yA1 = model1a.predict(X_1a)[0]\n",
    "        yD1 = model1d.predict(X_1d)[0]\n",
    "\n",
    "    else:\n",
    "        yA1, yD1 = info[0][1]\n",
    "\n",
    "    if check[1] == 0:\n",
    "\n",
    "        start2a = [ts1[ts1 >= T][idx_2a[0]], ts2[ts2 >= T][idx_2a[1]]]\n",
    "        start2d = [ts1[ts1 >= T][idx_2d[0]], ts2[ts2 >= T][idx_2d[1]]]\n",
    "\n",
    "        X_2a = np.concatenate((u_fA[start2a[0],0],u_fA[start2a[1],1],u_fD[start2a[0],0],u_fD[start2a[1],1])).reshape(1, -1)\n",
    "        X_2d = np.concatenate((u_fA[start2d[0],0],u_fA[start2d[1],1],u_fD[start2d[0],0],u_fD[start2d[1],1])).reshape(1, -1)\n",
    "        yA2 = model2a.predict(X_2a)[0]\n",
    "        yD2 = model2d.predict(X_2d)[0]\n",
    "\n",
    "    else:\n",
    "        yA2, yD2 = info[1][1]\n",
    "\n",
    "    return yA2, yD2, yA1, yD1, reconstruct_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with horizon 1\n",
      "4.110626066517195\n",
      "Done with horizon 5\n",
      "4.969807960202762\n",
      "Done with horizon 20\n",
      "7.779306788706343\n",
      "Done with horizon 60\n",
      "13.778385209092912\n"
     ]
    }
   ],
   "source": [
    "horizons = [1,5,20,60]\n",
    "all_predictions = []\n",
    "\n",
    "for horizon in horizons:\n",
    "\n",
    "    forecasts_size = test_size - horizon + 1\n",
    "\n",
    "    horizon_forecasts = []\n",
    "\n",
    "    update_counter = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    lm_save_path = f'multistep_lm/batch_size_{batch_size}/no_decimation_adjusting_models_{iteration}.pkl'\n",
    "\n",
    "    with open(lm_save_path, 'rb') as file:\n",
    "        adjusting_models = pickle.load(file)\n",
    "\n",
    "    for j in range(forecasts_size-1, -1, -1):\n",
    "\n",
    "        pred_obs = j\n",
    "        current_time = pred_obs + horizon # latest available information\n",
    "        to_predict = np.flip(np.arange(pred_obs, current_time))\n",
    "\n",
    "        updated_fA = np.copy(fA)\n",
    "        updated_fD = np.copy(fD)\n",
    "\n",
    "        updated_time = current_time\n",
    "\n",
    "        coef_pick_decision = [[None,None], [None,None], updated_fA, updated_fD]\n",
    "\n",
    "        for i in range(len(to_predict)):\n",
    "\n",
    "            predict = to_predict[i]\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhflm(predict, current_time, [[None,None], [None,None], fA, fD],adjusting_models, num_lags_dict_big)\n",
    "\n",
    "            if i != 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhflm(predict, updated_time, coef_pick_decision, adjusting_models, num_lags_dict_big)\n",
    "\n",
    "            updated_fA[reconstruct_from[0],0], updated_fD[reconstruct_from[0],0] = a1,d1\n",
    "            updated_fA[reconstruct_from[1],1], updated_fD[reconstruct_from[1],1] = a2,d2\n",
    "            coef_pick_decision[0][0], coef_pick_decision[1][0] = reconstruct_from[0], reconstruct_from[1]\n",
    "            coef_pick_decision[0][1] = [a1,d1]\n",
    "            coef_pick_decision[1][1] = [a2,d2]\n",
    "            updated_time = updated_time - 1\n",
    "\n",
    "        position = pred_obs - coef_pick_decision[1][0]\n",
    "        pred = assemble(position, coef_pick_decision[1][1][0], coef_pick_decision[1][1][1], coef_pick_decision[0][1][1])\n",
    "        horizon_forecasts.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            lm_save_path = f'multistep_lm/batch_size_{batch_size}/no_decimation_adjusting_models_{iteration}.pkl'\n",
    "\n",
    "            with open(lm_save_path, 'rb') as file:\n",
    "                adjusting_models = pickle.load(file)\n",
    "\n",
    "    all_predictions.append(horizon_forecasts)\n",
    "\n",
    "    lm_save_path = f'prediction/no_decimation_multistep_lm_{horizon}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    print(f'Done with horizon {horizon}')\n",
    "    print(mean_squared_error(r_test[horizon-1:], horizon_forecasts))\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(horizon_forecasts, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direct Linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_direct_data(lags):\n",
    "\n",
    "    sample_length = np.min([len(fA[:-lags[0]*2,0]),len(fA[:-lags[1]*4,1]), len(fD[:-lags[2]*2,0]),len(fD[:-lags[3]*4,1])])\n",
    "    X = np.empty((sample_length, np.sum(lags)))\n",
    "    y = np.empty((sample_length,))\n",
    "\n",
    "    for t in range(sample_length):\n",
    "\n",
    "        ts1a_inds = ts1[ts1>t][:lags[0]]\n",
    "        ts2a_inds = ts2[ts2>t][:lags[1]]\n",
    "        ts1d_inds = ts1[ts1>t][:lags[2]]\n",
    "        ts2d_inds = ts2[ts2>t][:lags[3]]\n",
    "        X1a = fA[ts1a_inds,0]\n",
    "        X2a = fA[ts2a_inds,1]\n",
    "        X1d = fD[ts1d_inds,0]\n",
    "        X2d = fD[ts2d_inds,1]\n",
    "        X_row = np.concatenate((X1a,X2a,X1d,X2d))\n",
    "        X[t,:] = X_row\n",
    "        y[t] = r[t]\n",
    "\n",
    "    return np.flip(y), np.flip(X,0)\n",
    "\n",
    "lags = [10,20,15,30]\n",
    "y_dir, X_dir = create_direct_data(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_create_direct_data(lags, rv = r):\n",
    "\n",
    "    sample_length = np.min([len(fA[:-lags[0]*2,0]),len(fA[:-lags[1]*4,1]), len(fD[:-lags[2]*2,0]),len(fD[:-lags[3]*4,1])])\n",
    "    X = np.empty((sample_length, np.sum(lags)))\n",
    "    y = np.empty((sample_length,))\n",
    "\n",
    "    for t in range(sample_length):\n",
    "\n",
    "        ts1a_inds = ts1[ts1>t][:lags[0]]\n",
    "        ts2a_inds = ts2[ts2>t][:lags[1]]\n",
    "        ts1d_inds = ts1[ts1>t][:lags[2]]\n",
    "        ts2d_inds = ts2[ts2>t][:lags[3]]\n",
    "        X1a = fA[ts1a_inds,0]\n",
    "        X2a = fA[ts2a_inds,1]\n",
    "        X1d = fD[ts1d_inds,0]\n",
    "        X2d = fD[ts2d_inds,1]\n",
    "        X_row = np.concatenate((X1a,X2a,X1d,X2d,rv[t+1:t+1+lags[-1]]))\n",
    "        X[t,:] = X_row\n",
    "        y[t] = r[t]\n",
    "\n",
    "    return np.flip(y), np.flip(X,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_direct_tune(X,y):\n",
    "\n",
    "    grid = np.arange(0,2,0.1)\n",
    "\n",
    "    cv_performance = []\n",
    "\n",
    "    test_size = int(0.2*len(y))\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=4, test_size=test_size)\n",
    "\n",
    "    for k in range(len(grid)):\n",
    "\n",
    "        param = grid[k]\n",
    "        avg_mse = []\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "            X_train, y_train = X[train_index,:], y[train_index]\n",
    "            X_val, y_val = X[test_index,:], y[test_index]\n",
    "\n",
    "            if param != 0:\n",
    "                model = linear_model.Ridge(alpha=param)\n",
    "                model = model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            avg_mse.append(mean_squared_error(y_val, preds))\n",
    "\n",
    "        cv_performance.append(np.mean(avg_mse))\n",
    "\n",
    "    best_alpha = grid[np.where(cv_performance == np.min(cv_performance))[0][0]]\n",
    "\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_direct_tune(X,y):\n",
    "\n",
    "    grid = np.arange(0,2,0.1)\n",
    "\n",
    "    cv_performance = []\n",
    "\n",
    "    test_size = int(0.2*len(y))\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=4, test_size=test_size)\n",
    "\n",
    "    for k in range(len(grid)):\n",
    "\n",
    "        param = grid[k]\n",
    "        avg_mse = []\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(tscv.split(X)):\n",
    "\n",
    "            X_train, y_train = X[train_index,:], y[train_index]\n",
    "            X_val, y_val = X[test_index,:], y[test_index]\n",
    "\n",
    "            if param != 0:\n",
    "                model = linear_model.Lasso(alpha=param)\n",
    "                model = model.fit(X_train, y_train)\n",
    "            else:\n",
    "                model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            avg_mse.append(mean_squared_error(y_val, preds))\n",
    "\n",
    "        cv_performance.append(np.mean(avg_mse))\n",
    "\n",
    "    best_alpha = grid[np.where(cv_performance == np.min(cv_performance))[0][0]]\n",
    "\n",
    "    return best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non adjusting/updating models\n",
    "\n",
    "file_path = 'extra_new_direct_best_lags_lm_USDCHF.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    direct_best_lags = pickle.load(file)\n",
    "\n",
    "y_dir, X_dir = new_create_direct_data(direct_best_lags)\n",
    "test_y_dir, test_X_dir, train_y_dir, train_X_dir = y_dir[-test_size:], X_dir[-test_size:,:], y_dir[:-test_size], X_dir[:-test_size,:]\n",
    "\n",
    "best_alpha = lasso_direct_tune(train_X_dir,train_y_dir)\n",
    "\n",
    "direct_lm_model = linear_model.Lasso(alpha = best_alpha)\n",
    "\n",
    "direct_lm_model.fit(train_X_dir, train_y_dir)\n",
    "direct_lm_preds = direct_lm_model.predict(test_X_dir)\n",
    "\n",
    "print('1 day ahead forecasting performance')\n",
    "print('MSE = ',mean_squared_error(direct_lm_preds, r_test))\n",
    "print('MAE = ',mean_absolute_error(direct_lm_preds, r_test))\n",
    "print('R^2 = ',r2_score(r_test, direct_lm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_create_direct_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m     direct_best_lags \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(file)\n\u001b[0;32m      6\u001b[0m models_to_save \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m y_dir, X_dir \u001b[39m=\u001b[39m new_create_direct_data(direct_best_lags)\n\u001b[0;32m      9\u001b[0m test_y_dir, test_X_dir, train_y_dir, train_X_dir \u001b[39m=\u001b[39m y_dir[\u001b[39m-\u001b[39mtest_size:], X_dir[\u001b[39m-\u001b[39mtest_size:,:], y_dir[:\u001b[39m-\u001b[39mtest_size], X_dir[:\u001b[39m-\u001b[39mtest_size,:]\n\u001b[0;32m     11\u001b[0m update_frequency \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_create_direct_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Adjusting/updating models\n",
    "file_path = 'extra_new_direct_best_lags_lm_USDCHF.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    direct_best_lags = pickle.load(file)\n",
    "\n",
    "models_to_save = []\n",
    "\n",
    "y_dir, X_dir = new_create_direct_data(direct_best_lags)\n",
    "test_y_dir, test_X_dir, train_y_dir, train_X_dir = y_dir[-test_size:], X_dir[-test_size:,:], y_dir[:-test_size], X_dir[:-test_size,:]\n",
    "\n",
    "update_frequency = 1\n",
    "\n",
    "direct_lm_model = linear_model.Lasso(alpha = best_alpha)\n",
    "direct_lm_model.fit(train_X_dir, train_y_dir)\n",
    "\n",
    "models_to_save.append(direct_lm_model)\n",
    "\n",
    "direct_lm_preds = np.array([])\n",
    "\n",
    "for i in range(len(test_y_dir)):\n",
    "\n",
    "    pred = direct_lm_model.predict(test_X_dir[i,:].reshape(1, -1))\n",
    "    \n",
    "    direct_lm_preds = np.append(direct_lm_preds, pred)\n",
    "\n",
    "    if i % update_frequency == 0:\n",
    "\n",
    "        new_X = np.vstack((train_X_dir, test_X_dir[:i+1,:]))\n",
    "        new_y = np.concatenate((train_y_dir, test_y_dir[:i+1]))\n",
    "\n",
    "        best_alpha = lasso_direct_tune(new_X, new_y)\n",
    "\n",
    "        direct_lm_model = linear_model.Lasso(alpha = best_alpha)\n",
    "        direct_lm_model.fit(new_X, new_y)\n",
    "\n",
    "        models_to_save.append(direct_lm_model)\n",
    "\n",
    "lm_save_path = f'direct_lm/batch_size_{update_frequency}/direct_lms.pkl'\n",
    "os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "with open(lm_save_path, 'wb') as file:\n",
    "    pickle.dump(models_to_save, file)\n",
    "\n",
    "print('1 day ahead forecasting performance')\n",
    "print('MSE = ',mean_squared_error(direct_lm_preds, r_test))\n",
    "print('MAE = ',mean_absolute_error(direct_lm_preds, r_test))\n",
    "print('R^2 = ',r2_score(r_test, direct_lm_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H step ahead predictions \n",
    "\n",
    "def direct_horizon_prediction(horizon, lags, models, batch_size, rv = r, test_size = test_size):\n",
    "\n",
    "    forecasts_size = test_size - horizon + 1\n",
    "\n",
    "    horizon_forecasts_direct = np.array([])\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    obs_counter = 0\n",
    "\n",
    "    model = models[iteration-1]\n",
    "\n",
    "    for j in range(forecasts_size-1, -1, -1):\n",
    "\n",
    "        t = j\n",
    "        T = t + horizon\n",
    "\n",
    "        find_values = np.flip(np.arange(t,T))\n",
    "        # What y values can give me the following wavelets?\n",
    "\n",
    "        pred_and_trues = np.copy(r)\n",
    "        pred_and_trues[:T] = 0\n",
    "\n",
    "        new_fA = np.copy(fA)\n",
    "        new_fA[ts1[ts1 < T],0] = 0\n",
    "        new_fA[ts2[ts2 < T],1] = 0\n",
    "\n",
    "        new_fD = np.copy(fD)\n",
    "        new_fD[ts1[ts1 < T],0] = 0\n",
    "        new_fD[ts2[ts2 < T],1] = 0\n",
    "\n",
    "        counter = T\n",
    "        temp_predictions = np.array([])\n",
    "\n",
    "        for i in range(len(find_values)):\n",
    "\n",
    "            y_ind = find_values[i]\n",
    "            X_ind_1 = ts1[(ts1 > y_ind)*(ts1 >= counter)]\n",
    "            X_ind_2 = ts2[(ts2 > y_ind)*(ts2 >= counter)]\n",
    "            X = np.concatenate((new_fA[X_ind_1[:lags[0]],0],new_fA[X_ind_2[:lags[1]],1],new_fD[X_ind_1[:lags[2]],0],new_fD[X_ind_2[:lags[3]],1], pred_and_trues[counter:counter+lags[-1]])).reshape(1, -1)\n",
    "            y_hat = model.predict(X)\n",
    "            temp_predictions = np.append(temp_predictions, y_hat)\n",
    "\n",
    "            pred_and_trues[y_ind] = y_hat\n",
    "\n",
    "            if y_ind in ts1:\n",
    "                new_fA[int(y_ind/2),0], new_fD[int(y_ind/2),0] =  pywt.dwt(pred_and_trues[y_ind:y_ind+2], BandiWavelet)\n",
    "            if y_ind in ts2:\n",
    "                new_fA[int(y_ind/4),1], new_fD[int(y_ind/4),1] =  pywt.dwt(pywt.dwt(pred_and_trues[y_ind:y_ind+4], BandiWavelet)[0], BandiWavelet)\n",
    "\n",
    "            counter = counter - 1\n",
    "\n",
    "        horizon_forecasts_direct = np.append(horizon_forecasts_direct, temp_predictions[-1])\n",
    "\n",
    "        obs_counter += 1\n",
    "\n",
    "        if obs_counter % batch_size == 0:\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "            model = models[iteration-1]\n",
    "\n",
    "    return horizon_forecasts_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with horizon 1\n",
      "4.192841651366032\n",
      "Done with horizon 5\n",
      "7.592489354517747\n",
      "Done with horizon 20\n",
      "15.280373518947911\n",
      "Done with horizon 60\n",
      "15.512620712229818\n"
     ]
    }
   ],
   "source": [
    "lm_save_path = f'direct_lm/batch_size_1/direct_lms_USDCHF.pkl'\n",
    "with open(lm_save_path, 'rb') as file:\n",
    "    all_models = pickle.load(file)\n",
    "\n",
    "file_path = 'extra_new_direct_best_lags_lm_USDCHF.pkl'\n",
    "with open(file_path, 'rb') as file:\n",
    "    direct_best_lags = pickle.load(file)\n",
    "\n",
    "horizons = [1,5,20,60]\n",
    "\n",
    "for hor in horizons:\n",
    "\n",
    "    preds = direct_horizon_prediction(hor, direct_best_lags, all_models, update_frequency, r)\n",
    "\n",
    "    lm_save_path = f'prediction/direct_lm_{hor}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    print(f'Done with horizon {hor}')\n",
    "    print(f'{mean_squared_error(r_test[hor-1:],preds)}')\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(preds, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
