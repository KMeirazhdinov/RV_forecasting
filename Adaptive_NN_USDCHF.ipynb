{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1724575977.py:12: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import BayesianOptimization\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import pywt, math\n",
    "import statsmodels.api as sm\n",
    "from tensorflow.keras.models import save_model\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from kerastuner.tuners import BayesianOptimization\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow.keras import regularizers\n",
    "from pandas.plotting import lag_plot\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LayerNormalization\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.regularizers import l1, l2\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from datetime import timedelta\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from IPython.display import Image\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import RandomSearch\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import scipy.io\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"USD_CHF_RV_89_93.csv.zip\"\n",
    "df = pd.read_csv(f'{path}', compression = 'zip') \n",
    "rv = df.rvfx.values\n",
    "r = np.flip(rv - np.mean(rv)) # Flip the data for convenience\n",
    "test_size = 520\n",
    "r_test = np.flip(r[:test_size]) # This corresponds to the last 520 observation (The most recent ones)\n",
    "r = np.append(r, 0)\n",
    "ts = np.arange(0, len(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16380b17d90>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.flip(r))\n",
    "plt.plot(np.concatenate((np.zeros((len(r)-test_size),),r_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_test_set(original_series,horizon):\n",
    "\n",
    "    original_series = original_series[:-1]\n",
    "    compare = np.zeros((len(original_series) - horizon + 1,))\n",
    "\n",
    "    for i in range(len(compare)):\n",
    "\n",
    "        compare[i] = np.mean(original_series[i:i+horizon])\n",
    "\n",
    "    return np.flip(compare)[-test_size+horizon:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DWT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pywt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m dec_lo, dec_hi, rec_lo, rec_hi \u001b[39m=\u001b[39m [c, c], [\u001b[39m-\u001b[39mc, c], [\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m], [\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m filter_bank \u001b[39m=\u001b[39m [dec_lo, dec_hi, rec_lo, rec_hi]\n\u001b[1;32m----> 4\u001b[0m BandiWavelet \u001b[39m=\u001b[39m pywt\u001b[39m.\u001b[39mWavelet(name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBandi\u001b[39m\u001b[39m\"\u001b[39m, filter_bank\u001b[39m=\u001b[39mfilter_bank)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pywt' is not defined"
     ]
    }
   ],
   "source": [
    "c = 1/2\n",
    "dec_lo, dec_hi, rec_lo, rec_hi = [c, c], [-c, c], [1, 1], [1, -1]\n",
    "filter_bank = [dec_lo, dec_hi, rec_lo, rec_hi]\n",
    "BandiWavelet = pywt.Wavelet(name=\"Bandi\", filter_bank=filter_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A1, D1) = pywt.dwt(r, BandiWavelet)\n",
    "(A2, D2) = pywt.dwt(A1, BandiWavelet)\n",
    "\n",
    "# Creating the timestamps to making indexing more convenient\n",
    "ts1 = np.arange(0, len(r), 2**1)\n",
    "ts2 = np.arange(0, len(r), 2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m   D_output \u001b[39m=\u001b[39m D[:cutoff,:]\n\u001b[0;32m     37\u001b[0m   \u001b[39mreturn\u001b[39;00m A_output, D_output\n\u001b[1;32m---> 39\u001b[0m fA1 \u001b[39m=\u001b[39m bring_to_original_size(A1, \u001b[39m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m fA2 \u001b[39m=\u001b[39m bring_to_original_size(A2, \u001b[39m2\u001b[39m)\n\u001b[0;32m     41\u001b[0m fD1 \u001b[39m=\u001b[39m bring_to_original_size(D1, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'A1' is not defined"
     ]
    }
   ],
   "source": [
    "def bring_to_original_size(arr, j):\n",
    "\n",
    "  # This function accepts the wavelet coefficients and depending on the scale\n",
    "  # will return the wavelet coefficients that are of the same size as the\n",
    "  # original realized volatility time series (3600), by filling zeros in between.\n",
    "\n",
    "  output = np.array([])\n",
    "\n",
    "  zeros_array = np.zeros(2**j-1)\n",
    "\n",
    "  for i in range(len(arr)):\n",
    "\n",
    "    output = np.append(output, arr[i])\n",
    "\n",
    "    output = np.concatenate((output, zeros_array))\n",
    "\n",
    "  return output\n",
    "\n",
    "def adjust_size(A,D):\n",
    "\n",
    "  # Since we model the scales using the other scales, for the j=3 coefficients\n",
    "  # last 7 observations are 0s, for j=2 its 3 and for j=1 its 1. Hence the output\n",
    "  # is the matrix of wavelet coefficients being all of the size of the coefficients\n",
    "  # for j=3. Check the output.\n",
    "\n",
    "  lengths = []\n",
    "\n",
    "  for i in range(A.shape[1]):\n",
    "\n",
    "      lengths.append(np.where(A[:,i] == A[:,i][A[:,i] != 0][-1])[0][0]+1)\n",
    "\n",
    "  cutoff = np.min(lengths)\n",
    "\n",
    "  A_output = A[:cutoff,:]\n",
    "  D_output = D[:cutoff,:]\n",
    "\n",
    "  return A_output, D_output\n",
    "\n",
    "fA1 = bring_to_original_size(A1, 1)\n",
    "fA2 = bring_to_original_size(A2, 2)\n",
    "fD1 = bring_to_original_size(D1, 1)\n",
    "fD2 = bring_to_original_size(D2, 2)\n",
    "\n",
    "fA = np.column_stack((fA1,fA2))\n",
    "fD = np.column_stack((fD1,fD2))\n",
    "fA, fD = adjust_size(fA,fD)\n",
    "\n",
    "# Creating the timestamps to making indexing more convenient\n",
    "ts1 = np.arange(0, len(fA), 2**1)\n",
    "ts2 = np.arange(0, len(fA), 2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling function\n",
    "def assemble(position, yA2, yD2, yD1):\n",
    "\n",
    "    a2 = yA2\n",
    "\n",
    "    if position == 3:\n",
    "\n",
    "        d2 = -yD2\n",
    "        d1 = -yD1\n",
    "\n",
    "    elif position == 2:\n",
    "        d2 = -yD2\n",
    "        d1 = yD1\n",
    "\n",
    "    elif position == 1:\n",
    "        d2 = yD2\n",
    "        d1 = -yD1\n",
    "\n",
    "    elif position == 0:\n",
    "        d2 = yD2\n",
    "        d1 = yD1\n",
    "\n",
    "    output = a2 + d2 + d1\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_1(ind_mat):\n",
    "    checker = 0\n",
    "    for i in range(len(ind_mat)):\n",
    "        if np.sum(ind_mat[i,0] < ind_mat[i,1:]) != len(ind_mat[i,1:]):\n",
    "            print(f\"Check observation {i}\")\n",
    "            print(f\"Row is {ind_mat[i,:]}\")\n",
    "            print('                          ')\n",
    "        else:\n",
    "            checker += 1\n",
    "    return checker == len(ind_mat)\n",
    "\n",
    "def check_2(ind_mat):\n",
    "    checker = 0\n",
    "    for i in range(len(ind_mat)):\n",
    "        row = ind_mat[i,:]\n",
    "        y = row[0]\n",
    "        x = row[1:]\n",
    "        check = 0\n",
    "        for j in range(len(x)):\n",
    "            if x[j] > y:\n",
    "                check += 1\n",
    "        if check == len(x):\n",
    "            checker += 1\n",
    "        else:\n",
    "            print(f'Something is wrong with the order, check row {i}')\n",
    "            print(f'{row}')\n",
    "            print(f'           ')\n",
    "    return checker == len(ind_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj(M, j, struct, num_lags):\n",
    "\n",
    "    num_lags = np.array(num_lags).astype(int)\n",
    "\n",
    "    lags = [np.arange(struct[0],struct[0]+num_lags[0]),np.arange(struct[1],struct[1]+num_lags[1])]\n",
    "\n",
    "    Jmax = num_lags[0]+num_lags[1]\n",
    "\n",
    "    max_inds = [-2*(num_lags[0]+struct[0]-1)-1, -4*(num_lags[1]+struct[1]-1)-1]\n",
    "    idxcount = len(M) + np.min(max_inds)\n",
    "\n",
    "    if j == 2:\n",
    "        idx = ts2[ts2 < idxcount][-1]\n",
    "    elif j == 1:\n",
    "        idx = ts1[ts1 < idxcount][-1]\n",
    "\n",
    "    y_idx = np.arange(0,idx+1,2**j)\n",
    "\n",
    "    X = np.zeros((len(y_idx),Jmax))\n",
    "    X_ind = np.zeros((len(y_idx),Jmax))\n",
    "\n",
    "    X_indices = {1:np.arange(0,num_lags[0]),2:np.arange(num_lags[0],num_lags[0]+num_lags[1])}\n",
    "\n",
    "    for k in range(M.shape[1]):\n",
    "\n",
    "        X_idx = np.nonzero(fA[:,k])[0]\n",
    "\n",
    "        indices = np.zeros((len(y_idx),num_lags[k]), dtype=int)\n",
    "\n",
    "        for i in range(len(y_idx)):\n",
    "\n",
    "            current_y_idx = y_idx[i]\n",
    "\n",
    "            try:\n",
    "\n",
    "                x_idx = X_idx[X_idx > current_y_idx][lags[k]]\n",
    "\n",
    "            except:\n",
    "\n",
    "                print('Something is wrong')\n",
    "\n",
    "            indices[i,:] = x_idx\n",
    "\n",
    "        X[:,X_indices[k+1]] = M[indices,k]\n",
    "        X_ind[:,X_indices[k+1]] = indices\n",
    "\n",
    "    y = M[y_idx,j-1]\n",
    "    reg_mat = np.column_stack((y,X))\n",
    "    reg_mat_ind = np.column_stack((y_idx,X_ind))\n",
    "\n",
    "    # Do the checks to see if data is in the right order/format\n",
    "    # print(\"Check. Checking if the index of y is always smaller than the indices of any feature included, status = \",check_1(reg_mat_ind),check_2(reg_mat_ind))\n",
    "#     print(\"                   \")\n",
    "    return reg_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num_lags_dict, fA = fA, fD = fD):\n",
    "\n",
    "    Reg_data_dict = {}\n",
    "\n",
    "    lags = [0,0,0]\n",
    "    num_lags = num_lags_dict[1]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 1, lags, num_lags), adj(fD, 1, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[1] = reg_mat\n",
    "\n",
    "    lags = [0,0,0]\n",
    "    num_lags = num_lags_dict[2]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 2, lags, num_lags), adj(fD, 2, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[2] = reg_mat\n",
    "\n",
    "    lags = [1,0,0]\n",
    "    num_lags = num_lags_dict[3]\n",
    "    a_reg_mat, d_reg_mat = adj(fA, 2, lags, num_lags), adj(fD, 2, lags, num_lags)\n",
    "    reg_mat = {\"A\":a_reg_mat, \"D\":d_reg_mat}\n",
    "    Reg_data_dict[3] = reg_mat\n",
    "\n",
    "    return Reg_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN New method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "\n",
    "    def build(self, hp):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        # pick activation function\n",
    "        hp_act_func = hp.Choice('activation', values=['tanh','sigmoid','relu'])\n",
    "\n",
    "        # Add input layer\n",
    "        l2_reg = hp.Float('l2_regularization', min_value=0, max_value=0.3, step=0.01)\n",
    "        l1_reg = hp.Float('l1_regularization', min_value=0, max_value=0.3, step=0.01)\n",
    "\n",
    "        model.add(Dense(units=X_train.shape[1], activation=hp_act_func, input_dim=X_train.shape[1], kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))\n",
    "\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        for i in range(hp.Int('num_layers', min_value=1, max_value=1, step=1)):\n",
    "\n",
    "            l2_reg = hp.Float('l2_regularization_'+str(i), min_value=0, max_value=0.4, step=0.01)\n",
    "            l1_reg = hp.Float('l1_regularization_'+str(i), min_value=0, max_value=0.4, step=0.01)\n",
    "\n",
    "            hp_units = hp.Int('hidden_units_'+str(i), min_value=10, max_value=200, step=5)\n",
    "\n",
    "            hp_act_func = hp.Choice('activation'+str(i), values=['tanh','sigmoid','relu'])\n",
    "\n",
    "            model.add(Dense(units=hp_units, activation=hp_act_func, kernel_regularizer=l1_l2(l1=l1_reg, l2=l2_reg)))\n",
    "\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "        # Add output layer\n",
    "        model.add(Dense(units=2, activation='linear'))\n",
    "\n",
    "        hp_learning_rate = hp.Choice('learning_rate', values=[0.1, 0.01, 0.001, 0.0001, 0.00001, 0.05, 0.005, 0.00005])\n",
    "\n",
    "        hp_weight_decay = hp.Choice('weight_decay', values=[0.005, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "\n",
    "        opt = tf.keras.optimizers.Adam(\n",
    "                learning_rate=hp_learning_rate,\n",
    "                name=\"Adam\",weight_decay=hp_weight_decay)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=opt, loss='mse', metrics=[\"mean_absolute_error\"])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, hp, model, x, y, validation_data, **kwargs):\n",
    "\n",
    "        return model.fit(\n",
    "            x,\n",
    "            y,\n",
    "            validation_data=validation_data,\n",
    "            batch_size=hp.Choice(\"batch_size\", [16, 32, 64, 128, 256]),\n",
    "            epochs = hp.Int('epochs', min_value=200, max_value=300, step=10),\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "class BestValidationLossCallback(Callback):\n",
    "    def __init__(self):\n",
    "        super(BestValidationLossCallback, self).__init__()\n",
    "        self.best_val_loss = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_loss = logs.get('val_loss')\n",
    "        if val_loss is not None and val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('Best validation loss: {}'.format(self.best_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_nn(training_X, training_y, validation_X, validation_y, scale, iter, trial):\n",
    "\n",
    "        save_directory = f'Adaptive_tuning/trial_{trial}/Reg_{scale}/iter_{iter}'\n",
    "\n",
    "        max_trials = 50\n",
    "\n",
    "        tuner = BayesianOptimization(MyHyperModel(),\n",
    "                objective='val_loss',\n",
    "                num_initial_points=20,\n",
    "                max_trials=max_trials,\n",
    "                directory=save_directory,\n",
    "                project_name=f'RV_forecasting',\n",
    "                overwrite = True)\n",
    "\n",
    "        callback = BestValidationLossCallback()\n",
    "\n",
    "        tuner.search(training_X, training_y, validation_data = (validation_X, validation_y),callbacks=[tf.keras.callbacks.EarlyStopping('val_loss', patience=3),callback],verbose = 0)\n",
    "        \n",
    "        best_model = tuner.get_best_models(1)[0]\n",
    "        save_model(best_model, f'{save_directory}/model_{iter}.h5')\n",
    "\n",
    "        best_hps = tuner.get_best_hyperparameters(30)\n",
    "        hp_directory = f'{save_directory}/hps_{iter}.pkl'\n",
    "        with open(hp_directory, 'wb') as file:\n",
    "                pickle.dump(best_hps, file)\n",
    "        \n",
    "        return best_model, best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = 1\n",
    "batch_size = 44\n",
    "num_lags_dict = {1:[30,30],2:[30,30],3:[30,30]}\n",
    "Reg_data_dict = generate_data(num_lags_dict)\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 520 and current scale is 1\n",
      "Best validation loss: 26.215633392333984\n",
      "Best validation loss: 7.488504409790039\n",
      "Best validation loss: 694.350341796875\n",
      "Best validation loss: 7.000074863433838\n",
      "Best validation loss: 8.555575370788574\n",
      "Best validation loss: 8.584161758422852\n",
      "Best validation loss: 11.940953254699707\n",
      "Best validation loss: 20.567420959472656\n",
      "Best validation loss: 161.1753692626953\n",
      "Best validation loss: 6.407491207122803\n",
      "Best validation loss: 151.85256958007812\n",
      "Best validation loss: 36.057369232177734\n",
      "Best validation loss: 316.3294677734375\n",
      "Best validation loss: 37.10983657836914\n",
      "Best validation loss: 24.40593147277832\n",
      "Best validation loss: 121.10980987548828\n",
      "Best validation loss: 12.004537582397461\n",
      "Best validation loss: 40.094398498535156\n",
      "Best validation loss: 11.298891067504883\n",
      "Best validation loss: 5.419666767120361\n",
      "Best validation loss: 4.744312763214111\n",
      "Best validation loss: 9.922039985656738\n",
      "Best validation loss: 29.484251022338867\n",
      "Best validation loss: 8.673332214355469\n",
      "Best validation loss: 22.179901123046875\n",
      "Best validation loss: 4.145450592041016\n",
      "Best validation loss: 6.112552165985107\n",
      "Best validation loss: 9.862992286682129\n",
      "Best validation loss: 6.287504196166992\n",
      "Best validation loss: 11.410933494567871\n",
      "Best validation loss: 47.80515670776367\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0005s). Check your callbacks.\n",
      "Best validation loss: 27.091197967529297\n",
      "Best validation loss: 5.098818778991699\n",
      "Best validation loss: 10.090425491333008\n",
      "Best validation loss: 6.453243255615234\n",
      "Best validation loss: 9.18195915222168\n",
      "Best validation loss: 6.932207107543945\n",
      "Best validation loss: 6.666172981262207\n",
      "Best validation loss: 5.769171714782715\n",
      "Best validation loss: 34.163448333740234\n",
      "Best validation loss: 4.04238748550415\n",
      "Best validation loss: 8.940284729003906\n",
      "Best validation loss: 4.449987411499023\n",
      "Best validation loss: 4.4512939453125\n",
      "Best validation loss: 6.429367542266846\n",
      "Best validation loss: 4.294333457946777\n",
      "Best validation loss: 11.14651870727539\n",
      "Best validation loss: 7.696157455444336\n",
      "Best validation loss: 10.410981178283691\n",
      "Best validation loss: 7.139810562133789\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 476 and current scale is 1\n",
      "Best validation loss: 59.768951416015625\n",
      "Best validation loss: 60.145904541015625\n",
      "Best validation loss: 8.060742378234863\n",
      "Best validation loss: 52.36336898803711\n",
      "Best validation loss: 6.658105850219727\n",
      "Best validation loss: 10.538784980773926\n",
      "Best validation loss: 151.2156524658203\n",
      "Best validation loss: 56.4187126159668\n",
      "Best validation loss: 4.456160068511963\n",
      "Best validation loss: 11.292608261108398\n",
      "Best validation loss: 7.013861656188965\n",
      "Best validation loss: 35.999183654785156\n",
      "Best validation loss: 9.904715538024902\n",
      "Best validation loss: 7.5368146896362305\n",
      "Best validation loss: 7.731151103973389\n",
      "Best validation loss: 4.65449857711792\n",
      "Best validation loss: 43.17470169067383\n",
      "Best validation loss: 13.71731185913086\n",
      "Best validation loss: 9.615071296691895\n",
      "Best validation loss: 8.650493621826172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 58.3181037902832\n",
      "Best validation loss: 12.372989654541016\n",
      "Best validation loss: 10.086380958557129\n",
      "Best validation loss: 14.116111755371094\n",
      "Best validation loss: 24.910812377929688\n",
      "Best validation loss: 10.01558780670166\n",
      "Best validation loss: 6.214799404144287\n",
      "Best validation loss: 7.910337448120117\n",
      "Best validation loss: 6.359682559967041\n",
      "Best validation loss: 8.877166748046875\n",
      "Best validation loss: 11.694046974182129\n",
      "Best validation loss: 7.544763565063477\n",
      "Best validation loss: 12.187512397766113\n",
      "Best validation loss: 22.115711212158203\n",
      "Best validation loss: 9.430011749267578\n",
      "Best validation loss: 6.76997184753418\n",
      "Best validation loss: 21.433183670043945\n",
      "Best validation loss: 377.4803466796875\n",
      "Best validation loss: 11.941600799560547\n",
      "Best validation loss: 6.619654178619385\n",
      "Best validation loss: 8.260323524475098\n",
      "Best validation loss: 10.100285530090332\n",
      "Best validation loss: 9.998414993286133\n",
      "Best validation loss: 5.739291667938232\n",
      "Best validation loss: 6.332170486450195\n",
      "Best validation loss: 16.225332260131836\n",
      "Best validation loss: 32.262908935546875\n",
      "Best validation loss: 7.210404872894287\n",
      "Best validation loss: 63.749061584472656\n",
      "Best validation loss: 156.82904052734375\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 432 and current scale is 1\n",
      "Best validation loss: 20.728254318237305\n",
      "Best validation loss: 74.85633850097656\n",
      "Best validation loss: 101.70210266113281\n",
      "Best validation loss: 456.7337646484375\n",
      "Best validation loss: 40.55928421020508\n",
      "Best validation loss: 28.488447189331055\n",
      "Best validation loss: 30.146577835083008\n",
      "Best validation loss: 11.931584358215332\n",
      "Best validation loss: 85.84585571289062\n",
      "Best validation loss: 7.247346878051758\n",
      "Best validation loss: 6.559067249298096\n",
      "Best validation loss: 172.94236755371094\n",
      "Best validation loss: 84.49977111816406\n",
      "Best validation loss: 17.313114166259766\n",
      "Best validation loss: 5.400216102600098\n",
      "Best validation loss: 5.328129768371582\n",
      "Best validation loss: 5.341123580932617\n",
      "Best validation loss: 41.59945297241211\n",
      "Best validation loss: 17.6510066986084\n",
      "Best validation loss: 228.96542358398438\n",
      "Best validation loss: 24.712570190429688\n",
      "Best validation loss: 283.1202087402344\n",
      "Best validation loss: 4.505190372467041\n",
      "Best validation loss: 28.38925552368164\n",
      "Best validation loss: 10.541953086853027\n",
      "Best validation loss: 29.846519470214844\n",
      "Best validation loss: 7.34188175201416\n",
      "Best validation loss: 7.738572597503662\n",
      "Best validation loss: 26.17209243774414\n",
      "Best validation loss: 6.833787441253662\n",
      "Best validation loss: 6.693203449249268\n",
      "Best validation loss: 19.153583526611328\n",
      "Best validation loss: 15.205992698669434\n",
      "Best validation loss: 13.91740894317627\n",
      "Best validation loss: 8.46088695526123\n",
      "Best validation loss: 3.9526658058166504\n",
      "Best validation loss: 8.778579711914062\n",
      "Best validation loss: 19.687068939208984\n",
      "Best validation loss: 5.427403926849365\n",
      "Best validation loss: 26.281997680664062\n",
      "Best validation loss: 7.628848552703857\n",
      "Best validation loss: 11.522644996643066\n",
      "Best validation loss: 7.9578094482421875\n",
      "Best validation loss: 54.535560607910156\n",
      "Best validation loss: 6.78614616394043\n",
      "Best validation loss: 3.9265522956848145\n",
      "Best validation loss: 5.710259437561035\n",
      "Best validation loss: 7.573784351348877\n",
      "Best validation loss: 8.273244857788086\n",
      "Best validation loss: 8.050318717956543\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 388 and current scale is 1\n",
      "Best validation loss: 7.059826374053955\n",
      "Best validation loss: 9.654658317565918\n",
      "Best validation loss: 20.186447143554688\n",
      "Best validation loss: 5.962066650390625\n",
      "Best validation loss: 365.0809020996094\n",
      "Best validation loss: 326.0533752441406\n",
      "Best validation loss: 5.930963516235352\n",
      "Best validation loss: 4.032998561859131\n",
      "Best validation loss: 29.669483184814453\n",
      "Best validation loss: 67.03236389160156\n",
      "Best validation loss: 49.10906219482422\n",
      "Best validation loss: 5.235555648803711\n",
      "Best validation loss: 6.167550086975098\n",
      "Best validation loss: 54.14267349243164\n",
      "Best validation loss: 7.49114465713501\n",
      "Best validation loss: 4.262202739715576\n",
      "Best validation loss: 5.207612037658691\n",
      "Best validation loss: 125.42350006103516\n",
      "Best validation loss: 3.730506658554077\n",
      "Best validation loss: 40.145851135253906\n",
      "Best validation loss: 37.20122146606445\n",
      "Best validation loss: 67.65036010742188\n",
      "Best validation loss: 22.66020393371582\n",
      "Best validation loss: 8.111776351928711\n",
      "Best validation loss: 63.18626403808594\n",
      "Best validation loss: 74.50393676757812\n",
      "Best validation loss: 5.0955681800842285\n",
      "Best validation loss: 16.448904037475586\n",
      "Best validation loss: 90.7170639038086\n",
      "Best validation loss: 50.60446548461914\n",
      "Best validation loss: 4.043666839599609\n",
      "Best validation loss: 33.63296890258789\n",
      "Best validation loss: 8.251167297363281\n",
      "Best validation loss: 4.572560787200928\n",
      "Best validation loss: 8.309469223022461\n",
      "Best validation loss: 4.376220226287842\n",
      "Best validation loss: 65.19219970703125\n",
      "Best validation loss: 4.493826866149902\n",
      "Best validation loss: 3.8606202602386475\n",
      "Best validation loss: 4.230964660644531\n",
      "Best validation loss: 4.922745227813721\n",
      "Best validation loss: 4.106906890869141\n",
      "Best validation loss: 3.9092600345611572\n",
      "Best validation loss: 16.69127082824707\n",
      "Best validation loss: 53.578636169433594\n",
      "Best validation loss: 4.493456840515137\n",
      "Best validation loss: 5.6548357009887695\n",
      "Best validation loss: 6.62001895904541\n",
      "Best validation loss: 4.090998649597168\n",
      "Best validation loss: 3.9443349838256836\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 344 and current scale is 1\n",
      "Best validation loss: 59.781681060791016\n",
      "Best validation loss: 5.7372236251831055\n",
      "Best validation loss: 24.179014205932617\n",
      "Best validation loss: 6.048186302185059\n",
      "Best validation loss: 33.746429443359375\n",
      "Best validation loss: 9.373673439025879\n",
      "Best validation loss: 33.728851318359375\n",
      "Best validation loss: 6.262847423553467\n",
      "Best validation loss: 15.91079044342041\n",
      "Best validation loss: 207.8301239013672\n",
      "Best validation loss: 11.858810424804688\n",
      "Best validation loss: 27.70492172241211\n",
      "Best validation loss: 118.0539779663086\n",
      "Best validation loss: 59.1064567565918\n",
      "Best validation loss: 41.52384567260742\n",
      "Best validation loss: 6.010212421417236\n",
      "Best validation loss: 5.501534461975098\n",
      "Best validation loss: 9.52686595916748\n",
      "Best validation loss: 10.779877662658691\n",
      "Best validation loss: 6.0539631843566895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 11.026261329650879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 112.4146499633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 18.700889587402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 5.563816070556641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 10.596787452697754\n",
      "Best validation loss: 5.552953243255615\n",
      "Best validation loss: 12.567464828491211\n",
      "Best validation loss: 16.23235321044922\n",
      "Best validation loss: 86.1971664428711\n",
      "Best validation loss: 7.429376125335693\n",
      "Best validation loss: 383.4725036621094\n",
      "Best validation loss: 5.434082984924316\n",
      "Best validation loss: 15.564651489257812\n",
      "Best validation loss: 23.12022590637207\n",
      "Best validation loss: 7.370031356811523\n",
      "Best validation loss: 23.650693893432617\n",
      "Best validation loss: 6.985517978668213\n",
      "Best validation loss: 100.18760681152344\n",
      "Best validation loss: 40.47578430175781\n",
      "Best validation loss: 4.915872573852539\n",
      "Best validation loss: 8.248851776123047\n",
      "Best validation loss: 16.081375122070312\n",
      "Best validation loss: 7.637243270874023\n",
      "Best validation loss: 8.141846656799316\n",
      "Best validation loss: 19.182592391967773\n",
      "Best validation loss: 6.887850284576416\n",
      "Best validation loss: 12.200560569763184\n",
      "Best validation loss: 8.020523071289062\n",
      "Best validation loss: 16.041296005249023\n",
      "Best validation loss: 7.196892738342285\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 300 and current scale is 1\n",
      "Best validation loss: 48.45001220703125\n",
      "Best validation loss: 33.659912109375\n",
      "Best validation loss: 36.419864654541016\n",
      "Best validation loss: 27.538333892822266\n",
      "Best validation loss: 33.5545654296875\n",
      "Best validation loss: 4.004245758056641\n",
      "Best validation loss: 15.015252113342285\n",
      "Best validation loss: 69.0533447265625\n",
      "Best validation loss: 6.50075101852417\n",
      "Best validation loss: 56.767032623291016\n",
      "Best validation loss: 12.387401580810547\n",
      "Best validation loss: 4.515862941741943\n",
      "Best validation loss: 53.79975891113281\n",
      "Best validation loss: 41.09152603149414\n",
      "Best validation loss: 5.6405463218688965\n",
      "Best validation loss: 33.05181121826172\n",
      "Best validation loss: 110.65162658691406\n",
      "Best validation loss: 12.813492774963379\n",
      "Best validation loss: 4.230838775634766\n",
      "Best validation loss: 69.21868133544922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 34.058284759521484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 4.860793113708496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 490.88330078125\n",
      "Best validation loss: 33.867069244384766\n",
      "Best validation loss: 9.524771690368652\n",
      "Best validation loss: 38.89827346801758\n",
      "Best validation loss: 3.665482997894287\n",
      "Best validation loss: 8.506976127624512\n",
      "Best validation loss: 20.230083465576172\n",
      "Best validation loss: 4.178051948547363\n",
      "Best validation loss: 13.068181037902832\n",
      "Best validation loss: 4.725722789764404\n",
      "Best validation loss: 4.555757522583008\n",
      "Best validation loss: 33.89858627319336\n",
      "Best validation loss: 4.59623384475708\n",
      "Best validation loss: 13.481274604797363\n",
      "Best validation loss: 27.712800979614258\n",
      "Best validation loss: 9.935808181762695\n",
      "Best validation loss: 7.590029716491699\n",
      "Best validation loss: 5.346385955810547\n",
      "Best validation loss: 3.7549991607666016\n",
      "Best validation loss: 8.52707290649414\n",
      "Best validation loss: 5.6341633796691895\n",
      "Best validation loss: 123.36235809326172\n",
      "Best validation loss: 14.698615074157715\n",
      "Best validation loss: 212.85755920410156\n",
      "Best validation loss: 4.687299728393555\n",
      "Best validation loss: 46.705562591552734\n",
      "Best validation loss: 5.467901229858398\n",
      "Best validation loss: 4.096435070037842\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 256 and current scale is 1\n",
      "Best validation loss: 10.635926246643066\n",
      "Best validation loss: 8.731941223144531\n",
      "Best validation loss: 36.90852737426758\n",
      "Best validation loss: 6.821737289428711\n",
      "Best validation loss: 38.17930603027344\n",
      "Best validation loss: 3.767703056335449\n",
      "Best validation loss: 26.139909744262695\n",
      "Best validation loss: 3.98770809173584\n",
      "Best validation loss: 262.148193359375\n",
      "Best validation loss: 330.8374938964844\n",
      "Best validation loss: 28.829391479492188\n",
      "Best validation loss: 8.539952278137207\n",
      "Best validation loss: 182.37258911132812\n",
      "Best validation loss: 7.101219654083252\n",
      "Best validation loss: 4.80082368850708\n",
      "Best validation loss: 50.19108581542969\n",
      "Best validation loss: 5.528698921203613\n",
      "Best validation loss: 3.784899950027466\n",
      "Best validation loss: 7.757133960723877\n",
      "Best validation loss: 10.23831558227539\n",
      "Best validation loss: 5.695711612701416\n",
      "Best validation loss: 32.96321487426758\n",
      "Best validation loss: 12.790574073791504\n",
      "Best validation loss: 3.439364433288574\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0003s). Check your callbacks.\n",
      "Best validation loss: 7.169347763061523\n",
      "Best validation loss: 9.074007034301758\n",
      "Best validation loss: 26.125764846801758\n",
      "Best validation loss: 5.821805953979492\n",
      "Best validation loss: 20.460601806640625\n",
      "Best validation loss: 39.71245574951172\n",
      "Best validation loss: 21.41426658630371\n",
      "Best validation loss: 56.203731536865234\n",
      "Best validation loss: 68.42205810546875\n",
      "Best validation loss: 5.088260173797607\n",
      "Best validation loss: 8.710442543029785\n",
      "Best validation loss: 13.299031257629395\n",
      "Best validation loss: 77.8086166381836\n",
      "Best validation loss: 8.448549270629883\n",
      "Best validation loss: 5.370763301849365\n",
      "Best validation loss: 5.6008501052856445\n",
      "Best validation loss: 6.391884803771973\n",
      "Best validation loss: 3.994974374771118\n",
      "Best validation loss: 11.874785423278809\n",
      "Best validation loss: 95.2513656616211\n",
      "Best validation loss: 32.91535186767578\n",
      "Best validation loss: 6.715797424316406\n",
      "Best validation loss: 21.06545066833496\n",
      "Best validation loss: 9.144285202026367\n",
      "Best validation loss: 3.4646425247192383\n",
      "Best validation loss: 4.048773765563965\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 212 and current scale is 1\n",
      "Best validation loss: 60.772430419921875\n",
      "Best validation loss: 13.443711280822754\n",
      "Best validation loss: 4.01194429397583\n",
      "Best validation loss: 34.81926727294922\n",
      "Best validation loss: 57.462520599365234\n",
      "Best validation loss: 12.380878448486328\n",
      "Best validation loss: 6.46158504486084\n",
      "Best validation loss: 27.82227325439453\n",
      "Best validation loss: 355.5929260253906\n",
      "Best validation loss: 4.685730934143066\n",
      "Best validation loss: 8.367560386657715\n",
      "Best validation loss: 29.9637451171875\n",
      "Best validation loss: 4.230854511260986\n",
      "Best validation loss: 6.972154140472412\n",
      "Best validation loss: 5.5438385009765625\n",
      "Best validation loss: 5.334114074707031\n",
      "Best validation loss: 56.49991989135742\n",
      "Best validation loss: 7.343450546264648\n",
      "Best validation loss: 323.174560546875\n",
      "Best validation loss: 11.425667762756348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 8.481141090393066\n",
      "Best validation loss: 5.15752649307251\n",
      "Best validation loss: 3.9426066875457764\n",
      "Best validation loss: 5.671981334686279\n",
      "Best validation loss: 23.86594581604004\n",
      "Best validation loss: 24.477432250976562\n",
      "Best validation loss: 13.74572467803955\n",
      "Best validation loss: 5.259599685668945\n",
      "Best validation loss: 6.557382106781006\n",
      "Best validation loss: 7.548203468322754\n",
      "Best validation loss: 12.74778938293457\n",
      "Best validation loss: 70.43566131591797\n",
      "Best validation loss: 6.706455707550049\n",
      "Best validation loss: 57.47406768798828\n",
      "Best validation loss: 15.414488792419434\n",
      "Best validation loss: 6.21581506729126\n",
      "Best validation loss: 5.435067176818848\n",
      "Best validation loss: 5.304988861083984\n",
      "Best validation loss: 47.450286865234375\n",
      "Best validation loss: 19.943344116210938\n",
      "Best validation loss: 5.981986999511719\n",
      "Best validation loss: 10.014347076416016\n",
      "Best validation loss: 58.226627349853516\n",
      "Best validation loss: 6.88716983795166\n",
      "Best validation loss: 5.837080478668213\n",
      "Best validation loss: 6.252678871154785\n",
      "Best validation loss: 7.273200511932373\n",
      "Best validation loss: 5.381945610046387\n",
      "Best validation loss: 6.544830322265625\n",
      "Best validation loss: 5.5546956062316895\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 168 and current scale is 1\n",
      "Best validation loss: 14.08150577545166\n",
      "Best validation loss: 165.9253387451172\n",
      "Best validation loss: 31.452857971191406\n",
      "Best validation loss: 10.891544342041016\n",
      "Best validation loss: 108.39527130126953\n",
      "Best validation loss: 34.95186233520508\n",
      "Best validation loss: 6.672662258148193\n",
      "Best validation loss: 13.824625968933105\n",
      "Best validation loss: 5.991273880004883\n",
      "Best validation loss: 6.2739458084106445\n",
      "Best validation loss: 20.569250106811523\n",
      "Best validation loss: 36.66804504394531\n",
      "Best validation loss: 34.347412109375\n",
      "Best validation loss: 9.257668495178223\n",
      "Best validation loss: 11.040523529052734\n",
      "Best validation loss: 51.57088088989258\n",
      "Best validation loss: 5.746181011199951\n",
      "Best validation loss: 3.8779115676879883\n",
      "Best validation loss: 8.959327697753906\n",
      "Best validation loss: 7.078151226043701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 39.913883209228516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 59.273685455322266\n",
      "Best validation loss: 7.756558418273926\n",
      "Best validation loss: 25.129356384277344\n",
      "Best validation loss: 6.056561470031738\n",
      "Best validation loss: 4.7917375564575195\n",
      "Best validation loss: 6.393855571746826\n",
      "Best validation loss: 4.1162824630737305\n",
      "Best validation loss: 4.702905654907227\n",
      "Best validation loss: 4.699095726013184\n",
      "Best validation loss: 4.426579475402832\n",
      "Best validation loss: 4.454631805419922\n",
      "Best validation loss: 4.591820240020752\n",
      "Best validation loss: 3.8408093452453613\n",
      "Best validation loss: 3.870002508163452\n",
      "Best validation loss: 4.300112247467041\n",
      "Best validation loss: 4.199068069458008\n",
      "Best validation loss: 6.371579647064209\n",
      "Best validation loss: 5.114983081817627\n",
      "Best validation loss: 5.157169342041016\n",
      "Best validation loss: 4.519367694854736\n",
      "Best validation loss: 6.0628662109375\n",
      "Best validation loss: 4.421937942504883\n",
      "Best validation loss: 8.974000930786133\n",
      "Best validation loss: 4.239832878112793\n",
      "Best validation loss: 4.474992752075195\n",
      "Best validation loss: 6.684293746948242\n",
      "Best validation loss: 6.242617130279541\n",
      "Best validation loss: 3.9825010299682617\n",
      "Best validation loss: 4.329631328582764\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 124 and current scale is 1\n",
      "Best validation loss: 4.539597511291504\n",
      "Best validation loss: 18.022113800048828\n",
      "Best validation loss: 4.371769905090332\n",
      "Best validation loss: 611.216552734375\n",
      "Best validation loss: 26.403648376464844\n",
      "Best validation loss: 32.50907516479492\n",
      "Best validation loss: 23.099843978881836\n",
      "Best validation loss: 26.24703025817871\n",
      "Best validation loss: 4.73441219329834\n",
      "Best validation loss: 5.149847507476807\n",
      "Best validation loss: 6.893872261047363\n",
      "Best validation loss: 92.35585021972656\n",
      "Best validation loss: 3.641139507293701\n",
      "Best validation loss: 31.64398765563965\n",
      "Best validation loss: 58.33149719238281\n",
      "Best validation loss: 5.601032733917236\n",
      "Best validation loss: 76.74642944335938\n",
      "Best validation loss: 508.2795715332031\n",
      "Best validation loss: 23.647018432617188\n",
      "Best validation loss: 15.752645492553711\n",
      "Best validation loss: 8.123509407043457\n",
      "Best validation loss: 4.305410385131836\n",
      "Best validation loss: 25.954132080078125\n",
      "Best validation loss: 4.926888942718506\n",
      "Best validation loss: 42.682838439941406\n",
      "Best validation loss: 4.256547451019287\n",
      "Best validation loss: 4.419923782348633\n",
      "Best validation loss: 7.354698181152344\n",
      "Best validation loss: 7.13241720199585\n",
      "Best validation loss: 57.8751335144043\n",
      "Best validation loss: 35.98908615112305\n",
      "Best validation loss: 91.33706665039062\n",
      "Best validation loss: 6.840172290802002\n",
      "Best validation loss: 7.935412883758545\n",
      "Best validation loss: 12.532143592834473\n",
      "Best validation loss: 3.471398115158081\n",
      "Best validation loss: 3.7612388134002686\n",
      "Best validation loss: 6.216442584991455\n",
      "Best validation loss: 9.880407333374023\n",
      "Best validation loss: 5.463694095611572\n",
      "Best validation loss: 5.530115127563477\n",
      "Best validation loss: 20.71910858154297\n",
      "Best validation loss: 9.537917137145996\n",
      "Best validation loss: 26.727657318115234\n",
      "Best validation loss: 7.9035515785217285\n",
      "Best validation loss: 19.472427368164062\n",
      "Best validation loss: 8.221551895141602\n",
      "Best validation loss: 5.714981555938721\n",
      "Best validation loss: 5.819929122924805\n",
      "Best validation loss: 4.379849910736084\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 80 and current scale is 1\n",
      "Best validation loss: 54.614017486572266\n",
      "Best validation loss: 7.072896480560303\n",
      "Best validation loss: 6.996650218963623\n",
      "Best validation loss: 27.497154235839844\n",
      "Best validation loss: 16.537702560424805\n",
      "Best validation loss: 10.302591323852539\n",
      "Best validation loss: 12.49226188659668\n",
      "Best validation loss: 9.470235824584961\n",
      "Best validation loss: 26.260725021362305\n",
      "Best validation loss: 41.8262939453125\n",
      "Best validation loss: 4.516345024108887\n",
      "Best validation loss: 407.8263244628906\n",
      "Best validation loss: 19.798519134521484\n",
      "Best validation loss: 8.772886276245117\n",
      "Best validation loss: 35.30807113647461\n",
      "Best validation loss: 8.294133186340332\n",
      "Best validation loss: 72.3033676147461\n",
      "Best validation loss: 6.81530237197876\n",
      "Best validation loss: 38.01730728149414\n",
      "Best validation loss: 91.52632141113281\n",
      "Best validation loss: 6.501343727111816\n",
      "Best validation loss: 4.927440643310547\n",
      "Best validation loss: 6.467866897583008\n",
      "Best validation loss: 243.84939575195312\n",
      "Best validation loss: 6.4270524978637695\n",
      "Best validation loss: 14.287479400634766\n",
      "Best validation loss: 36.216590881347656\n",
      "Best validation loss: 4.447085380554199\n",
      "Best validation loss: 22.308237075805664\n",
      "Best validation loss: 127.1656265258789\n",
      "Best validation loss: 22.849863052368164\n",
      "Best validation loss: 4.721299648284912\n",
      "Best validation loss: 26.551044464111328\n",
      "Best validation loss: 6.27014684677124\n",
      "Best validation loss: 5.378620624542236\n",
      "Best validation loss: 4.546339511871338\n",
      "Best validation loss: 3.83986234664917\n",
      "Best validation loss: 8.086676597595215\n",
      "Best validation loss: 13.065032958984375\n",
      "Best validation loss: 27.773401260375977\n",
      "Best validation loss: 9.12791633605957\n",
      "Best validation loss: 7.237366199493408\n",
      "Best validation loss: 6.137862682342529\n",
      "Best validation loss: 4.049119472503662\n",
      "Best validation loss: 5.994102478027344\n",
      "Best validation loss: 5.686634540557861\n",
      "Best validation loss: 7.228248596191406\n",
      "Best validation loss: 4.769569396972656\n",
      "Best validation loss: 9.36340618133545\n",
      "Best validation loss: 119.67717742919922\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 36 and current scale is 1\n",
      "Best validation loss: 3.718555212020874\n",
      "Best validation loss: 105.55013275146484\n",
      "Best validation loss: 7.818422317504883\n",
      "Best validation loss: 5.43878173828125\n",
      "Best validation loss: 56.694034576416016\n",
      "Best validation loss: 9.446702003479004\n",
      "Best validation loss: 90.60005187988281\n",
      "Best validation loss: 406.5304870605469\n",
      "Best validation loss: 8.163838386535645\n",
      "Best validation loss: 11.018630981445312\n",
      "Best validation loss: 29.095401763916016\n",
      "Best validation loss: 8.449054718017578\n",
      "Best validation loss: 8.493119239807129\n",
      "Best validation loss: 5.7204999923706055\n",
      "Best validation loss: 31.294597625732422\n",
      "Best validation loss: 20.376991271972656\n",
      "Best validation loss: 4.056022644042969\n",
      "Best validation loss: 5.435699939727783\n",
      "Best validation loss: 14.276342391967773\n",
      "Best validation loss: 84.38435363769531\n",
      "Best validation loss: 3.737121820449829\n",
      "Best validation loss: 6.8370890617370605\n",
      "Best validation loss: 8.699131965637207\n",
      "Best validation loss: 3.4417803287506104\n",
      "Best validation loss: 6.216617107391357\n",
      "Best validation loss: 64.30602264404297\n",
      "Best validation loss: 5.938100337982178\n",
      "Best validation loss: 4.288166046142578\n",
      "Best validation loss: 20.157093048095703\n",
      "Best validation loss: 6.814677715301514\n",
      "Best validation loss: 4.2973198890686035\n",
      "Best validation loss: 6.6694440841674805\n",
      "Best validation loss: 152.26295471191406\n",
      "Best validation loss: 6.091204643249512\n",
      "Best validation loss: 3.9220333099365234\n",
      "Best validation loss: 21.224456787109375\n",
      "Best validation loss: 3.7868547439575195\n",
      "Best validation loss: 11.804195404052734\n",
      "Best validation loss: 3.5560719966888428\n",
      "Best validation loss: 4.142530918121338\n",
      "Best validation loss: 6.495230197906494\n",
      "Best validation loss: 3.4891672134399414\n",
      "Best validation loss: 45.48366165161133\n",
      "Best validation loss: 6.724160671234131\n",
      "Best validation loss: 13.27927303314209\n",
      "Best validation loss: 3.5439536571502686\n",
      "Best validation loss: 6.348227500915527\n",
      "Best validation loss: 5.447113990783691\n",
      "Best validation loss: 113.73515319824219\n",
      "Best validation loss: 4.3134636878967285\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 520 and current scale is 2\n",
      "Best validation loss: 3.9470767974853516\n",
      "Best validation loss: 6.541773319244385\n",
      "Best validation loss: 13.442215919494629\n",
      "Best validation loss: 4.145435810089111\n",
      "Best validation loss: 10.011942863464355\n",
      "Best validation loss: 11.855125427246094\n",
      "Best validation loss: 66.40187072753906\n",
      "Best validation loss: 11.302328109741211\n",
      "Best validation loss: 17.50299835205078\n",
      "Best validation loss: 276.81109619140625\n",
      "Best validation loss: 83.23196411132812\n",
      "Best validation loss: 320.0314636230469\n",
      "Best validation loss: 7.999077320098877\n",
      "Best validation loss: 21.33162498474121\n",
      "Best validation loss: 55.02892303466797\n",
      "Best validation loss: 10.535563468933105\n",
      "Best validation loss: 13.239309310913086\n",
      "Best validation loss: 13.644142150878906\n",
      "Best validation loss: 32.131431579589844\n",
      "Best validation loss: 50.80072021484375\n",
      "Best validation loss: 14.068812370300293\n",
      "Best validation loss: 214.1724090576172\n",
      "Best validation loss: 15.085626602172852\n",
      "Best validation loss: 514.4681396484375\n",
      "Best validation loss: 12.410940170288086\n",
      "Best validation loss: 13.772936820983887\n",
      "Best validation loss: 5.117445468902588\n",
      "Best validation loss: 181.26414489746094\n",
      "Best validation loss: 15.472614288330078\n",
      "Best validation loss: 9.813680648803711\n",
      "Best validation loss: 42.08662414550781\n",
      "Best validation loss: 5.625484943389893\n",
      "Best validation loss: 4.597872734069824\n",
      "Best validation loss: 4.416671276092529\n",
      "Best validation loss: 7.9164042472839355\n",
      "Best validation loss: 3.9494428634643555\n",
      "Best validation loss: 6.046321868896484\n",
      "Best validation loss: 5.75302791595459\n",
      "Best validation loss: 6.520155429840088\n",
      "Best validation loss: 4.894470691680908\n",
      "Best validation loss: 4.727347373962402\n",
      "Best validation loss: 6.412045955657959\n",
      "Best validation loss: 3.800222635269165\n",
      "Best validation loss: 3.9340078830718994\n",
      "Best validation loss: 4.351037979125977\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0002s). Check your callbacks.\n",
      "Best validation loss: 4.525998592376709\n",
      "Best validation loss: 3.561474561691284\n",
      "Best validation loss: 5.610719203948975\n",
      "Best validation loss: 3.2060422897338867\n",
      "Best validation loss: 4.425689220428467\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 476 and current scale is 2\n",
      "Best validation loss: 20.503355026245117\n",
      "Best validation loss: 26.55898666381836\n",
      "Best validation loss: 3.849449872970581\n",
      "Best validation loss: 200.5334930419922\n",
      "Best validation loss: 8.769814491271973\n",
      "Best validation loss: 2.7545888423919678\n",
      "Best validation loss: 18.689002990722656\n",
      "Best validation loss: 20.965469360351562\n",
      "Best validation loss: 3.462923288345337\n",
      "Best validation loss: 8.847163200378418\n",
      "Best validation loss: 16.990245819091797\n",
      "Best validation loss: 64.634765625\n",
      "Best validation loss: 291.603271484375\n",
      "Best validation loss: 47.48103332519531\n",
      "Best validation loss: 7.62578010559082\n",
      "Best validation loss: 33.346370697021484\n",
      "Best validation loss: 239.64935302734375\n",
      "Best validation loss: 5.232269287109375\n",
      "Best validation loss: 133.0023956298828\n",
      "Best validation loss: 12.59130573272705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 368.1743469238281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.019469261169434\n",
      "Best validation loss: 14.943351745605469\n",
      "Best validation loss: 159.70236206054688\n",
      "Best validation loss: 15.28534984588623\n",
      "Best validation loss: 12.216583251953125\n",
      "Best validation loss: 6.012729644775391\n",
      "Best validation loss: 99.5931167602539\n",
      "Best validation loss: 60.78156280517578\n",
      "Best validation loss: 54.806800842285156\n",
      "Best validation loss: 28.05206871032715\n",
      "Best validation loss: 115.04621887207031\n",
      "Best validation loss: 39.26386260986328\n",
      "Best validation loss: 3.042752504348755\n",
      "Best validation loss: 66.51866149902344\n",
      "Best validation loss: 86.20699310302734\n",
      "Best validation loss: 46.492000579833984\n",
      "Best validation loss: 69.24308013916016\n",
      "Best validation loss: 2.20241379737854\n",
      "Best validation loss: 2.468636989593506\n",
      "Best validation loss: 361.6624755859375\n",
      "Best validation loss: 2.7553508281707764\n",
      "Best validation loss: 5.656314373016357\n",
      "Best validation loss: 8.898747444152832\n",
      "Best validation loss: 16.023591995239258\n",
      "Best validation loss: 19.603471755981445\n",
      "Best validation loss: 6.956769943237305\n",
      "Best validation loss: 98.29208374023438\n",
      "Best validation loss: 459.4588623046875\n",
      "Best validation loss: 17.376903533935547\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 432 and current scale is 2\n",
      "Best validation loss: 2.3203155994415283\n",
      "Best validation loss: 10.33737850189209\n",
      "Best validation loss: 27.16529083251953\n",
      "Best validation loss: 18.98217010498047\n",
      "Best validation loss: 33.19606018066406\n",
      "Best validation loss: 18.373571395874023\n",
      "Best validation loss: 3.085097551345825\n",
      "Best validation loss: 18.452360153198242\n",
      "Best validation loss: 94.52166748046875\n",
      "Best validation loss: 4.617552757263184\n",
      "Best validation loss: 91.16645812988281\n",
      "Best validation loss: 14.519444465637207\n",
      "Best validation loss: 29.689525604248047\n",
      "Best validation loss: 53.063663482666016\n",
      "Best validation loss: 66.56257629394531\n",
      "Best validation loss: 56.29930877685547\n",
      "Best validation loss: 5.3322882652282715\n",
      "Best validation loss: 8.39957046508789\n",
      "Best validation loss: 7.9972429275512695\n",
      "Best validation loss: 58.73687744140625\n",
      "Best validation loss: 1.891218662261963\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0004s vs `on_train_batch_end` time: 0.0005s). Check your callbacks.\n",
      "Best validation loss: 2.193295955657959\n",
      "Best validation loss: 74.63548278808594\n",
      "Best validation loss: 6.200939178466797\n",
      "Best validation loss: 2.2115204334259033\n",
      "Best validation loss: 2.3012382984161377\n",
      "Best validation loss: 22.40806770324707\n",
      "Best validation loss: 3.136747121810913\n",
      "Best validation loss: 35.10381317138672\n",
      "Best validation loss: 46.37629699707031\n",
      "Best validation loss: 2.0482473373413086\n",
      "Best validation loss: 97.74848175048828\n",
      "Best validation loss: 2.0475826263427734\n",
      "Best validation loss: 5.056245803833008\n",
      "Best validation loss: 2.3426053524017334\n",
      "Best validation loss: 2.1852824687957764\n",
      "Best validation loss: 37.3075065612793\n",
      "Best validation loss: 1.6913070678710938\n",
      "Best validation loss: 1.8935449123382568\n",
      "Best validation loss: 2.2047502994537354\n",
      "Best validation loss: 3.2701120376586914\n",
      "Best validation loss: 1.9969265460968018\n",
      "Best validation loss: 1.9748077392578125\n",
      "Best validation loss: 1.6044015884399414\n",
      "Best validation loss: 2.890740156173706\n",
      "Best validation loss: 1.8450887203216553\n",
      "Best validation loss: 3.10274338722229\n",
      "Best validation loss: 2.4797322750091553\n",
      "Best validation loss: 58.50043869018555\n",
      "Best validation loss: 1.762699007987976\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 388 and current scale is 2\n",
      "Best validation loss: 187.2111053466797\n",
      "Best validation loss: 3.2546122074127197\n",
      "Best validation loss: 5.61895227432251\n",
      "Best validation loss: 3.0658323764801025\n",
      "Best validation loss: 57.5830078125\n",
      "Best validation loss: 21.973588943481445\n",
      "Best validation loss: 7.0766472816467285\n",
      "Best validation loss: 8.745774269104004\n",
      "Best validation loss: 12.109026908874512\n",
      "Best validation loss: 27.540206909179688\n",
      "Best validation loss: 2.0836427211761475\n",
      "Best validation loss: 212.31350708007812\n",
      "Best validation loss: 136.8820037841797\n",
      "Best validation loss: 5.652509689331055\n",
      "Best validation loss: 6.957424640655518\n",
      "Best validation loss: 297.4649658203125\n",
      "Best validation loss: 116.36250305175781\n",
      "Best validation loss: 6.711644649505615\n",
      "Best validation loss: 96.57768249511719\n",
      "Best validation loss: 56.488197326660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 105.24567413330078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.813082218170166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.351393461227417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 16.292078018188477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 60.6002082824707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 89.34989166259766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 70.24922943115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 65.10431671142578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.42026424407959\n",
      "Best validation loss: 8.074385643005371\n",
      "Best validation loss: 2.531851291656494\n",
      "Best validation loss: 3.46720290184021\n",
      "Best validation loss: 8.617578506469727\n",
      "Best validation loss: 4.730082988739014\n",
      "Best validation loss: 16.138572692871094\n",
      "Best validation loss: 21.897968292236328\n",
      "Best validation loss: 3.448195457458496\n",
      "Best validation loss: 2.1627304553985596\n",
      "Best validation loss: 3.64377760887146\n",
      "Best validation loss: 2.312406539916992\n",
      "Best validation loss: 3.02980375289917\n",
      "Best validation loss: 4.755683898925781\n",
      "Best validation loss: 28.960508346557617\n",
      "Best validation loss: 15.76616096496582\n",
      "Best validation loss: 17.024913787841797\n",
      "Best validation loss: 2.4014008045196533\n",
      "Best validation loss: 4.528295993804932\n",
      "Best validation loss: 3.8960816860198975\n",
      "Best validation loss: 33.82252502441406\n",
      "Best validation loss: 6.748121738433838\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 344 and current scale is 2\n",
      "Best validation loss: 10.194662094116211\n",
      "Best validation loss: 4.170201778411865\n",
      "Best validation loss: 2.7140085697174072\n",
      "Best validation loss: 4.105415344238281\n",
      "Best validation loss: 10.964288711547852\n",
      "Best validation loss: 7.139249324798584\n",
      "Best validation loss: 111.37470245361328\n",
      "Best validation loss: 22.50381088256836\n",
      "Best validation loss: 7.839810371398926\n",
      "Best validation loss: 245.9231719970703\n",
      "Best validation loss: 3.5263869762420654\n",
      "Best validation loss: 192.74742126464844\n",
      "Best validation loss: 141.75186157226562\n",
      "Best validation loss: 3.8620309829711914\n",
      "Best validation loss: 88.88135528564453\n",
      "Best validation loss: 302.99029541015625\n",
      "Best validation loss: 22.929067611694336\n",
      "Best validation loss: 123.8226318359375\n",
      "Best validation loss: 3.839721918106079\n",
      "Best validation loss: 40.68514633178711\n",
      "Best validation loss: 2.252382278442383\n",
      "Best validation loss: 12.533438682556152\n",
      "Best validation loss: 2.4767584800720215\n",
      "Best validation loss: 14.95988941192627\n",
      "Best validation loss: 8.894933700561523\n",
      "Best validation loss: 3.9653759002685547\n",
      "Best validation loss: 31.486671447753906\n",
      "Best validation loss: 8.270625114440918\n",
      "Best validation loss: 3.087657928466797\n",
      "Best validation loss: 2.0491983890533447\n",
      "Best validation loss: 3.16823148727417\n",
      "Best validation loss: 92.08792114257812\n",
      "Best validation loss: 3.7498576641082764\n",
      "Best validation loss: 9.667582511901855\n",
      "Best validation loss: 5.647381782531738\n",
      "Best validation loss: 6.458679676055908\n",
      "Best validation loss: 5.676131725311279\n",
      "Best validation loss: 7.133274078369141\n",
      "Best validation loss: 34.496707916259766\n",
      "Best validation loss: 3.9810690879821777\n",
      "Best validation loss: 7.70082426071167\n",
      "Best validation loss: 28.86529541015625\n",
      "Best validation loss: 5.920996189117432\n",
      "Best validation loss: 6.358746528625488\n",
      "Best validation loss: 2.0258867740631104\n",
      "Best validation loss: 75.73178100585938\n",
      "Best validation loss: 3.962698221206665\n",
      "Best validation loss: 7.065878391265869\n",
      "Best validation loss: 2.7991743087768555\n",
      "Best validation loss: 8.2204008102417\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 300 and current scale is 2\n",
      "Best validation loss: 3.373077154159546\n",
      "Best validation loss: 10.688641548156738\n",
      "Best validation loss: 56.53065872192383\n",
      "Best validation loss: 17.195846557617188\n",
      "Best validation loss: 3.937319755554199\n",
      "Best validation loss: 239.40142822265625\n",
      "Best validation loss: 117.45851135253906\n",
      "Best validation loss: 39.179752349853516\n",
      "Best validation loss: 4.440466403961182\n",
      "Best validation loss: 38.28338623046875\n",
      "Best validation loss: 9.028478622436523\n",
      "Best validation loss: 47.51078414916992\n",
      "Best validation loss: 13.375699043273926\n",
      "Best validation loss: 32.24354934692383\n",
      "Best validation loss: 98.55258178710938\n",
      "Best validation loss: 41.03504180908203\n",
      "Best validation loss: 2.1433608531951904\n",
      "Best validation loss: 15.787050247192383\n",
      "Best validation loss: 10.640448570251465\n",
      "Best validation loss: 47.39796447753906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 22.709569931030273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.408928871154785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 42.86166763305664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 19.63965606689453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 93.87175750732422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 64.97342681884766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 22.67171859741211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 11.132817268371582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 5.732089042663574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 12.733511924743652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 56.33077621459961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.1258621215820312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 10.464756965637207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 367.1434631347656\n",
      "Best validation loss: 6.055117130279541\n",
      "Best validation loss: 54.12212371826172\n",
      "Best validation loss: 4.351183891296387\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0003s). Check your callbacks.\n",
      "Best validation loss: 24.303573608398438\n",
      "Best validation loss: 39.045806884765625\n",
      "Best validation loss: 5.252969741821289\n",
      "Best validation loss: 2.4322853088378906\n",
      "Best validation loss: 431.0563659667969\n",
      "Best validation loss: 4.080048084259033\n",
      "Best validation loss: 21.46379280090332\n",
      "Best validation loss: 9.081457138061523\n",
      "Best validation loss: 8.688343048095703\n",
      "Best validation loss: 7.083709239959717\n",
      "Best validation loss: 1.8885424137115479\n",
      "Best validation loss: 2.3634755611419678\n",
      "Best validation loss: 2.015129327774048\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 256 and current scale is 2\n",
      "Best validation loss: 37.50123596191406\n",
      "Best validation loss: 282.71600341796875\n",
      "Best validation loss: 1.8398991823196411\n",
      "Best validation loss: 338.6131286621094\n",
      "Best validation loss: 27.36970329284668\n",
      "Best validation loss: 39.75065612792969\n",
      "Best validation loss: 39.78425598144531\n",
      "Best validation loss: 8.940319061279297\n",
      "Best validation loss: 275.279052734375\n",
      "Best validation loss: 14.590847969055176\n",
      "Best validation loss: 1.7975245714187622\n",
      "Best validation loss: 139.83323669433594\n",
      "Best validation loss: 12.947532653808594\n",
      "Best validation loss: 2.39125919342041\n",
      "Best validation loss: 40.191349029541016\n",
      "Best validation loss: 59.17460632324219\n",
      "Best validation loss: 28.72062873840332\n",
      "Best validation loss: 61.56786346435547\n",
      "Best validation loss: 15.622072219848633\n",
      "Best validation loss: 86.18260955810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 12.808954238891602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 13.78719425201416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 696.585693359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 207.74415588378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.822296142578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 9.585350036621094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.672403335571289\n",
      "Best validation loss: 2.009284019470215\n",
      "Best validation loss: 22.356590270996094\n",
      "Best validation loss: 1.5938266515731812\n",
      "Best validation loss: 1.893011450767517\n",
      "Best validation loss: 1.987768530845642\n",
      "Best validation loss: 39.383426666259766\n",
      "Best validation loss: 2.6952648162841797\n",
      "Best validation loss: 2.4342751502990723\n",
      "Best validation loss: 6.843359470367432\n",
      "Best validation loss: 45.87625503540039\n",
      "Best validation loss: 18.00679588317871\n",
      "Best validation loss: 58.77445983886719\n",
      "Best validation loss: 53.724571228027344\n",
      "Best validation loss: 223.64610290527344\n",
      "Best validation loss: 46.741676330566406\n",
      "Best validation loss: 2.2504055500030518\n",
      "Best validation loss: 44.56411361694336\n",
      "Best validation loss: 51.641334533691406\n",
      "Best validation loss: 12.53477668762207\n",
      "Best validation loss: 2.362868547439575\n",
      "Best validation loss: 3.6352615356445312\n",
      "Best validation loss: 2.8795149326324463\n",
      "Best validation loss: 64.41919708251953\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 212 and current scale is 2\n",
      "Best validation loss: 21.94096565246582\n",
      "Best validation loss: 15.117612838745117\n",
      "Best validation loss: 363.87213134765625\n",
      "Best validation loss: 195.17918395996094\n",
      "Best validation loss: 35.091392517089844\n",
      "Best validation loss: 1.8518457412719727\n",
      "Best validation loss: 236.20985412597656\n",
      "Best validation loss: 3.811331272125244\n",
      "Best validation loss: 6.51889705657959\n",
      "Best validation loss: 9.587814331054688\n",
      "Best validation loss: 6.188628673553467\n",
      "Best validation loss: 2.589101791381836\n",
      "Best validation loss: 32.241912841796875\n",
      "Best validation loss: 164.1857452392578\n",
      "Best validation loss: 144.54940795898438\n",
      "Best validation loss: 15.838915824890137\n",
      "Best validation loss: 9.609476089477539\n",
      "Best validation loss: 8.019514083862305\n",
      "Best validation loss: 353.1455993652344\n",
      "Best validation loss: 20.91387176513672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 73.31256103515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.709909677505493\n",
      "Best validation loss: 3.8155951499938965\n",
      "Best validation loss: 6.1635518074035645\n",
      "Best validation loss: 38.36086654663086\n",
      "Best validation loss: 29.898462295532227\n",
      "Best validation loss: 48.06480407714844\n",
      "Best validation loss: 67.47191619873047\n",
      "Best validation loss: 53.08298110961914\n",
      "Best validation loss: 16.94902229309082\n",
      "Best validation loss: 36.60145950317383\n",
      "Best validation loss: 12.308053970336914\n",
      "Best validation loss: 71.78761291503906\n",
      "Best validation loss: 28.401845932006836\n",
      "Best validation loss: 25.83782958984375\n",
      "Best validation loss: 6.456801891326904\n",
      "Best validation loss: 1.8105976581573486\n",
      "Best validation loss: 2.1483826637268066\n",
      "Best validation loss: 57.25467300415039\n",
      "Best validation loss: 1.5732078552246094\n",
      "Best validation loss: 10.994349479675293\n",
      "Best validation loss: 5.0725884437561035\n",
      "Best validation loss: 2.5078344345092773\n",
      "Best validation loss: 24.354215621948242\n",
      "Best validation loss: 14.241450309753418\n",
      "Best validation loss: 4.497959613800049\n",
      "Best validation loss: 9.822015762329102\n",
      "Best validation loss: 76.0449447631836\n",
      "Best validation loss: 15.78161334991455\n",
      "Best validation loss: 111.377197265625\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 168 and current scale is 2\n",
      "Best validation loss: 32.523521423339844\n",
      "Best validation loss: 59.990726470947266\n",
      "Best validation loss: 52.49283981323242\n",
      "Best validation loss: 42.4791145324707\n",
      "Best validation loss: 235.1071014404297\n",
      "Best validation loss: 145.55450439453125\n",
      "Best validation loss: 20.442520141601562\n",
      "Best validation loss: 5.298738479614258\n",
      "Best validation loss: 60.1182861328125\n",
      "Best validation loss: 66.19424438476562\n",
      "Best validation loss: 4.3984375\n",
      "Best validation loss: 6.199099063873291\n",
      "Best validation loss: 2.3857955932617188\n",
      "Best validation loss: 4.747269630432129\n",
      "Best validation loss: 403.38800048828125\n",
      "Best validation loss: 67.20816802978516\n",
      "Best validation loss: 46.21481704711914\n",
      "Best validation loss: 14.07243824005127\n",
      "Best validation loss: 2.503594398498535\n",
      "Best validation loss: 210.76683044433594\n",
      "Best validation loss: 1.7701584100723267\n",
      "Best validation loss: 7.758950710296631\n",
      "Best validation loss: 118.53872680664062\n",
      "Best validation loss: 3.4808197021484375\n",
      "Best validation loss: 91.76197052001953\n",
      "Best validation loss: 20.461971282958984\n",
      "Best validation loss: 6.952271461486816\n",
      "Best validation loss: 7.589550495147705\n",
      "Best validation loss: 9.749700546264648\n",
      "Best validation loss: 7.369252681732178\n",
      "Best validation loss: 8.286757469177246\n",
      "Best validation loss: 22.464458465576172\n",
      "Best validation loss: 97.40263366699219\n",
      "Best validation loss: 31.41923713684082\n",
      "Best validation loss: 4.074298858642578\n",
      "Best validation loss: 3.88684344291687\n",
      "Best validation loss: 21.627843856811523\n",
      "Best validation loss: 10.417652130126953\n",
      "Best validation loss: 3.7216339111328125\n",
      "Best validation loss: 3.0593113899230957\n",
      "Best validation loss: 2.269256353378296\n",
      "Best validation loss: 3.243196964263916\n",
      "Best validation loss: 47.63422393798828\n",
      "Best validation loss: 22.869421005249023\n",
      "Best validation loss: 2.093356132507324\n",
      "Best validation loss: 3.492863655090332\n",
      "Best validation loss: 3.208570957183838\n",
      "Best validation loss: 3.8604953289031982\n",
      "Best validation loss: 6.06915283203125\n",
      "Best validation loss: 5.16886043548584\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 124 and current scale is 2\n",
      "Best validation loss: 15.086626052856445\n",
      "Best validation loss: 55.43903350830078\n",
      "Best validation loss: 55.472774505615234\n",
      "Best validation loss: 103.94422912597656\n",
      "Best validation loss: 8.0296630859375\n",
      "Best validation loss: 10.997421264648438\n",
      "Best validation loss: 133.32650756835938\n",
      "Best validation loss: 22.006851196289062\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0003s). Check your callbacks.\n",
      "Best validation loss: 35.49921417236328\n",
      "Best validation loss: 7.419262409210205\n",
      "Best validation loss: 59.08946990966797\n",
      "Best validation loss: 44.130496978759766\n",
      "Best validation loss: 31.24827003479004\n",
      "Best validation loss: 12.360651016235352\n",
      "Best validation loss: 113.32865905761719\n",
      "Best validation loss: 286.86614990234375\n",
      "Best validation loss: 5.170517921447754\n",
      "Best validation loss: 51.54355239868164\n",
      "Best validation loss: 59.3726806640625\n",
      "Best validation loss: 2.693121910095215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 45.38990783691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 276.77532958984375\n",
      "Best validation loss: 7.296781063079834\n",
      "Best validation loss: 74.89876556396484\n",
      "Best validation loss: 11.070138931274414\n",
      "Best validation loss: 3.3097989559173584\n",
      "Best validation loss: 4.063735008239746\n",
      "Best validation loss: 8.840773582458496\n",
      "Best validation loss: 28.061006546020508\n",
      "Best validation loss: 4.483853340148926\n",
      "Best validation loss: 2.7380669116973877\n",
      "Best validation loss: 6.864614486694336\n",
      "Best validation loss: 3.230658769607544\n",
      "Best validation loss: 2.8867409229278564\n",
      "Best validation loss: 58.50527572631836\n",
      "Best validation loss: 14.723187446594238\n",
      "Best validation loss: 3.111453056335449\n",
      "Best validation loss: 7.760939598083496\n",
      "Best validation loss: 2.6452651023864746\n",
      "Best validation loss: 4.626418590545654\n",
      "Best validation loss: 2.0508053302764893\n",
      "Best validation loss: 3.6324453353881836\n",
      "Best validation loss: 2.05639386177063\n",
      "Best validation loss: 3.421457529067993\n",
      "Best validation loss: 6.960980415344238\n",
      "Best validation loss: 3.04341721534729\n",
      "Best validation loss: 14.4537935256958\n",
      "Best validation loss: 59.748077392578125\n",
      "Best validation loss: 2.426506996154785\n",
      "Best validation loss: 3.8734676837921143\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 80 and current scale is 2\n",
      "Best validation loss: 6.5998311042785645\n",
      "Best validation loss: 1.8296221494674683\n",
      "Best validation loss: 8.63604736328125\n",
      "Best validation loss: 17.536046981811523\n",
      "Best validation loss: 20.599416732788086\n",
      "Best validation loss: 4.5704827308654785\n",
      "Best validation loss: 8.640789031982422\n",
      "Best validation loss: 4.256460189819336\n",
      "Best validation loss: 9.332204818725586\n",
      "Best validation loss: 3.6958281993865967\n",
      "Best validation loss: 9.683660507202148\n",
      "Best validation loss: 11.258776664733887\n",
      "Best validation loss: 5.8497443199157715\n",
      "Best validation loss: 129.9980926513672\n",
      "Best validation loss: 4.076789855957031\n",
      "Best validation loss: 7.890169143676758\n",
      "Best validation loss: 51.75832748413086\n",
      "Best validation loss: 30.943063735961914\n",
      "Best validation loss: 82.41778564453125\n",
      "Best validation loss: 1.9416214227676392\n",
      "Best validation loss: 2.634230375289917\n",
      "Best validation loss: 3.2834184169769287\n",
      "Best validation loss: 27.44465446472168\n",
      "Best validation loss: 372.4427795410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 15.356477737426758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 5.851699352264404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 14.133902549743652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 32.03068542480469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 4.019740104675293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 144.48902893066406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 13.325693130493164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 222.90463256835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 73.45545959472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 8.611516952514648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 51.77199935913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 14.974634170532227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.8960530757904053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.488295078277588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 360.2320251464844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 5.564794540405273\n",
      "Best validation loss: 27.849178314208984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 95.42417907714844\n",
      "Best validation loss: 13.227327346801758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 9.450777053833008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 66.69786834716797\n",
      "Best validation loss: 120.50782775878906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 49.270023345947266\n",
      "Best validation loss: 3.285712957382202\n",
      "Best validation loss: 4.949695587158203\n",
      "Best validation loss: 5.8109307289123535\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 36 and current scale is 2\n",
      "Best validation loss: 2.3675377368927\n",
      "Best validation loss: 24.15386962890625\n",
      "Best validation loss: 34.266075134277344\n",
      "Best validation loss: 427.3688049316406\n",
      "Best validation loss: 2.645808458328247\n",
      "Best validation loss: 188.7213134765625\n",
      "Best validation loss: 10.416481971740723\n",
      "Best validation loss: 11.305466651916504\n",
      "Best validation loss: 16.640127182006836\n",
      "Best validation loss: 2.8296151161193848\n",
      "Best validation loss: 162.76925659179688\n",
      "Best validation loss: 177.15277099609375\n",
      "Best validation loss: 2.0679662227630615\n",
      "Best validation loss: 536.4591064453125\n",
      "Best validation loss: 351.9839782714844\n",
      "Best validation loss: 75.28873443603516\n",
      "Best validation loss: 18.546329498291016\n",
      "Best validation loss: 12.465978622436523\n",
      "Best validation loss: 206.0263671875\n",
      "Best validation loss: 1.6467024087905884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 113.50306701660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 162.1484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 53.33970642089844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 1.8175148963928223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.5885274410247803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 6.8769850730896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 9.081461906433105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 31.49407958984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 7.587144374847412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 32.25533676147461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 611.3939208984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 22.933609008789062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 383.6282653808594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.5276505947113037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 2.1209864616394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 13.203913688659668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 3.063985586166382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best validation loss: 8.072051048278809\n",
      "Best validation loss: 1.764414668083191\n",
      "Best validation loss: 2.1667239665985107\n",
      "Best validation loss: 1.910845160484314\n",
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0002s vs `on_train_batch_end` time: 0.0003s). Check your callbacks.\n",
      "Best validation loss: 1.7514383792877197\n",
      "Best validation loss: 2.552175998687744\n",
      "Best validation loss: 18.096240997314453\n",
      "Best validation loss: 2.36020565032959\n",
      "Best validation loss: 2.2519218921661377\n",
      "Best validation loss: 6.287112236022949\n",
      "Best validation loss: 3.2041733264923096\n",
      "Best validation loss: 3.737783193588257\n",
      "Best validation loss: 4.031461238861084\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.19\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VANKK\\AppData\\Local\\Temp\\ipykernel_16300\\1154356729.py:20: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(best_model, f'{save_directory}/model_{iter}.h5')\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "\n",
    "    yd = np.flip(Reg_data_dict[i]['D'][:,0])\n",
    "    Xd = np.flip(Reg_data_dict[i]['D'][:,1:],0)\n",
    "    ya = np.flip(Reg_data_dict[i]['A'][:,0])\n",
    "    Xa = np.flip(Reg_data_dict[i]['A'][:,1:],0)\n",
    "\n",
    "    X = np.column_stack((Xa,Xd))\n",
    "    y = np.column_stack((ya,yd))\n",
    "\n",
    "    update_size = np.copy(test_size)\n",
    "    iteration = 1\n",
    "\n",
    "    while update_size > 0:\n",
    "\n",
    "        print(f\"Current update size is {update_size} and current scale is {i}\")\n",
    "\n",
    "        train_size = int(len(ya) - update_size/(2**i))\n",
    "        val_size = np.floor(train_size * validation_ratio).astype(int)\n",
    "\n",
    "        X_train, X_test = X[:train_size,:], X[train_size:,:]\n",
    "        y_train, y_test = y[:train_size,:], y[train_size:,:]\n",
    "\n",
    "        X_val, y_val = X_train[-val_size:,:], y_train[-val_size:,:]\n",
    "        X_train, y_train = X_train[:-val_size,:], y_train[:-val_size,:]\n",
    "\n",
    "        model, hp = tune_nn(X_train, y_train, X_val, y_val, i, iteration, trial)\n",
    "\n",
    "        update_size = update_size - batch_size\n",
    "\n",
    "        iteration = iteration + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfndnn(adjusting_models, num_lags_dict, batch_size, r_test = r_test):\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    update_models = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    for k in range(len(r_test),0,-1):\n",
    "\n",
    "        T = k                              # Current day\n",
    "        t = T-1                            # Next day (The one we make the prediction for)\n",
    "\n",
    "        stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "        stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "        reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "        position = t - reconstruct_from[-1] # 0 to 7 (The position explained in the thesis)\n",
    "\n",
    "        model1 = adjusting_models[1][iteration]\n",
    "        model2 = adjusting_models[2][iteration]\n",
    "\n",
    "        idx_2 = [np.arange(0,num_lags_dict[2][0]),np.arange(0,num_lags_dict[2][1])]\n",
    "        idx_1 = [np.arange(0,num_lags_dict[1][0]),np.arange(0,num_lags_dict[1][1])]\n",
    "\n",
    "        start2 = [ts1[ts1 >= T][idx_2[0]], ts2[ts2 >= T][idx_2[1]]]\n",
    "        start1 = [ts1[ts1 >= T][idx_1[0]], ts2[ts2 >= T][idx_1[1]]]\n",
    "\n",
    "        X_2 = np.concatenate((fA[start2[0],0],fA[start2[1],1],fD[start2[0],0],fD[start2[1],1])).reshape(1, -1)\n",
    "        X_1 = np.concatenate((fA[start1[0],0],fA[start1[1],1],fD[start1[0],0],fD[start1[1],1])).reshape(1, -1)\n",
    "\n",
    "        y2 = model2.predict(X_2, verbose = 0)[0]\n",
    "        yA2 = y2[0]\n",
    "        yD2 = y2[1]\n",
    "\n",
    "        y1 = model1.predict(X_1, verbose = 0)[0]\n",
    "        yA1 = y1[0]\n",
    "        yD1 = y1[1]\n",
    "\n",
    "        pred = assemble(position, yA2, yD2, yD1)\n",
    "\n",
    "        predictions.append(pred)\n",
    "\n",
    "        update_models += 1\n",
    "\n",
    "        if update_models % batch_size == 0:\n",
    "            \n",
    "            iteration += 1\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_amount = int(np.floor(test_size/batch_size))\n",
    "\n",
    "adjusting_models = {}\n",
    "\n",
    "for scale in range(1,3):\n",
    "\n",
    "    scale_models = {}\n",
    "    \n",
    "    for iteration in range(1,update_amount+2):\n",
    "    \n",
    "        scale_models[iteration] = load_model(f'Adaptive_tuning/trial_{trial}/Reg_{scale}/iter_{iteration}/model_{iteration}.h5')\n",
    "    \n",
    "    adjusting_models[scale] = scale_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  4.223757893270135\n",
      "MAE =  1.5572646190222963\n",
      "R2 =  0.6712365284573909\n"
     ]
    }
   ],
   "source": [
    "preds = mfndnn(adjusting_models, num_lags_dict, batch_size)\n",
    "print(\"MSE = \", mean_squared_error(r_test, preds))\n",
    "print(\"MAE = \", mean_absolute_error(r_test, preds))\n",
    "print(\"R2 = \", r2_score(r_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current update size is 520 and current scale is 1\n",
      "Current update size is 476 and current scale is 1\n",
      "New model 2 performs better\n",
      "Current update size is 432 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 388 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 344 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 300 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 256 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 212 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 168 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 124 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 80 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 36 and current scale is 1\n",
      "Old model 2 performs better\n",
      "Current update size is 520 and current scale is 2\n",
      "Current update size is 476 and current scale is 2\n",
      "New model 2 performs better\n",
      "Current update size is 432 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 388 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 344 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 300 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 256 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 212 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 168 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 124 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 80 and current scale is 2\n",
      "Old model 2 performs better\n",
      "Current update size is 36 and current scale is 2\n",
      "Old model 2 performs better\n"
     ]
    }
   ],
   "source": [
    "# Check performance within a scale or scales\n",
    "performances = []\n",
    "model_indices = []\n",
    "\n",
    "for i in range(1,3):\n",
    "\n",
    "    performance_j = np.array([])\n",
    "\n",
    "    yd = np.flip(Reg_data_dict[i]['D'][:,0])\n",
    "    Xd = np.flip(Reg_data_dict[i]['D'][:,1:],0)\n",
    "    ya = np.flip(Reg_data_dict[i]['A'][:,0])\n",
    "    Xa = np.flip(Reg_data_dict[i]['A'][:,1:],0)\n",
    "\n",
    "    X = np.column_stack((Xa,Xd))\n",
    "    y = np.column_stack((ya,yd))\n",
    "\n",
    "    update_size = test_size\n",
    "    iteration = 1\n",
    "\n",
    "    previous_model = adjusting_models[i][iteration]\n",
    "\n",
    "    model_iter_counter = []\n",
    "\n",
    "    model_idx = 1\n",
    "    \n",
    "    while update_size > 0:\n",
    "\n",
    "        print(f\"Current update size is {update_size} and current scale is {i}\")\n",
    "\n",
    "        train_size = int(len(ya) - update_size/(2**i))\n",
    "        val_size = np.floor(train_size * validation_ratio).astype(int)\n",
    "\n",
    "        X_train, X_test = X[:train_size,:], X[train_size:,:]\n",
    "        y_train, y_test = y[:train_size,:], y[train_size:,:]\n",
    "\n",
    "        X_val, y_val = X_train[-val_size:,:], y_train[-val_size:,:]\n",
    "        X_train, y_train = X_train[:-val_size,:], y_train[:-val_size,:]\n",
    "\n",
    "        new_model = adjusting_models[i][iteration]\n",
    "        new_val_preds = new_model.predict(X_val, verbose = 0)\n",
    "        new_mse = mean_squared_error(y_val, new_val_preds)\n",
    "\n",
    "        if iteration == 1:\n",
    "            performance_j = np.append(performance_j, new_mse)\n",
    "            model_iter_counter.append([iteration, iteration])\n",
    "\n",
    "        if iteration > 1:\n",
    "\n",
    "            old_val_preds = previous_model.predict(X_val, verbose = 0)\n",
    "            old_mse = mean_squared_error(y_val, old_val_preds)\n",
    "\n",
    "            if old_mse < new_mse:\n",
    "\n",
    "                performance_j = np.append(performance_j, old_mse)\n",
    "\n",
    "                model_iter_counter.append([iteration, model_idx])\n",
    "\n",
    "                print(f\"Old model {model_idx} performs better\")\n",
    "\n",
    "            else: \n",
    "\n",
    "                performance_j = np.append(performance_j, new_mse)\n",
    "\n",
    "                previous_model = new_model\n",
    "\n",
    "                model_idx = iteration\n",
    "\n",
    "                model_iter_counter.append([iteration, iteration])\n",
    "\n",
    "                print(f\"New model {iteration} performs better\")\n",
    "\n",
    "        update_size = update_size - batch_size\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "    performances.append(performance_j)\n",
    "    model_indices.append(model_iter_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusting_mfndnn(adjusting_models, num_lags_dict, model_indices, batch_size, r_test = r_test):\n",
    "\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    update_models = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    for k in range(len(r_test),0,-1):\n",
    "\n",
    "        T = k                              # Current day\n",
    "        t = T-1                            # Next day (The one we make the prediction for)\n",
    "\n",
    "        stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "        stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "        reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "        position = t - reconstruct_from[-1] # 0 to 3 (The position explained in the thesis)\n",
    "\n",
    "        model_index_1 = model_indices[0][iteration-1][1]\n",
    "        model1 = adjusting_models[1][model_index_1]\n",
    "        \n",
    "        model_index_2 = model_indices[1][iteration-1][1]\n",
    "        model2 = adjusting_models[2][model_index_2]\n",
    "\n",
    "        idx_2 = [np.arange(0,num_lags_dict[2][0]),np.arange(0,num_lags_dict[2][1])]\n",
    "        idx_1 = [np.arange(0,num_lags_dict[1][0]),np.arange(0,num_lags_dict[1][1])]\n",
    "\n",
    "        start2 = [ts1[ts1 >= T][idx_2[0]], ts2[ts2 >= T][idx_2[1]]]\n",
    "        start1 = [ts1[ts1 >= T][idx_1[0]], ts2[ts2 >= T][idx_1[1]]]\n",
    "\n",
    "        X_2 = np.concatenate((fA[start2[0],0],fA[start2[1],1],fD[start2[0],0],fD[start2[1],1])).reshape(1, -1)\n",
    "        X_1 = np.concatenate((fA[start1[0],0],fA[start1[1],1],fD[start1[0],0],fD[start1[1],1])).reshape(1, -1)\n",
    "\n",
    "        y2 = model2.predict(X_2, verbose = 0)[0]\n",
    "        yA2 = y2[0]\n",
    "        yD2 = y2[1]\n",
    "\n",
    "        y1 = model1.predict(X_1, verbose = 0)[0]\n",
    "        yA1 = y1[0]\n",
    "        yD1 = y1[1]\n",
    "\n",
    "        pred = assemble(position, yA2, yD2, yD1)\n",
    "\n",
    "        predictions.append(pred)\n",
    "\n",
    "        update_models += 1\n",
    "\n",
    "        if update_models % batch_size == 0:\n",
    "            \n",
    "            iteration += 1\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE =  4.009067896091015\n",
      "MAE =  1.4903368263090704\n",
      "R2 =  0.6879472942166078\n"
     ]
    }
   ],
   "source": [
    "preds = adjusting_mfndnn(adjusting_models, num_lags_dict, model_indices, batch_size, r_test = r_test)\n",
    "print(\"MSE = \", mean_squared_error(r_test, preds))\n",
    "print(\"MAE = \", mean_absolute_error(r_test, preds))\n",
    "print(\"R2 = \", r2_score(r_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H-steps ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhfnn(t, T, info, adjusting_models, num_lags_dict):\n",
    "\n",
    "    u_fA = info[2]\n",
    "    u_fD = info[3]\n",
    "    # Out-of-sample predictions\n",
    "\n",
    "    stop2 = ts2[ts2 <= t][-1]          # The index for the wavelet (j=2) that is needed for the reconstruction\n",
    "    stop1 = ts1[ts1 <= t][-1]\n",
    "\n",
    "    reconstruct_from = [stop1, stop2] # Wavelet indices (that correspond to the original rv timeseries)\n",
    "\n",
    "    check = [0,0] # Check variable records whether information is already available from previous forecasts or not, if 1 then the prediction for that scale doesnt have to be performed.\n",
    "\n",
    "    if info[0][0] != None:\n",
    "        if stop1 >= info[0][0]:\n",
    "            check[0] = 1\n",
    "\n",
    "    if info[1][0] != None:\n",
    "        if stop2 >= info[1][0]:\n",
    "            check[1] = 1\n",
    "\n",
    "    model1 = adjusting_models[1]\n",
    "    model2 = adjusting_models[2]\n",
    "\n",
    "    idx_2 = [np.arange(0,num_lags_dict[2][0]),np.arange(0,num_lags_dict[2][1])]\n",
    "    idx_1 = [np.arange(0,num_lags_dict[1][0]),np.arange(0,num_lags_dict[1][1])]\n",
    "\n",
    "    if check[0] == 0: # The prediction has to be made as info is available\n",
    "\n",
    "        start1 = [ts1[ts1 >= T][idx_1[0]], ts2[ts2 >= T][idx_1[1]]]\n",
    "        X_1 = np.concatenate((u_fA[start1[0],0],u_fA[start1[1],1],u_fD[start1[0],0],u_fD[start1[1],1])).reshape(1, -1)\n",
    "\n",
    "        y1 = model1.predict(X_1, verbose = 0)[0]\n",
    "        yA1 = y1[0]\n",
    "        yD1 = y1[1]\n",
    "\n",
    "    else:\n",
    "        yA1, yD1 = info[0][1]\n",
    "\n",
    "    if check[1] == 0:\n",
    "\n",
    "        start2 = [ts1[ts1 >= T][idx_2[0]], ts2[ts2 >= T][idx_2[1]]]\n",
    "        X_2 = np.concatenate((u_fA[start2[0],0],u_fA[start2[1],1],u_fD[start2[0],0],u_fD[start2[1],1])).reshape(1, -1)\n",
    "        y2 = model2.predict(X_2, verbose = 0)[0]\n",
    "        yA2 = y2[0]\n",
    "        yD2 = y2[1]\n",
    "\n",
    "    else:\n",
    "        yA2, yD2 = info[1][1]\n",
    "\n",
    "    return yA2, yD2, yA1, yD1, reconstruct_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_amount = int(np.floor(test_size/batch_size))\n",
    "\n",
    "models = {}\n",
    "\n",
    "for scale in range(1,3):\n",
    "\n",
    "    scale_models = {}\n",
    "    \n",
    "    for iteration in range(1,update_amount+2):\n",
    "    \n",
    "        scale_models[iteration] = load_model(f'Adaptive_tuning/trial_{trial}/Reg_{scale}/iter_{iteration}/model_{iteration}.h5')\n",
    "    \n",
    "    models[scale] = scale_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizons = [1,5,20,60]\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for horizon in horizons:\n",
    "\n",
    "    forecasts_size = test_size - horizon + 1\n",
    "\n",
    "    horizon_forecasts = []\n",
    "\n",
    "    update_counter = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    adjusting_models = {1:models[1][iteration],2:models[2][iteration]}\n",
    "\n",
    "    for j in range(forecasts_size-1, -1, -1):\n",
    "\n",
    "        pred_obs = j\n",
    "        current_time = pred_obs + horizon # latest available information\n",
    "        to_predict = np.flip(np.arange(pred_obs, current_time))\n",
    "\n",
    "        updated_fA = np.copy(fA)\n",
    "        updated_fD = np.copy(fD)\n",
    "\n",
    "        updated_time = np.copy(current_time)\n",
    "\n",
    "        coef_pick_decision = [[None,None], [None,None], updated_fA, updated_fD]\n",
    "\n",
    "        for i in range(len(to_predict)):\n",
    "\n",
    "            predict = to_predict[i]\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhfnn(predict, current_time, [[None,None], [None,None], fA, fD],adjusting_models, num_lags_dict)\n",
    "\n",
    "            if i != 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhfnn(predict, updated_time, coef_pick_decision, adjusting_models, num_lags_dict)\n",
    "\n",
    "            updated_fA[reconstruct_from[0],0], updated_fD[reconstruct_from[0],0] = a1,d1\n",
    "            updated_fA[reconstruct_from[1],1], updated_fD[reconstruct_from[1],1] = a2,d2\n",
    "            coef_pick_decision[2], coef_pick_decision[3] = updated_fA, updated_fD\n",
    "            coef_pick_decision[0][0], coef_pick_decision[1][0] = reconstruct_from[0], reconstruct_from[1]\n",
    "            coef_pick_decision[0][1] = [a1,d1]\n",
    "            coef_pick_decision[1][1] = [a2,d2]\n",
    "            updated_time = updated_time - 1\n",
    "\n",
    "        position = pred_obs - coef_pick_decision[1][0]\n",
    "        pred = assemble(position, coef_pick_decision[1][1][0], coef_pick_decision[1][1][1], coef_pick_decision[0][1][1])\n",
    "        horizon_forecasts.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            adjusting_models = {1:models[1][iteration],2:models[2][iteration]}\n",
    "\n",
    "    all_predictions.append(horizon_forecasts)\n",
    "\n",
    "    lm_save_path = f'prediction/no_decimation_multistep_nn_{horizon}.pkl'\n",
    "\n",
    "    os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "    print(f'Done with horizon {horizon}')\n",
    "    print(mean_squared_error(r_test[horizon-1:],horizon_forecasts))\n",
    "\n",
    "    with open(lm_save_path, 'wb') as file:\n",
    "        pickle.dump(horizon_forecasts, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting obs 519\n",
      "predicting obs 518\n",
      "predicting obs 517\n",
      "predicting obs 516\n",
      "predicting obs 515\n",
      "predicting obs 514\n",
      "predicting obs 513\n",
      "predicting obs 512\n",
      "predicting obs 511\n",
      "predicting obs 510\n",
      "predicting obs 509\n",
      "predicting obs 508\n",
      "predicting obs 507\n",
      "predicting obs 506\n",
      "predicting obs 505\n",
      "predicting obs 504\n",
      "predicting obs 503\n",
      "predicting obs 502\n",
      "predicting obs 501\n",
      "predicting obs 500\n",
      "predicting obs 499\n",
      "predicting obs 498\n",
      "predicting obs 497\n",
      "predicting obs 496\n",
      "predicting obs 495\n",
      "predicting obs 494\n",
      "predicting obs 493\n",
      "predicting obs 492\n",
      "predicting obs 491\n",
      "predicting obs 490\n",
      "predicting obs 489\n",
      "predicting obs 488\n",
      "predicting obs 487\n",
      "predicting obs 486\n",
      "predicting obs 485\n",
      "predicting obs 484\n",
      "predicting obs 483\n",
      "predicting obs 482\n",
      "predicting obs 481\n",
      "predicting obs 480\n",
      "predicting obs 479\n",
      "predicting obs 478\n",
      "predicting obs 477\n",
      "predicting obs 476\n",
      "predicting obs 475\n",
      "predicting obs 474\n",
      "predicting obs 473\n",
      "predicting obs 472\n",
      "predicting obs 471\n",
      "predicting obs 470\n",
      "predicting obs 469\n",
      "predicting obs 468\n",
      "predicting obs 467\n",
      "predicting obs 466\n",
      "predicting obs 465\n",
      "predicting obs 464\n",
      "predicting obs 463\n",
      "predicting obs 462\n",
      "predicting obs 461\n",
      "predicting obs 460\n",
      "predicting obs 459\n",
      "predicting obs 458\n",
      "predicting obs 457\n",
      "predicting obs 456\n",
      "predicting obs 455\n",
      "predicting obs 454\n",
      "predicting obs 453\n",
      "predicting obs 452\n",
      "predicting obs 451\n",
      "predicting obs 450\n",
      "predicting obs 449\n",
      "predicting obs 448\n",
      "predicting obs 447\n",
      "predicting obs 446\n",
      "predicting obs 445\n",
      "predicting obs 444\n",
      "predicting obs 443\n",
      "predicting obs 442\n",
      "predicting obs 441\n",
      "predicting obs 440\n",
      "predicting obs 439\n",
      "predicting obs 438\n",
      "predicting obs 437\n",
      "predicting obs 436\n",
      "predicting obs 435\n",
      "predicting obs 434\n",
      "predicting obs 433\n",
      "predicting obs 432\n",
      "predicting obs 431\n",
      "predicting obs 430\n",
      "predicting obs 429\n",
      "predicting obs 428\n",
      "predicting obs 427\n",
      "predicting obs 426\n",
      "predicting obs 425\n",
      "predicting obs 424\n",
      "predicting obs 423\n",
      "predicting obs 422\n",
      "predicting obs 421\n",
      "predicting obs 420\n",
      "predicting obs 419\n",
      "predicting obs 418\n",
      "predicting obs 417\n",
      "predicting obs 416\n",
      "predicting obs 415\n",
      "predicting obs 414\n",
      "predicting obs 413\n",
      "predicting obs 412\n",
      "predicting obs 411\n",
      "predicting obs 410\n",
      "predicting obs 409\n",
      "predicting obs 408\n",
      "predicting obs 407\n",
      "predicting obs 406\n",
      "predicting obs 405\n",
      "predicting obs 404\n",
      "predicting obs 403\n",
      "predicting obs 402\n",
      "predicting obs 401\n",
      "predicting obs 400\n",
      "predicting obs 399\n",
      "predicting obs 398\n",
      "predicting obs 397\n",
      "predicting obs 396\n",
      "predicting obs 395\n",
      "predicting obs 394\n",
      "predicting obs 393\n",
      "predicting obs 392\n",
      "predicting obs 391\n",
      "predicting obs 390\n",
      "predicting obs 389\n",
      "predicting obs 388\n",
      "predicting obs 387\n",
      "predicting obs 386\n",
      "predicting obs 385\n",
      "predicting obs 384\n",
      "predicting obs 383\n",
      "predicting obs 382\n",
      "predicting obs 381\n",
      "predicting obs 380\n",
      "predicting obs 379\n",
      "predicting obs 378\n",
      "predicting obs 377\n",
      "predicting obs 376\n",
      "predicting obs 375\n",
      "predicting obs 374\n",
      "predicting obs 373\n",
      "predicting obs 372\n",
      "predicting obs 371\n",
      "predicting obs 370\n",
      "predicting obs 369\n",
      "predicting obs 368\n",
      "predicting obs 367\n",
      "predicting obs 366\n",
      "predicting obs 365\n",
      "predicting obs 364\n",
      "predicting obs 363\n",
      "predicting obs 362\n",
      "predicting obs 361\n",
      "predicting obs 360\n",
      "predicting obs 359\n",
      "predicting obs 358\n",
      "predicting obs 357\n",
      "predicting obs 356\n",
      "predicting obs 355\n",
      "predicting obs 354\n",
      "predicting obs 353\n",
      "predicting obs 352\n",
      "predicting obs 351\n",
      "predicting obs 350\n",
      "predicting obs 349\n",
      "predicting obs 348\n",
      "predicting obs 347\n",
      "predicting obs 346\n",
      "predicting obs 345\n",
      "predicting obs 344\n",
      "predicting obs 343\n",
      "predicting obs 342\n",
      "predicting obs 341\n",
      "predicting obs 340\n",
      "predicting obs 339\n",
      "predicting obs 338\n",
      "predicting obs 337\n",
      "predicting obs 336\n",
      "predicting obs 335\n",
      "predicting obs 334\n",
      "predicting obs 333\n",
      "predicting obs 332\n",
      "predicting obs 331\n",
      "predicting obs 330\n",
      "predicting obs 329\n",
      "predicting obs 328\n",
      "predicting obs 327\n",
      "predicting obs 326\n",
      "predicting obs 325\n",
      "predicting obs 324\n",
      "predicting obs 323\n",
      "predicting obs 322\n",
      "predicting obs 321\n",
      "predicting obs 320\n",
      "predicting obs 319\n",
      "predicting obs 318\n",
      "predicting obs 317\n",
      "predicting obs 316\n",
      "predicting obs 315\n",
      "predicting obs 314\n",
      "predicting obs 313\n",
      "predicting obs 312\n",
      "predicting obs 311\n",
      "predicting obs 310\n",
      "predicting obs 309\n",
      "predicting obs 308\n",
      "predicting obs 307\n",
      "predicting obs 306\n",
      "predicting obs 305\n",
      "predicting obs 304\n",
      "predicting obs 303\n",
      "predicting obs 302\n",
      "predicting obs 301\n",
      "predicting obs 300\n",
      "predicting obs 299\n",
      "predicting obs 298\n",
      "predicting obs 297\n",
      "predicting obs 296\n",
      "predicting obs 295\n",
      "predicting obs 294\n",
      "predicting obs 293\n",
      "predicting obs 292\n",
      "predicting obs 291\n",
      "predicting obs 290\n",
      "predicting obs 289\n",
      "predicting obs 288\n",
      "predicting obs 287\n",
      "predicting obs 286\n",
      "predicting obs 285\n",
      "predicting obs 284\n",
      "predicting obs 283\n",
      "predicting obs 282\n",
      "predicting obs 281\n",
      "predicting obs 280\n",
      "predicting obs 279\n",
      "predicting obs 278\n",
      "predicting obs 277\n",
      "predicting obs 276\n",
      "predicting obs 275\n",
      "predicting obs 274\n",
      "predicting obs 273\n",
      "predicting obs 272\n",
      "predicting obs 271\n",
      "predicting obs 270\n",
      "predicting obs 269\n",
      "predicting obs 268\n",
      "predicting obs 267\n",
      "predicting obs 266\n",
      "predicting obs 265\n",
      "predicting obs 264\n",
      "predicting obs 263\n",
      "predicting obs 262\n",
      "predicting obs 261\n",
      "predicting obs 260\n",
      "predicting obs 259\n",
      "predicting obs 258\n",
      "predicting obs 257\n",
      "predicting obs 256\n",
      "predicting obs 255\n",
      "predicting obs 254\n",
      "predicting obs 253\n",
      "predicting obs 252\n",
      "predicting obs 251\n",
      "predicting obs 250\n",
      "predicting obs 249\n",
      "predicting obs 248\n",
      "predicting obs 247\n",
      "predicting obs 246\n",
      "predicting obs 245\n",
      "predicting obs 244\n",
      "predicting obs 243\n",
      "predicting obs 242\n",
      "predicting obs 241\n",
      "predicting obs 240\n",
      "predicting obs 239\n",
      "predicting obs 238\n",
      "predicting obs 237\n",
      "predicting obs 236\n",
      "predicting obs 235\n",
      "predicting obs 234\n",
      "predicting obs 233\n",
      "predicting obs 232\n",
      "predicting obs 231\n",
      "predicting obs 230\n",
      "predicting obs 229\n",
      "predicting obs 228\n",
      "predicting obs 227\n",
      "predicting obs 226\n",
      "predicting obs 225\n",
      "predicting obs 224\n",
      "predicting obs 223\n",
      "predicting obs 222\n",
      "predicting obs 221\n",
      "predicting obs 220\n",
      "predicting obs 219\n",
      "predicting obs 218\n",
      "predicting obs 217\n",
      "predicting obs 216\n",
      "predicting obs 215\n",
      "predicting obs 214\n",
      "predicting obs 213\n",
      "predicting obs 212\n",
      "predicting obs 211\n",
      "predicting obs 210\n",
      "predicting obs 209\n",
      "predicting obs 208\n",
      "predicting obs 207\n",
      "predicting obs 206\n",
      "predicting obs 205\n",
      "predicting obs 204\n",
      "predicting obs 203\n",
      "predicting obs 202\n",
      "predicting obs 201\n",
      "predicting obs 200\n",
      "predicting obs 199\n",
      "predicting obs 198\n",
      "predicting obs 197\n",
      "predicting obs 196\n",
      "predicting obs 195\n",
      "predicting obs 194\n",
      "predicting obs 193\n",
      "predicting obs 192\n",
      "predicting obs 191\n",
      "predicting obs 190\n",
      "predicting obs 189\n",
      "predicting obs 188\n",
      "predicting obs 187\n",
      "predicting obs 186\n",
      "predicting obs 185\n",
      "predicting obs 184\n",
      "predicting obs 183\n",
      "predicting obs 182\n",
      "predicting obs 181\n",
      "predicting obs 180\n",
      "predicting obs 179\n",
      "predicting obs 178\n",
      "predicting obs 177\n",
      "predicting obs 176\n",
      "predicting obs 175\n",
      "predicting obs 174\n",
      "predicting obs 173\n",
      "predicting obs 172\n",
      "predicting obs 171\n",
      "predicting obs 170\n",
      "predicting obs 169\n",
      "predicting obs 168\n",
      "predicting obs 167\n",
      "predicting obs 166\n",
      "predicting obs 165\n",
      "predicting obs 164\n",
      "predicting obs 163\n",
      "predicting obs 162\n",
      "predicting obs 161\n",
      "predicting obs 160\n",
      "predicting obs 159\n",
      "predicting obs 158\n",
      "predicting obs 157\n",
      "predicting obs 156\n",
      "predicting obs 155\n",
      "predicting obs 154\n",
      "predicting obs 153\n",
      "predicting obs 152\n",
      "predicting obs 151\n",
      "predicting obs 150\n",
      "predicting obs 149\n",
      "predicting obs 148\n",
      "predicting obs 147\n",
      "predicting obs 146\n",
      "predicting obs 145\n",
      "predicting obs 144\n",
      "predicting obs 143\n",
      "predicting obs 142\n",
      "predicting obs 141\n",
      "predicting obs 140\n",
      "predicting obs 139\n",
      "predicting obs 138\n",
      "predicting obs 137\n",
      "predicting obs 136\n",
      "predicting obs 135\n",
      "predicting obs 134\n",
      "predicting obs 133\n",
      "predicting obs 132\n",
      "predicting obs 131\n",
      "predicting obs 130\n",
      "predicting obs 129\n",
      "predicting obs 128\n",
      "predicting obs 127\n",
      "predicting obs 126\n",
      "predicting obs 125\n",
      "predicting obs 124\n",
      "predicting obs 123\n",
      "predicting obs 122\n",
      "predicting obs 121\n",
      "predicting obs 120\n",
      "predicting obs 119\n",
      "predicting obs 118\n",
      "predicting obs 117\n",
      "predicting obs 116\n",
      "predicting obs 115\n",
      "predicting obs 114\n",
      "predicting obs 113\n",
      "predicting obs 112\n",
      "predicting obs 111\n",
      "predicting obs 110\n",
      "predicting obs 109\n",
      "predicting obs 108\n",
      "predicting obs 107\n",
      "predicting obs 106\n",
      "predicting obs 105\n",
      "predicting obs 104\n",
      "predicting obs 103\n",
      "predicting obs 102\n",
      "predicting obs 101\n",
      "predicting obs 100\n",
      "predicting obs 99\n",
      "predicting obs 98\n",
      "predicting obs 97\n",
      "predicting obs 96\n",
      "predicting obs 95\n",
      "predicting obs 94\n",
      "predicting obs 93\n",
      "predicting obs 92\n",
      "predicting obs 91\n",
      "predicting obs 90\n",
      "predicting obs 89\n",
      "predicting obs 88\n",
      "predicting obs 87\n",
      "predicting obs 86\n",
      "predicting obs 85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting obs 84\n",
      "predicting obs 83\n",
      "predicting obs 82\n",
      "predicting obs 81\n",
      "predicting obs 80\n",
      "predicting obs 79\n",
      "predicting obs 78\n",
      "predicting obs 77\n",
      "predicting obs 76\n",
      "predicting obs 75\n",
      "predicting obs 74\n",
      "predicting obs 73\n",
      "predicting obs 72\n",
      "predicting obs 71\n",
      "predicting obs 70\n",
      "predicting obs 69\n",
      "predicting obs 68\n",
      "predicting obs 67\n",
      "predicting obs 66\n",
      "predicting obs 65\n",
      "predicting obs 64\n",
      "predicting obs 63\n",
      "predicting obs 62\n",
      "predicting obs 61\n",
      "predicting obs 60\n",
      "predicting obs 59\n",
      "predicting obs 58\n",
      "predicting obs 57\n",
      "predicting obs 56\n",
      "predicting obs 55\n",
      "predicting obs 54\n",
      "predicting obs 53\n",
      "predicting obs 52\n",
      "predicting obs 51\n",
      "predicting obs 50\n",
      "predicting obs 49\n",
      "predicting obs 48\n",
      "predicting obs 47\n",
      "predicting obs 46\n",
      "predicting obs 45\n",
      "predicting obs 44\n",
      "predicting obs 43\n",
      "predicting obs 42\n",
      "predicting obs 41\n",
      "predicting obs 40\n",
      "predicting obs 39\n",
      "predicting obs 38\n",
      "predicting obs 37\n",
      "predicting obs 36\n",
      "predicting obs 35\n",
      "predicting obs 34\n",
      "predicting obs 33\n",
      "predicting obs 32\n",
      "predicting obs 31\n",
      "predicting obs 30\n",
      "predicting obs 29\n",
      "predicting obs 28\n",
      "predicting obs 27\n",
      "predicting obs 26\n",
      "predicting obs 25\n",
      "predicting obs 24\n",
      "predicting obs 23\n",
      "predicting obs 22\n",
      "predicting obs 21\n",
      "predicting obs 20\n",
      "predicting obs 19\n",
      "predicting obs 18\n",
      "predicting obs 17\n",
      "predicting obs 16\n",
      "predicting obs 15\n",
      "predicting obs 14\n",
      "predicting obs 13\n",
      "predicting obs 12\n",
      "predicting obs 11\n",
      "predicting obs 10\n",
      "predicting obs 9\n",
      "predicting obs 8\n",
      "predicting obs 7\n",
      "predicting obs 6\n",
      "predicting obs 5\n",
      "predicting obs 4\n",
      "predicting obs 3\n",
      "predicting obs 2\n",
      "predicting obs 1\n",
      "predicting obs 0\n",
      "520\n",
      "predicting obs 515\n",
      "predicting obs 514\n",
      "predicting obs 513\n",
      "predicting obs 512\n",
      "predicting obs 511\n",
      "predicting obs 510\n",
      "predicting obs 509\n",
      "predicting obs 508\n",
      "predicting obs 507\n",
      "predicting obs 506\n",
      "predicting obs 505\n",
      "predicting obs 504\n",
      "predicting obs 503\n",
      "predicting obs 502\n",
      "predicting obs 501\n",
      "predicting obs 500\n",
      "predicting obs 499\n",
      "predicting obs 498\n",
      "predicting obs 497\n",
      "predicting obs 496\n",
      "predicting obs 495\n",
      "predicting obs 494\n",
      "predicting obs 493\n",
      "predicting obs 492\n",
      "predicting obs 491\n",
      "predicting obs 490\n",
      "predicting obs 489\n",
      "predicting obs 488\n",
      "predicting obs 487\n",
      "predicting obs 486\n",
      "predicting obs 485\n",
      "predicting obs 484\n",
      "predicting obs 483\n",
      "predicting obs 482\n",
      "predicting obs 481\n",
      "predicting obs 480\n",
      "predicting obs 479\n",
      "predicting obs 478\n",
      "predicting obs 477\n",
      "predicting obs 476\n",
      "predicting obs 475\n",
      "predicting obs 474\n",
      "predicting obs 473\n",
      "predicting obs 472\n",
      "predicting obs 471\n",
      "predicting obs 470\n",
      "predicting obs 469\n",
      "predicting obs 468\n",
      "predicting obs 467\n",
      "predicting obs 466\n",
      "predicting obs 465\n",
      "predicting obs 464\n",
      "predicting obs 463\n",
      "predicting obs 462\n",
      "predicting obs 461\n",
      "predicting obs 460\n",
      "predicting obs 459\n",
      "predicting obs 458\n",
      "predicting obs 457\n",
      "predicting obs 456\n",
      "predicting obs 455\n",
      "predicting obs 454\n",
      "predicting obs 453\n",
      "predicting obs 452\n",
      "predicting obs 451\n",
      "predicting obs 450\n",
      "predicting obs 449\n",
      "predicting obs 448\n",
      "predicting obs 447\n",
      "predicting obs 446\n",
      "predicting obs 445\n",
      "predicting obs 444\n",
      "predicting obs 443\n",
      "predicting obs 442\n",
      "predicting obs 441\n",
      "predicting obs 440\n",
      "predicting obs 439\n",
      "predicting obs 438\n",
      "predicting obs 437\n",
      "predicting obs 436\n",
      "predicting obs 435\n",
      "predicting obs 434\n",
      "predicting obs 433\n",
      "predicting obs 432\n",
      "predicting obs 431\n",
      "predicting obs 430\n",
      "predicting obs 429\n",
      "predicting obs 428\n",
      "predicting obs 427\n",
      "predicting obs 426\n",
      "predicting obs 425\n",
      "predicting obs 424\n",
      "predicting obs 423\n",
      "predicting obs 422\n",
      "predicting obs 421\n",
      "predicting obs 420\n",
      "predicting obs 419\n",
      "predicting obs 418\n",
      "predicting obs 417\n",
      "predicting obs 416\n",
      "predicting obs 415\n",
      "predicting obs 414\n",
      "predicting obs 413\n",
      "predicting obs 412\n",
      "predicting obs 411\n",
      "predicting obs 410\n",
      "predicting obs 409\n",
      "predicting obs 408\n",
      "predicting obs 407\n",
      "predicting obs 406\n",
      "predicting obs 405\n",
      "predicting obs 404\n",
      "predicting obs 403\n",
      "predicting obs 402\n",
      "predicting obs 401\n",
      "predicting obs 400\n",
      "predicting obs 399\n",
      "predicting obs 398\n",
      "predicting obs 397\n",
      "predicting obs 396\n",
      "predicting obs 395\n",
      "predicting obs 394\n",
      "predicting obs 393\n",
      "predicting obs 392\n",
      "predicting obs 391\n",
      "predicting obs 390\n",
      "predicting obs 389\n",
      "predicting obs 388\n",
      "predicting obs 387\n",
      "predicting obs 386\n",
      "predicting obs 385\n",
      "predicting obs 384\n",
      "predicting obs 383\n",
      "predicting obs 382\n",
      "predicting obs 381\n",
      "predicting obs 380\n",
      "predicting obs 379\n",
      "predicting obs 378\n",
      "predicting obs 377\n",
      "predicting obs 376\n",
      "predicting obs 375\n",
      "predicting obs 374\n",
      "predicting obs 373\n",
      "predicting obs 372\n",
      "predicting obs 371\n",
      "predicting obs 370\n",
      "predicting obs 369\n",
      "predicting obs 368\n",
      "predicting obs 367\n",
      "predicting obs 366\n",
      "predicting obs 365\n",
      "predicting obs 364\n",
      "predicting obs 363\n",
      "predicting obs 362\n",
      "predicting obs 361\n",
      "predicting obs 360\n",
      "predicting obs 359\n",
      "predicting obs 358\n",
      "predicting obs 357\n",
      "predicting obs 356\n",
      "predicting obs 355\n",
      "predicting obs 354\n",
      "predicting obs 353\n",
      "predicting obs 352\n",
      "predicting obs 351\n",
      "predicting obs 350\n",
      "predicting obs 349\n",
      "predicting obs 348\n",
      "predicting obs 347\n",
      "predicting obs 346\n",
      "predicting obs 345\n",
      "predicting obs 344\n",
      "predicting obs 343\n",
      "predicting obs 342\n",
      "predicting obs 341\n",
      "predicting obs 340\n",
      "predicting obs 339\n",
      "predicting obs 338\n",
      "predicting obs 337\n",
      "predicting obs 336\n",
      "predicting obs 335\n",
      "predicting obs 334\n",
      "predicting obs 333\n",
      "predicting obs 332\n",
      "predicting obs 331\n",
      "predicting obs 330\n",
      "predicting obs 329\n",
      "predicting obs 328\n",
      "predicting obs 327\n",
      "predicting obs 326\n",
      "predicting obs 325\n",
      "predicting obs 324\n",
      "predicting obs 323\n",
      "predicting obs 322\n",
      "predicting obs 321\n",
      "predicting obs 320\n",
      "predicting obs 319\n",
      "predicting obs 318\n",
      "predicting obs 317\n",
      "predicting obs 316\n",
      "predicting obs 315\n",
      "predicting obs 314\n",
      "predicting obs 313\n",
      "predicting obs 312\n",
      "predicting obs 311\n",
      "predicting obs 310\n",
      "predicting obs 309\n",
      "predicting obs 308\n",
      "predicting obs 307\n",
      "predicting obs 306\n",
      "predicting obs 305\n",
      "predicting obs 304\n",
      "predicting obs 303\n",
      "predicting obs 302\n",
      "predicting obs 301\n",
      "predicting obs 300\n",
      "predicting obs 299\n",
      "predicting obs 298\n",
      "predicting obs 297\n",
      "predicting obs 296\n",
      "predicting obs 295\n",
      "predicting obs 294\n",
      "predicting obs 293\n",
      "predicting obs 292\n",
      "predicting obs 291\n",
      "predicting obs 290\n",
      "predicting obs 289\n",
      "predicting obs 288\n",
      "predicting obs 287\n",
      "predicting obs 286\n",
      "predicting obs 285\n",
      "predicting obs 284\n",
      "predicting obs 283\n",
      "predicting obs 282\n",
      "predicting obs 281\n",
      "predicting obs 280\n",
      "predicting obs 279\n",
      "predicting obs 278\n",
      "predicting obs 277\n",
      "predicting obs 276\n",
      "predicting obs 275\n",
      "predicting obs 274\n",
      "predicting obs 273\n",
      "predicting obs 272\n",
      "predicting obs 271\n",
      "predicting obs 270\n",
      "predicting obs 269\n",
      "predicting obs 268\n",
      "predicting obs 267\n",
      "predicting obs 266\n",
      "predicting obs 265\n",
      "predicting obs 264\n",
      "predicting obs 263\n",
      "predicting obs 262\n",
      "predicting obs 261\n",
      "predicting obs 260\n",
      "predicting obs 259\n",
      "predicting obs 258\n",
      "predicting obs 257\n",
      "predicting obs 256\n",
      "predicting obs 255\n",
      "predicting obs 254\n",
      "predicting obs 253\n",
      "predicting obs 252\n",
      "predicting obs 251\n",
      "predicting obs 250\n",
      "predicting obs 249\n",
      "predicting obs 248\n",
      "predicting obs 247\n",
      "predicting obs 246\n",
      "predicting obs 245\n",
      "predicting obs 244\n",
      "predicting obs 243\n",
      "predicting obs 242\n",
      "predicting obs 241\n",
      "predicting obs 240\n",
      "predicting obs 239\n",
      "predicting obs 238\n",
      "predicting obs 237\n",
      "predicting obs 236\n",
      "predicting obs 235\n",
      "predicting obs 234\n",
      "predicting obs 233\n",
      "predicting obs 232\n",
      "predicting obs 231\n",
      "predicting obs 230\n",
      "predicting obs 229\n",
      "predicting obs 228\n",
      "predicting obs 227\n",
      "predicting obs 226\n",
      "predicting obs 225\n",
      "predicting obs 224\n",
      "predicting obs 223\n",
      "predicting obs 222\n",
      "predicting obs 221\n",
      "predicting obs 220\n",
      "predicting obs 219\n",
      "predicting obs 218\n",
      "predicting obs 217\n",
      "predicting obs 216\n",
      "predicting obs 215\n",
      "predicting obs 214\n",
      "predicting obs 213\n",
      "predicting obs 212\n",
      "predicting obs 211\n",
      "predicting obs 210\n",
      "predicting obs 209\n",
      "predicting obs 208\n",
      "predicting obs 207\n",
      "predicting obs 206\n",
      "predicting obs 205\n",
      "predicting obs 204\n",
      "predicting obs 203\n",
      "predicting obs 202\n",
      "predicting obs 201\n",
      "predicting obs 200\n",
      "predicting obs 199\n",
      "predicting obs 198\n",
      "predicting obs 197\n",
      "predicting obs 196\n",
      "predicting obs 195\n",
      "predicting obs 194\n",
      "predicting obs 193\n",
      "predicting obs 192\n",
      "predicting obs 191\n",
      "predicting obs 190\n",
      "predicting obs 189\n",
      "predicting obs 188\n",
      "predicting obs 187\n",
      "predicting obs 186\n",
      "predicting obs 185\n",
      "predicting obs 184\n",
      "predicting obs 183\n",
      "predicting obs 182\n",
      "predicting obs 181\n",
      "predicting obs 180\n",
      "predicting obs 179\n",
      "predicting obs 178\n",
      "predicting obs 177\n",
      "predicting obs 176\n",
      "predicting obs 175\n",
      "predicting obs 174\n",
      "predicting obs 173\n",
      "predicting obs 172\n",
      "predicting obs 171\n",
      "predicting obs 170\n",
      "predicting obs 169\n",
      "predicting obs 168\n",
      "predicting obs 167\n",
      "predicting obs 166\n",
      "predicting obs 165\n",
      "predicting obs 164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting obs 163\n",
      "predicting obs 162\n",
      "predicting obs 161\n",
      "predicting obs 160\n",
      "predicting obs 159\n",
      "predicting obs 158\n",
      "predicting obs 157\n",
      "predicting obs 156\n",
      "predicting obs 155\n",
      "predicting obs 154\n",
      "predicting obs 153\n",
      "predicting obs 152\n",
      "predicting obs 151\n",
      "predicting obs 150\n",
      "predicting obs 149\n",
      "predicting obs 148\n",
      "predicting obs 147\n",
      "predicting obs 146\n",
      "predicting obs 145\n",
      "predicting obs 144\n",
      "predicting obs 143\n",
      "predicting obs 142\n",
      "predicting obs 141\n",
      "predicting obs 140\n",
      "predicting obs 139\n",
      "predicting obs 138\n",
      "predicting obs 137\n",
      "predicting obs 136\n",
      "predicting obs 135\n",
      "predicting obs 134\n",
      "predicting obs 133\n",
      "predicting obs 132\n",
      "predicting obs 131\n",
      "predicting obs 130\n",
      "predicting obs 129\n",
      "predicting obs 128\n",
      "predicting obs 127\n",
      "predicting obs 126\n",
      "predicting obs 125\n",
      "predicting obs 124\n",
      "predicting obs 123\n",
      "predicting obs 122\n",
      "predicting obs 121\n",
      "predicting obs 120\n",
      "predicting obs 119\n",
      "predicting obs 118\n",
      "predicting obs 117\n",
      "predicting obs 116\n",
      "predicting obs 115\n",
      "predicting obs 114\n",
      "predicting obs 113\n",
      "predicting obs 112\n",
      "predicting obs 111\n",
      "predicting obs 110\n",
      "predicting obs 109\n",
      "predicting obs 108\n",
      "predicting obs 107\n",
      "predicting obs 106\n",
      "predicting obs 105\n",
      "predicting obs 104\n",
      "predicting obs 103\n",
      "predicting obs 102\n",
      "predicting obs 101\n",
      "predicting obs 100\n",
      "predicting obs 99\n",
      "predicting obs 98\n",
      "predicting obs 97\n",
      "predicting obs 96\n",
      "predicting obs 95\n",
      "predicting obs 94\n",
      "predicting obs 93\n",
      "predicting obs 92\n",
      "predicting obs 91\n",
      "predicting obs 90\n",
      "predicting obs 89\n",
      "predicting obs 88\n",
      "predicting obs 87\n",
      "predicting obs 86\n",
      "predicting obs 85\n",
      "predicting obs 84\n",
      "predicting obs 83\n",
      "predicting obs 82\n",
      "predicting obs 81\n",
      "predicting obs 80\n",
      "predicting obs 79\n",
      "predicting obs 78\n",
      "predicting obs 77\n",
      "predicting obs 76\n",
      "predicting obs 75\n",
      "predicting obs 74\n",
      "predicting obs 73\n",
      "predicting obs 72\n",
      "predicting obs 71\n",
      "predicting obs 70\n",
      "predicting obs 69\n",
      "predicting obs 68\n",
      "predicting obs 67\n",
      "predicting obs 66\n",
      "predicting obs 65\n",
      "predicting obs 64\n",
      "predicting obs 63\n",
      "predicting obs 62\n",
      "predicting obs 61\n",
      "predicting obs 60\n",
      "predicting obs 59\n",
      "predicting obs 58\n",
      "predicting obs 57\n",
      "predicting obs 56\n",
      "predicting obs 55\n",
      "predicting obs 54\n",
      "predicting obs 53\n",
      "predicting obs 52\n",
      "predicting obs 51\n",
      "predicting obs 50\n",
      "predicting obs 49\n",
      "predicting obs 48\n",
      "predicting obs 47\n",
      "predicting obs 46\n",
      "predicting obs 45\n",
      "predicting obs 44\n",
      "predicting obs 43\n",
      "predicting obs 42\n",
      "predicting obs 41\n",
      "predicting obs 40\n",
      "predicting obs 39\n",
      "predicting obs 38\n",
      "predicting obs 37\n",
      "predicting obs 36\n",
      "predicting obs 35\n",
      "predicting obs 34\n",
      "predicting obs 33\n",
      "predicting obs 32\n",
      "predicting obs 31\n",
      "predicting obs 30\n",
      "predicting obs 29\n",
      "predicting obs 28\n",
      "predicting obs 27\n",
      "predicting obs 26\n",
      "predicting obs 25\n",
      "predicting obs 24\n",
      "predicting obs 23\n",
      "predicting obs 22\n",
      "predicting obs 21\n",
      "predicting obs 20\n",
      "predicting obs 19\n",
      "predicting obs 18\n",
      "predicting obs 17\n",
      "predicting obs 16\n",
      "predicting obs 15\n",
      "predicting obs 14\n",
      "predicting obs 13\n",
      "predicting obs 12\n",
      "predicting obs 11\n",
      "predicting obs 10\n",
      "predicting obs 9\n",
      "predicting obs 8\n",
      "predicting obs 7\n",
      "predicting obs 6\n",
      "predicting obs 5\n",
      "predicting obs 4\n",
      "predicting obs 3\n",
      "predicting obs 2\n",
      "predicting obs 1\n",
      "predicting obs 0\n",
      "516\n",
      "predicting obs 500\n",
      "predicting obs 499\n",
      "predicting obs 498\n",
      "predicting obs 497\n",
      "predicting obs 496\n",
      "predicting obs 495\n",
      "predicting obs 494\n",
      "predicting obs 493\n",
      "predicting obs 492\n",
      "predicting obs 491\n",
      "predicting obs 490\n",
      "predicting obs 489\n",
      "predicting obs 488\n",
      "predicting obs 487\n",
      "predicting obs 486\n",
      "predicting obs 485\n",
      "predicting obs 484\n",
      "predicting obs 483\n",
      "predicting obs 482\n",
      "predicting obs 481\n",
      "predicting obs 480\n",
      "predicting obs 479\n",
      "predicting obs 478\n",
      "predicting obs 477\n",
      "predicting obs 476\n",
      "predicting obs 475\n",
      "predicting obs 474\n",
      "predicting obs 473\n",
      "predicting obs 472\n",
      "predicting obs 471\n",
      "predicting obs 470\n",
      "predicting obs 469\n",
      "predicting obs 468\n",
      "predicting obs 467\n",
      "predicting obs 466\n",
      "predicting obs 465\n",
      "predicting obs 464\n",
      "predicting obs 463\n",
      "predicting obs 462\n",
      "predicting obs 461\n",
      "predicting obs 460\n",
      "predicting obs 459\n",
      "predicting obs 458\n",
      "predicting obs 457\n",
      "predicting obs 456\n",
      "predicting obs 455\n",
      "predicting obs 454\n",
      "predicting obs 453\n",
      "predicting obs 452\n",
      "predicting obs 451\n",
      "predicting obs 450\n",
      "predicting obs 449\n",
      "predicting obs 448\n",
      "predicting obs 447\n",
      "predicting obs 446\n",
      "predicting obs 445\n",
      "predicting obs 444\n",
      "predicting obs 443\n",
      "predicting obs 442\n",
      "predicting obs 441\n",
      "predicting obs 440\n",
      "predicting obs 439\n",
      "predicting obs 438\n",
      "predicting obs 437\n",
      "predicting obs 436\n",
      "predicting obs 435\n",
      "predicting obs 434\n",
      "predicting obs 433\n",
      "predicting obs 432\n",
      "predicting obs 431\n",
      "predicting obs 430\n",
      "predicting obs 429\n",
      "predicting obs 428\n",
      "predicting obs 427\n",
      "predicting obs 426\n",
      "predicting obs 425\n",
      "predicting obs 424\n",
      "predicting obs 423\n",
      "predicting obs 422\n",
      "predicting obs 421\n",
      "predicting obs 420\n",
      "predicting obs 419\n",
      "predicting obs 418\n",
      "predicting obs 417\n",
      "predicting obs 416\n",
      "predicting obs 415\n",
      "predicting obs 414\n",
      "predicting obs 413\n",
      "predicting obs 412\n",
      "predicting obs 411\n",
      "predicting obs 410\n",
      "predicting obs 409\n",
      "predicting obs 408\n",
      "predicting obs 407\n",
      "predicting obs 406\n",
      "predicting obs 405\n",
      "predicting obs 404\n",
      "predicting obs 403\n",
      "predicting obs 402\n",
      "predicting obs 401\n",
      "predicting obs 400\n",
      "predicting obs 399\n",
      "predicting obs 398\n",
      "predicting obs 397\n",
      "predicting obs 396\n",
      "predicting obs 395\n",
      "predicting obs 394\n",
      "predicting obs 393\n",
      "predicting obs 392\n",
      "predicting obs 391\n",
      "predicting obs 390\n",
      "predicting obs 389\n",
      "predicting obs 388\n",
      "predicting obs 387\n",
      "predicting obs 386\n",
      "predicting obs 385\n",
      "predicting obs 384\n",
      "predicting obs 383\n",
      "predicting obs 382\n",
      "predicting obs 381\n",
      "predicting obs 380\n",
      "predicting obs 379\n",
      "predicting obs 378\n",
      "predicting obs 377\n",
      "predicting obs 376\n",
      "predicting obs 375\n",
      "predicting obs 374\n",
      "predicting obs 373\n",
      "predicting obs 372\n",
      "predicting obs 371\n",
      "predicting obs 370\n",
      "predicting obs 369\n",
      "predicting obs 368\n",
      "predicting obs 367\n",
      "predicting obs 366\n",
      "predicting obs 365\n",
      "predicting obs 364\n",
      "predicting obs 363\n",
      "predicting obs 362\n",
      "predicting obs 361\n",
      "predicting obs 360\n",
      "predicting obs 359\n",
      "predicting obs 358\n",
      "predicting obs 357\n",
      "predicting obs 356\n",
      "predicting obs 355\n",
      "predicting obs 354\n",
      "predicting obs 353\n",
      "predicting obs 352\n",
      "predicting obs 351\n",
      "predicting obs 350\n",
      "predicting obs 349\n",
      "predicting obs 348\n",
      "predicting obs 347\n",
      "predicting obs 346\n",
      "predicting obs 345\n",
      "predicting obs 344\n",
      "predicting obs 343\n",
      "predicting obs 342\n",
      "predicting obs 341\n",
      "predicting obs 340\n",
      "predicting obs 339\n",
      "predicting obs 338\n",
      "predicting obs 337\n",
      "predicting obs 336\n",
      "predicting obs 335\n",
      "predicting obs 334\n",
      "predicting obs 333\n",
      "predicting obs 332\n",
      "predicting obs 331\n",
      "predicting obs 330\n",
      "predicting obs 329\n",
      "predicting obs 328\n",
      "predicting obs 327\n",
      "predicting obs 326\n",
      "predicting obs 325\n",
      "predicting obs 324\n",
      "predicting obs 323\n",
      "predicting obs 322\n",
      "predicting obs 321\n",
      "predicting obs 320\n",
      "predicting obs 319\n",
      "predicting obs 318\n",
      "predicting obs 317\n",
      "predicting obs 316\n",
      "predicting obs 315\n",
      "predicting obs 314\n",
      "predicting obs 313\n",
      "predicting obs 312\n",
      "predicting obs 311\n",
      "predicting obs 310\n",
      "predicting obs 309\n",
      "predicting obs 308\n",
      "predicting obs 307\n",
      "predicting obs 306\n",
      "predicting obs 305\n",
      "predicting obs 304\n",
      "predicting obs 303\n",
      "predicting obs 302\n",
      "predicting obs 301\n",
      "predicting obs 300\n",
      "predicting obs 299\n",
      "predicting obs 298\n",
      "predicting obs 297\n",
      "predicting obs 296\n",
      "predicting obs 295\n",
      "predicting obs 294\n",
      "predicting obs 293\n",
      "predicting obs 292\n",
      "predicting obs 291\n",
      "predicting obs 290\n",
      "predicting obs 289\n",
      "predicting obs 288\n",
      "predicting obs 287\n",
      "predicting obs 286\n",
      "predicting obs 285\n",
      "predicting obs 284\n",
      "predicting obs 283\n",
      "predicting obs 282\n",
      "predicting obs 281\n",
      "predicting obs 280\n",
      "predicting obs 279\n",
      "predicting obs 278\n",
      "predicting obs 277\n",
      "predicting obs 276\n",
      "predicting obs 275\n",
      "predicting obs 274\n",
      "predicting obs 273\n",
      "predicting obs 272\n",
      "predicting obs 271\n",
      "predicting obs 270\n",
      "predicting obs 269\n",
      "predicting obs 268\n",
      "predicting obs 267\n",
      "predicting obs 266\n",
      "predicting obs 265\n",
      "predicting obs 264\n",
      "predicting obs 263\n",
      "predicting obs 262\n",
      "predicting obs 261\n",
      "predicting obs 260\n",
      "predicting obs 259\n",
      "predicting obs 258\n",
      "predicting obs 257\n",
      "predicting obs 256\n",
      "predicting obs 255\n",
      "predicting obs 254\n",
      "predicting obs 253\n",
      "predicting obs 252\n",
      "predicting obs 251\n",
      "predicting obs 250\n",
      "predicting obs 249\n",
      "predicting obs 248\n",
      "predicting obs 247\n",
      "predicting obs 246\n",
      "predicting obs 245\n",
      "predicting obs 244\n",
      "predicting obs 243\n",
      "predicting obs 242\n",
      "predicting obs 241\n",
      "predicting obs 240\n",
      "predicting obs 239\n",
      "predicting obs 238\n",
      "predicting obs 237\n",
      "predicting obs 236\n",
      "predicting obs 235\n",
      "predicting obs 234\n",
      "predicting obs 233\n",
      "predicting obs 232\n",
      "predicting obs 231\n",
      "predicting obs 230\n",
      "predicting obs 229\n",
      "predicting obs 228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting obs 227\n",
      "predicting obs 226\n",
      "predicting obs 225\n",
      "predicting obs 224\n",
      "predicting obs 223\n",
      "predicting obs 222\n",
      "predicting obs 221\n",
      "predicting obs 220\n",
      "predicting obs 219\n",
      "predicting obs 218\n",
      "predicting obs 217\n",
      "predicting obs 216\n",
      "predicting obs 215\n",
      "predicting obs 214\n",
      "predicting obs 213\n",
      "predicting obs 212\n",
      "predicting obs 211\n",
      "predicting obs 210\n",
      "predicting obs 209\n",
      "predicting obs 208\n",
      "predicting obs 207\n",
      "predicting obs 206\n",
      "predicting obs 205\n",
      "predicting obs 204\n",
      "predicting obs 203\n",
      "predicting obs 202\n",
      "predicting obs 201\n",
      "predicting obs 200\n",
      "predicting obs 199\n",
      "predicting obs 198\n",
      "predicting obs 197\n",
      "predicting obs 196\n",
      "predicting obs 195\n",
      "predicting obs 194\n",
      "predicting obs 193\n",
      "predicting obs 192\n",
      "predicting obs 191\n",
      "predicting obs 190\n",
      "predicting obs 189\n",
      "predicting obs 188\n",
      "predicting obs 187\n",
      "predicting obs 186\n",
      "predicting obs 185\n",
      "predicting obs 184\n",
      "predicting obs 183\n",
      "predicting obs 182\n",
      "predicting obs 181\n",
      "predicting obs 180\n",
      "predicting obs 179\n",
      "predicting obs 178\n",
      "predicting obs 177\n",
      "predicting obs 176\n",
      "predicting obs 175\n",
      "predicting obs 174\n",
      "predicting obs 173\n",
      "predicting obs 172\n",
      "predicting obs 171\n",
      "predicting obs 170\n",
      "predicting obs 169\n",
      "predicting obs 168\n",
      "predicting obs 167\n",
      "predicting obs 166\n",
      "predicting obs 165\n",
      "predicting obs 164\n",
      "predicting obs 163\n",
      "predicting obs 162\n",
      "predicting obs 161\n",
      "predicting obs 160\n",
      "predicting obs 159\n",
      "predicting obs 158\n",
      "predicting obs 157\n",
      "predicting obs 156\n",
      "predicting obs 155\n",
      "predicting obs 154\n",
      "predicting obs 153\n",
      "predicting obs 152\n",
      "predicting obs 151\n",
      "predicting obs 150\n",
      "predicting obs 149\n",
      "predicting obs 148\n",
      "predicting obs 147\n",
      "predicting obs 146\n",
      "predicting obs 145\n",
      "predicting obs 144\n",
      "predicting obs 143\n",
      "predicting obs 142\n",
      "predicting obs 141\n",
      "predicting obs 140\n",
      "predicting obs 139\n",
      "predicting obs 138\n",
      "predicting obs 137\n",
      "predicting obs 136\n",
      "predicting obs 135\n",
      "predicting obs 134\n",
      "predicting obs 133\n",
      "predicting obs 132\n",
      "predicting obs 131\n",
      "predicting obs 130\n",
      "predicting obs 129\n",
      "predicting obs 128\n",
      "predicting obs 127\n",
      "predicting obs 126\n",
      "predicting obs 125\n",
      "predicting obs 124\n",
      "predicting obs 123\n",
      "predicting obs 122\n",
      "predicting obs 121\n",
      "predicting obs 120\n",
      "predicting obs 119\n",
      "predicting obs 118\n",
      "predicting obs 117\n",
      "predicting obs 116\n",
      "predicting obs 115\n",
      "predicting obs 114\n",
      "predicting obs 113\n",
      "predicting obs 112\n",
      "predicting obs 111\n",
      "predicting obs 110\n",
      "predicting obs 109\n",
      "predicting obs 108\n",
      "predicting obs 107\n",
      "predicting obs 106\n",
      "predicting obs 105\n",
      "predicting obs 104\n",
      "predicting obs 103\n",
      "predicting obs 102\n",
      "predicting obs 101\n",
      "predicting obs 100\n",
      "predicting obs 99\n",
      "predicting obs 98\n",
      "predicting obs 97\n",
      "predicting obs 96\n",
      "predicting obs 95\n",
      "predicting obs 94\n",
      "predicting obs 93\n",
      "predicting obs 92\n",
      "predicting obs 91\n",
      "predicting obs 90\n",
      "predicting obs 89\n",
      "predicting obs 88\n",
      "predicting obs 87\n",
      "predicting obs 86\n",
      "predicting obs 85\n",
      "predicting obs 84\n",
      "predicting obs 83\n",
      "predicting obs 82\n",
      "predicting obs 81\n",
      "predicting obs 80\n",
      "predicting obs 79\n",
      "predicting obs 78\n",
      "predicting obs 77\n",
      "predicting obs 76\n",
      "predicting obs 75\n",
      "predicting obs 74\n",
      "predicting obs 73\n",
      "predicting obs 72\n",
      "predicting obs 71\n",
      "predicting obs 70\n",
      "predicting obs 69\n",
      "predicting obs 68\n",
      "predicting obs 67\n",
      "predicting obs 66\n",
      "predicting obs 65\n",
      "predicting obs 64\n",
      "predicting obs 63\n",
      "predicting obs 62\n",
      "predicting obs 61\n",
      "predicting obs 60\n",
      "predicting obs 59\n",
      "predicting obs 58\n",
      "predicting obs 57\n",
      "predicting obs 56\n",
      "predicting obs 55\n",
      "predicting obs 54\n",
      "predicting obs 53\n",
      "predicting obs 52\n",
      "predicting obs 51\n",
      "predicting obs 50\n",
      "predicting obs 49\n",
      "predicting obs 48\n",
      "predicting obs 47\n",
      "predicting obs 46\n",
      "predicting obs 45\n",
      "predicting obs 44\n",
      "predicting obs 43\n",
      "predicting obs 42\n",
      "predicting obs 41\n",
      "predicting obs 40\n",
      "predicting obs 39\n",
      "predicting obs 38\n",
      "predicting obs 37\n",
      "predicting obs 36\n",
      "predicting obs 35\n",
      "predicting obs 34\n",
      "predicting obs 33\n",
      "predicting obs 32\n",
      "predicting obs 31\n",
      "predicting obs 30\n",
      "predicting obs 29\n",
      "predicting obs 28\n",
      "predicting obs 27\n",
      "predicting obs 26\n",
      "predicting obs 25\n",
      "predicting obs 24\n",
      "predicting obs 23\n",
      "predicting obs 22\n",
      "predicting obs 21\n",
      "predicting obs 20\n",
      "predicting obs 19\n",
      "predicting obs 18\n",
      "predicting obs 17\n",
      "predicting obs 16\n",
      "predicting obs 15\n",
      "predicting obs 14\n",
      "predicting obs 13\n",
      "predicting obs 12\n",
      "predicting obs 11\n",
      "predicting obs 10\n",
      "predicting obs 9\n",
      "predicting obs 8\n",
      "predicting obs 7\n",
      "predicting obs 6\n",
      "predicting obs 5\n",
      "predicting obs 4\n",
      "predicting obs 3\n",
      "predicting obs 2\n",
      "predicting obs 1\n",
      "predicting obs 0\n",
      "501\n",
      "predicting obs 460\n",
      "predicting obs 459\n",
      "predicting obs 458\n",
      "predicting obs 457\n",
      "predicting obs 456\n",
      "predicting obs 455\n",
      "predicting obs 454\n",
      "predicting obs 453\n",
      "predicting obs 452\n",
      "predicting obs 451\n",
      "predicting obs 450\n",
      "predicting obs 449\n",
      "predicting obs 448\n",
      "predicting obs 447\n",
      "predicting obs 446\n",
      "predicting obs 445\n",
      "predicting obs 444\n",
      "predicting obs 443\n",
      "predicting obs 442\n",
      "predicting obs 441\n",
      "predicting obs 440\n",
      "predicting obs 439\n",
      "predicting obs 438\n",
      "predicting obs 437\n",
      "predicting obs 436\n",
      "predicting obs 435\n",
      "predicting obs 434\n",
      "predicting obs 433\n",
      "predicting obs 432\n",
      "predicting obs 431\n",
      "predicting obs 430\n",
      "predicting obs 429\n",
      "predicting obs 428\n",
      "predicting obs 427\n",
      "predicting obs 426\n",
      "predicting obs 425\n",
      "predicting obs 424\n",
      "predicting obs 423\n",
      "predicting obs 422\n",
      "predicting obs 421\n",
      "predicting obs 420\n",
      "predicting obs 419\n",
      "predicting obs 418\n",
      "predicting obs 417\n",
      "predicting obs 416\n",
      "predicting obs 415\n",
      "predicting obs 414\n",
      "predicting obs 413\n",
      "predicting obs 412\n",
      "predicting obs 411\n",
      "predicting obs 410\n",
      "predicting obs 409\n",
      "predicting obs 408\n",
      "predicting obs 407\n",
      "predicting obs 406\n",
      "predicting obs 405\n",
      "predicting obs 404\n",
      "predicting obs 403\n",
      "predicting obs 402\n",
      "predicting obs 401\n",
      "predicting obs 400\n",
      "predicting obs 399\n",
      "predicting obs 398\n",
      "predicting obs 397\n",
      "predicting obs 396\n",
      "predicting obs 395\n",
      "predicting obs 394\n",
      "predicting obs 393\n",
      "predicting obs 392\n",
      "predicting obs 391\n",
      "predicting obs 390\n",
      "predicting obs 389\n",
      "predicting obs 388\n",
      "predicting obs 387\n",
      "predicting obs 386\n",
      "predicting obs 385\n",
      "predicting obs 384\n",
      "predicting obs 383\n",
      "predicting obs 382\n",
      "predicting obs 381\n",
      "predicting obs 380\n",
      "predicting obs 379\n",
      "predicting obs 378\n",
      "predicting obs 377\n",
      "predicting obs 376\n",
      "predicting obs 375\n",
      "predicting obs 374\n",
      "predicting obs 373\n",
      "predicting obs 372\n",
      "predicting obs 371\n",
      "predicting obs 370\n",
      "predicting obs 369\n",
      "predicting obs 368\n",
      "predicting obs 367\n",
      "predicting obs 366\n",
      "predicting obs 365\n",
      "predicting obs 364\n",
      "predicting obs 363\n",
      "predicting obs 362\n",
      "predicting obs 361\n",
      "predicting obs 360\n",
      "predicting obs 359\n",
      "predicting obs 358\n",
      "predicting obs 357\n",
      "predicting obs 356\n",
      "predicting obs 355\n",
      "predicting obs 354\n",
      "predicting obs 353\n",
      "predicting obs 352\n",
      "predicting obs 351\n",
      "predicting obs 350\n",
      "predicting obs 349\n",
      "predicting obs 348\n",
      "predicting obs 347\n",
      "predicting obs 346\n",
      "predicting obs 345\n",
      "predicting obs 344\n",
      "predicting obs 343\n",
      "predicting obs 342\n",
      "predicting obs 341\n",
      "predicting obs 340\n",
      "predicting obs 339\n",
      "predicting obs 338\n",
      "predicting obs 337\n",
      "predicting obs 336\n",
      "predicting obs 335\n",
      "predicting obs 334\n",
      "predicting obs 333\n",
      "predicting obs 332\n",
      "predicting obs 331\n",
      "predicting obs 330\n",
      "predicting obs 329\n",
      "predicting obs 328\n",
      "predicting obs 327\n",
      "predicting obs 326\n",
      "predicting obs 325\n",
      "predicting obs 324\n",
      "predicting obs 323\n",
      "predicting obs 322\n",
      "predicting obs 321\n",
      "predicting obs 320\n",
      "predicting obs 319\n",
      "predicting obs 318\n",
      "predicting obs 317\n",
      "predicting obs 316\n",
      "predicting obs 315\n",
      "predicting obs 314\n",
      "predicting obs 313\n",
      "predicting obs 312\n",
      "predicting obs 311\n",
      "predicting obs 310\n",
      "predicting obs 309\n",
      "predicting obs 308\n",
      "predicting obs 307\n",
      "predicting obs 306\n",
      "predicting obs 305\n",
      "predicting obs 304\n",
      "predicting obs 303\n",
      "predicting obs 302\n",
      "predicting obs 301\n",
      "predicting obs 300\n",
      "predicting obs 299\n",
      "predicting obs 298\n",
      "predicting obs 297\n",
      "predicting obs 296\n",
      "predicting obs 295\n",
      "predicting obs 294\n",
      "predicting obs 293\n",
      "predicting obs 292\n",
      "predicting obs 291\n",
      "predicting obs 290\n",
      "predicting obs 289\n",
      "predicting obs 288\n",
      "predicting obs 287\n",
      "predicting obs 286\n",
      "predicting obs 285\n",
      "predicting obs 284\n",
      "predicting obs 283\n",
      "predicting obs 282\n",
      "predicting obs 281\n",
      "predicting obs 280\n",
      "predicting obs 279\n",
      "predicting obs 278\n",
      "predicting obs 277\n",
      "predicting obs 276\n",
      "predicting obs 275\n",
      "predicting obs 274\n",
      "predicting obs 273\n",
      "predicting obs 272\n",
      "predicting obs 271\n",
      "predicting obs 270\n",
      "predicting obs 269\n",
      "predicting obs 268\n",
      "predicting obs 267\n",
      "predicting obs 266\n",
      "predicting obs 265\n",
      "predicting obs 264\n",
      "predicting obs 263\n",
      "predicting obs 262\n",
      "predicting obs 261\n",
      "predicting obs 260\n",
      "predicting obs 259\n",
      "predicting obs 258\n",
      "predicting obs 257\n",
      "predicting obs 256\n",
      "predicting obs 255\n",
      "predicting obs 254\n",
      "predicting obs 253\n",
      "predicting obs 252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting obs 251\n",
      "predicting obs 250\n",
      "predicting obs 249\n",
      "predicting obs 248\n",
      "predicting obs 247\n",
      "predicting obs 246\n",
      "predicting obs 245\n",
      "predicting obs 244\n",
      "predicting obs 243\n",
      "predicting obs 242\n",
      "predicting obs 241\n",
      "predicting obs 240\n",
      "predicting obs 239\n",
      "predicting obs 238\n",
      "predicting obs 237\n",
      "predicting obs 236\n",
      "predicting obs 235\n",
      "predicting obs 234\n",
      "predicting obs 233\n",
      "predicting obs 232\n",
      "predicting obs 231\n",
      "predicting obs 230\n",
      "predicting obs 229\n",
      "predicting obs 228\n",
      "predicting obs 227\n",
      "predicting obs 226\n",
      "predicting obs 225\n",
      "predicting obs 224\n",
      "predicting obs 223\n",
      "predicting obs 222\n",
      "predicting obs 221\n",
      "predicting obs 220\n",
      "predicting obs 219\n",
      "predicting obs 218\n",
      "predicting obs 217\n",
      "predicting obs 216\n",
      "predicting obs 215\n",
      "predicting obs 214\n",
      "predicting obs 213\n",
      "predicting obs 212\n",
      "predicting obs 211\n",
      "predicting obs 210\n",
      "predicting obs 209\n",
      "predicting obs 208\n",
      "predicting obs 207\n",
      "predicting obs 206\n",
      "predicting obs 205\n",
      "predicting obs 204\n",
      "predicting obs 203\n",
      "predicting obs 202\n",
      "predicting obs 201\n",
      "predicting obs 200\n",
      "predicting obs 199\n",
      "predicting obs 198\n",
      "predicting obs 197\n",
      "predicting obs 196\n",
      "predicting obs 195\n",
      "predicting obs 194\n",
      "predicting obs 193\n",
      "predicting obs 192\n",
      "predicting obs 191\n",
      "predicting obs 190\n",
      "predicting obs 189\n",
      "predicting obs 188\n",
      "predicting obs 187\n",
      "predicting obs 186\n",
      "predicting obs 185\n",
      "predicting obs 184\n",
      "predicting obs 183\n",
      "predicting obs 182\n",
      "predicting obs 181\n",
      "predicting obs 180\n",
      "predicting obs 179\n",
      "predicting obs 178\n",
      "predicting obs 177\n",
      "predicting obs 176\n",
      "predicting obs 175\n",
      "predicting obs 174\n",
      "predicting obs 173\n",
      "predicting obs 172\n",
      "predicting obs 171\n",
      "predicting obs 170\n",
      "predicting obs 169\n",
      "predicting obs 168\n",
      "predicting obs 167\n",
      "predicting obs 166\n",
      "predicting obs 165\n",
      "predicting obs 164\n",
      "predicting obs 163\n",
      "predicting obs 162\n",
      "predicting obs 161\n",
      "predicting obs 160\n",
      "predicting obs 159\n",
      "predicting obs 158\n",
      "predicting obs 157\n",
      "predicting obs 156\n",
      "predicting obs 155\n",
      "predicting obs 154\n",
      "predicting obs 153\n",
      "predicting obs 152\n",
      "predicting obs 151\n",
      "predicting obs 150\n",
      "predicting obs 149\n",
      "predicting obs 148\n",
      "predicting obs 147\n",
      "predicting obs 146\n",
      "predicting obs 145\n",
      "predicting obs 144\n",
      "predicting obs 143\n",
      "predicting obs 142\n",
      "predicting obs 141\n",
      "predicting obs 140\n",
      "predicting obs 139\n",
      "predicting obs 138\n",
      "predicting obs 137\n",
      "predicting obs 136\n",
      "predicting obs 135\n",
      "predicting obs 134\n",
      "predicting obs 133\n",
      "predicting obs 132\n",
      "predicting obs 131\n",
      "predicting obs 130\n",
      "predicting obs 129\n",
      "predicting obs 128\n",
      "predicting obs 127\n",
      "predicting obs 126\n",
      "predicting obs 125\n",
      "predicting obs 124\n",
      "predicting obs 123\n",
      "predicting obs 122\n",
      "predicting obs 121\n",
      "predicting obs 120\n",
      "predicting obs 119\n",
      "predicting obs 118\n",
      "predicting obs 117\n",
      "predicting obs 116\n",
      "predicting obs 115\n",
      "predicting obs 114\n",
      "predicting obs 113\n",
      "predicting obs 112\n",
      "predicting obs 111\n",
      "predicting obs 110\n",
      "predicting obs 109\n",
      "predicting obs 108\n",
      "predicting obs 107\n",
      "predicting obs 106\n",
      "predicting obs 105\n",
      "predicting obs 104\n",
      "predicting obs 103\n",
      "predicting obs 102\n",
      "predicting obs 101\n",
      "predicting obs 100\n",
      "predicting obs 99\n",
      "predicting obs 98\n",
      "predicting obs 97\n",
      "predicting obs 96\n",
      "predicting obs 95\n",
      "predicting obs 94\n",
      "predicting obs 93\n",
      "predicting obs 92\n",
      "predicting obs 91\n",
      "predicting obs 90\n",
      "predicting obs 89\n",
      "predicting obs 88\n",
      "predicting obs 87\n",
      "predicting obs 86\n",
      "predicting obs 85\n",
      "predicting obs 84\n",
      "predicting obs 83\n",
      "predicting obs 82\n",
      "predicting obs 81\n",
      "predicting obs 80\n",
      "predicting obs 79\n",
      "predicting obs 78\n",
      "predicting obs 77\n",
      "predicting obs 76\n",
      "predicting obs 75\n",
      "predicting obs 74\n",
      "predicting obs 73\n",
      "predicting obs 72\n",
      "predicting obs 71\n",
      "predicting obs 70\n",
      "predicting obs 69\n",
      "predicting obs 68\n",
      "predicting obs 67\n",
      "predicting obs 66\n",
      "predicting obs 65\n",
      "predicting obs 64\n",
      "predicting obs 63\n",
      "predicting obs 62\n",
      "predicting obs 61\n",
      "predicting obs 60\n",
      "predicting obs 59\n",
      "predicting obs 58\n",
      "predicting obs 57\n",
      "predicting obs 56\n",
      "predicting obs 55\n",
      "predicting obs 54\n",
      "predicting obs 53\n",
      "predicting obs 52\n",
      "predicting obs 51\n",
      "predicting obs 50\n",
      "predicting obs 49\n",
      "predicting obs 48\n",
      "predicting obs 47\n",
      "predicting obs 46\n",
      "predicting obs 45\n",
      "predicting obs 44\n",
      "predicting obs 43\n",
      "predicting obs 42\n",
      "predicting obs 41\n",
      "predicting obs 40\n",
      "predicting obs 39\n",
      "predicting obs 38\n",
      "predicting obs 37\n",
      "predicting obs 36\n",
      "predicting obs 35\n",
      "predicting obs 34\n",
      "predicting obs 33\n",
      "predicting obs 32\n",
      "predicting obs 31\n",
      "predicting obs 30\n",
      "predicting obs 29\n",
      "predicting obs 28\n",
      "predicting obs 27\n",
      "predicting obs 26\n",
      "predicting obs 25\n",
      "predicting obs 24\n",
      "predicting obs 23\n",
      "predicting obs 22\n",
      "predicting obs 21\n",
      "predicting obs 20\n",
      "predicting obs 19\n",
      "predicting obs 18\n",
      "predicting obs 17\n",
      "predicting obs 16\n",
      "predicting obs 15\n",
      "predicting obs 14\n",
      "predicting obs 13\n",
      "predicting obs 12\n",
      "predicting obs 11\n",
      "predicting obs 10\n",
      "predicting obs 9\n",
      "predicting obs 8\n",
      "predicting obs 7\n",
      "predicting obs 6\n",
      "predicting obs 5\n",
      "predicting obs 4\n",
      "predicting obs 3\n",
      "predicting obs 2\n",
      "predicting obs 1\n",
      "predicting obs 0\n",
      "461\n"
     ]
    }
   ],
   "source": [
    "horizons = [1,5,20,60]\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "for horizon in horizons:\n",
    "\n",
    "    forecasts_size = test_size - horizon + 1\n",
    "\n",
    "    horizon_forecasts = []\n",
    "\n",
    "    update_counter = 0\n",
    "\n",
    "    iteration = 1\n",
    "\n",
    "    model_index_1 = model_indices[0][iteration-1][1]\n",
    "    model1 = models[1][model_index_1]\n",
    "\n",
    "    model_index_2 = model_indices[1][iteration-1][1]\n",
    "    model2 = models[2][model_index_2]\n",
    "\n",
    "    adjusting_models = {1:model1,2:model2}\n",
    "\n",
    "    for j in range(forecasts_size-1, -1, -1):\n",
    "\n",
    "        print(f'predicting obs {j}')\n",
    "\n",
    "        pred_obs = j\n",
    "        current_time = pred_obs + horizon # latest available information\n",
    "        to_predict = np.flip(np.arange(pred_obs, current_time))\n",
    "\n",
    "        updated_fA = np.copy(fA)\n",
    "        updated_fD = np.copy(fD)\n",
    "\n",
    "        updated_time = np.copy(current_time)\n",
    "\n",
    "        coef_pick_decision = [[None,None], [None,None], updated_fA, updated_fD]\n",
    "\n",
    "        for i in range(len(to_predict)):\n",
    "\n",
    "            predict = to_predict[i]\n",
    "\n",
    "            if i == 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhfnn(predict, current_time, [[None,None], [None,None], fA, fD],adjusting_models, num_lags_dict)\n",
    "\n",
    "            if i != 0:\n",
    "\n",
    "                a2,d2,a1,d1,reconstruct_from = mhfnn(predict, updated_time, coef_pick_decision, adjusting_models, num_lags_dict)\n",
    "\n",
    "            updated_fA[reconstruct_from[0],0], updated_fD[reconstruct_from[0],0] = a1,d1\n",
    "            updated_fA[reconstruct_from[1],1], updated_fD[reconstruct_from[1],1] = a2,d2\n",
    "            coef_pick_decision[2], coef_pick_decision[3] = updated_fA, updated_fD\n",
    "            coef_pick_decision[0][0], coef_pick_decision[1][0] = reconstruct_from[0], reconstruct_from[1]\n",
    "            coef_pick_decision[0][1] = [a1,d1]\n",
    "            coef_pick_decision[1][1] = [a2,d2]\n",
    "            updated_time = updated_time - 1\n",
    "\n",
    "        position = pred_obs - coef_pick_decision[1][0]\n",
    "        pred = assemble(position, coef_pick_decision[1][1][0], coef_pick_decision[1][1][1], coef_pick_decision[0][1][1])\n",
    "        horizon_forecasts.append(pred)\n",
    "\n",
    "        update_counter += 1\n",
    "\n",
    "        if update_counter % batch_size == 0:\n",
    "\n",
    "            iteration += 1\n",
    "            \n",
    "            model_index_1 = model_indices[0][iteration-1][1]\n",
    "            model1 = models[1][model_index_1]\n",
    "\n",
    "            model_index_2 = model_indices[1][iteration-1][1]\n",
    "            model2 = models[2][model_index_2]\n",
    "\n",
    "            adjusting_models = {1:model1,2:model2}\n",
    "            \n",
    "        lm_save_path = f'prediction/no_decimation_multistep_nn_{horizon}.pkl'\n",
    "\n",
    "        os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "        with open(lm_save_path, 'wb') as file:\n",
    "            pickle.dump(horizon_forecasts, file)\n",
    "\n",
    "    all_predictions.append(horizon_forecasts)\n",
    "    print(len(horizon_forecasts))\n",
    "\n",
    "#     lm_save_path = f'USDCHF/new_prediction/no_decimation_multistep_nn_{horizon}.pkl'\n",
    "\n",
    "#     os.makedirs(os.path.dirname(lm_save_path), exist_ok=True)\n",
    "\n",
    "#     print(f'Done with horizon {horizon}')\n",
    "#     print(mean_squared_error(r_test[horizon-1:],horizon_forecasts))\n",
    "\n",
    "#     with open(lm_save_path, 'wb') as file:\n",
    "#         pickle.dump(horizon_forecasts, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
